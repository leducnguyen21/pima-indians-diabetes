{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "SzPE54CYM1kJ",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<h1 align=center><font size = 10> Classification with Python</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "XPfbiVLfM1kK",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this notebook, we try to practice all the classification algorithms that we have learned in this course.\n",
    "\n",
    "We load a dataset using the Pandas library, and apply the following algorithms, and find the best one for this specific dataset by accuracy evaluation methods.\n",
    "\n",
    "Lets first load required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "button": false,
    "id": "vcBmcLcqM1kL",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKehb7okM1kN"
   },
   "source": [
    "# Mandatory part (85%  of the total score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1OXuDMKku37m"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "ZAL75IefM1kO",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## About dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "yrPdRO--M1kO",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "The Pima is a group of Native Americans living in Arizona. A genetic predisposition allowed this group to survive normally to a diet poor of carbohydrates for years. In recent years, a sudden shift from traditional agricultural crops to processed foods, together with a decline in physical activity, has made them develop the highest prevalence of type 2 diabetes and for this reason, they have been subject of many studies.\n",
    "\n",
    "The dataset includes data from 768 women with 8 characteristics, in particular:\n",
    "\n",
    "- Number of times pregnant\n",
    "- Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "- Diastolic blood pressure (mm Hg)\n",
    "- Triceps skinfold thickness (mm)\n",
    "- 2-Hour serum insulin (mu U/ml)\n",
    "- Body mass index (weight in kg/(height in m)^2)\n",
    "- Diabetes pedigree function\n",
    "- Age (years)\n",
    "- The last column of the dataset indicates if the person has been diagnosed with diabetes (1) or not (0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzJFrqwyM1kP"
   },
   "source": [
    "## The problem:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WFl47FBcM1kQ"
   },
   "source": [
    "The type of dataset and problem is a classic supervised binary classification. Given a number of elements with certain characteristics (features), we want to build a machine learning model to identify people affected by type 2 diabetes.\n",
    "\n",
    "To solve the problem we will have to analyze the data, do any required transformation and nomarlization, apply a machine learning algorithm, train a model, check the performance of the trained model and iterate with other algorithms until we find the most performant for our type of dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "Diy5tSZ7M1kQ",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Load Data From CSV File  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qdIctwmZM1kR"
   },
   "source": [
    "### 1. Load the dataset from the 'pima-indians-diabetes.csv' file.\n",
    "\n",
    "Because the CSV doesn't contain any header, we add column names using the description from the original dataset website:\n",
    "\n",
    "dataset.columns = [\"NumTimesPrg\", \"PlGlcConc\", \"BloodP\", \"SkinThick\", \"TwoHourSerIns\", \"BMI\", \"DiPedFunc\", \"Age\", \"HasDiabetes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "button": false,
    "id": "K-TmhZ8vM1kS",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#TO DO:\n",
    "dataset = pd.read_csv('pima-indians-diabetes.csv', header=None)\n",
    "dataset.columns = [\n",
    "    \"NumTimesPrg\", \"PlGlcConc\", \"BloodP\",\n",
    "    \"SkinThick\", \"TwoHourSerIns\", \"BMI\",\n",
    "    \"DiPedFunc\", \"Age\", \"HasDiabetes\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "AmBhwo0DM1kU",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Inspect the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_HlgbaIQM1kU"
   },
   "source": [
    "### 2. Print out the shape of the dataset: we have 768 rows and 9 columns. Then, print out the head of the dataset to better understand the data format.\n",
    "\n",
    "The first 8 columns are features while the last one is the supervised label (1 = has diabetes, 0 = no diabetes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NumTimesPrg</th>\n",
       "      <th>PlGlcConc</th>\n",
       "      <th>BloodP</th>\n",
       "      <th>SkinThick</th>\n",
       "      <th>TwoHourSerIns</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiPedFunc</th>\n",
       "      <th>Age</th>\n",
       "      <th>HasDiabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.248</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.3</td>\n",
       "      <td>0.134</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>70</td>\n",
       "      <td>45</td>\n",
       "      <td>543</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.158</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>125</td>\n",
       "      <td>96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.232</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NumTimesPrg  PlGlcConc  BloodP  SkinThick  TwoHourSerIns   BMI  DiPedFunc  \\\n",
       "0            6        148      72         35              0  33.6      0.627   \n",
       "1            1         85      66         29              0  26.6      0.351   \n",
       "2            8        183      64          0              0  23.3      0.672   \n",
       "3            1         89      66         23             94  28.1      0.167   \n",
       "4            0        137      40         35            168  43.1      2.288   \n",
       "5            5        116      74          0              0  25.6      0.201   \n",
       "6            3         78      50         32             88  31.0      0.248   \n",
       "7           10        115       0          0              0  35.3      0.134   \n",
       "8            2        197      70         45            543  30.5      0.158   \n",
       "9            8        125      96          0              0   0.0      0.232   \n",
       "\n",
       "   Age  HasDiabetes  \n",
       "0   50            1  \n",
       "1   31            0  \n",
       "2   32            1  \n",
       "3   21            0  \n",
       "4   33            1  \n",
       "5   30            0  \n",
       "6   26            1  \n",
       "7   29            0  \n",
       "8   53            1  \n",
       "9   54            1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "button": false,
    "id": "bpyxtYzcM1kV",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#TO DO:\n",
    "# Number of times pregnant\n",
    "# Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
    "# Diastolic blood pressure (mm Hg)\n",
    "# Triceps skinfold thickness (mm)\n",
    "# 2-Hour serum insulin (mu U/ml)\n",
    "# Body mass index (weight in kg/(height in m)^2)\n",
    "# Diabetes pedigree function\n",
    "# Age (years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "a02T2r1XM1kY",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Data visualization and pre-processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "WyisS4NVM1kZ",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Data correlation matrix\n",
    "### 3. Let's calculate the correlation matrix for our dataset.\n",
    "\n",
    "The correlation matrix is an important tool to understand the correlation between the different characteristics. The values range from -1 to 1 and the closer a value is to 1 the better correlation there is between two characteristics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "button": false,
    "id": "vymkxfN8M1kZ",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NumTimesPrg</th>\n",
       "      <th>PlGlcConc</th>\n",
       "      <th>BloodP</th>\n",
       "      <th>SkinThick</th>\n",
       "      <th>TwoHourSerIns</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiPedFunc</th>\n",
       "      <th>Age</th>\n",
       "      <th>HasDiabetes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NumTimesPrg</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.129459</td>\n",
       "      <td>0.141282</td>\n",
       "      <td>-0.081672</td>\n",
       "      <td>-0.073535</td>\n",
       "      <td>0.017683</td>\n",
       "      <td>-0.033523</td>\n",
       "      <td>0.544341</td>\n",
       "      <td>0.221898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PlGlcConc</th>\n",
       "      <td>0.129459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.152590</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.331357</td>\n",
       "      <td>0.221071</td>\n",
       "      <td>0.137337</td>\n",
       "      <td>0.263514</td>\n",
       "      <td>0.466581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BloodP</th>\n",
       "      <td>0.141282</td>\n",
       "      <td>0.152590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>0.088933</td>\n",
       "      <td>0.281805</td>\n",
       "      <td>0.041265</td>\n",
       "      <td>0.239528</td>\n",
       "      <td>0.065068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SkinThick</th>\n",
       "      <td>-0.081672</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436783</td>\n",
       "      <td>0.392573</td>\n",
       "      <td>0.183928</td>\n",
       "      <td>-0.113970</td>\n",
       "      <td>0.074752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TwoHourSerIns</th>\n",
       "      <td>-0.073535</td>\n",
       "      <td>0.331357</td>\n",
       "      <td>0.088933</td>\n",
       "      <td>0.436783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.197859</td>\n",
       "      <td>0.185071</td>\n",
       "      <td>-0.042163</td>\n",
       "      <td>0.130548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>0.017683</td>\n",
       "      <td>0.221071</td>\n",
       "      <td>0.281805</td>\n",
       "      <td>0.392573</td>\n",
       "      <td>0.197859</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140647</td>\n",
       "      <td>0.036242</td>\n",
       "      <td>0.292695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiPedFunc</th>\n",
       "      <td>-0.033523</td>\n",
       "      <td>0.137337</td>\n",
       "      <td>0.041265</td>\n",
       "      <td>0.183928</td>\n",
       "      <td>0.185071</td>\n",
       "      <td>0.140647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033561</td>\n",
       "      <td>0.173844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.544341</td>\n",
       "      <td>0.263514</td>\n",
       "      <td>0.239528</td>\n",
       "      <td>-0.113970</td>\n",
       "      <td>-0.042163</td>\n",
       "      <td>0.036242</td>\n",
       "      <td>0.033561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.238356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasDiabetes</th>\n",
       "      <td>0.221898</td>\n",
       "      <td>0.466581</td>\n",
       "      <td>0.065068</td>\n",
       "      <td>0.074752</td>\n",
       "      <td>0.130548</td>\n",
       "      <td>0.292695</td>\n",
       "      <td>0.173844</td>\n",
       "      <td>0.238356</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               NumTimesPrg  PlGlcConc    BloodP  SkinThick  TwoHourSerIns  \\\n",
       "NumTimesPrg       1.000000   0.129459  0.141282  -0.081672      -0.073535   \n",
       "PlGlcConc         0.129459   1.000000  0.152590   0.057328       0.331357   \n",
       "BloodP            0.141282   0.152590  1.000000   0.207371       0.088933   \n",
       "SkinThick        -0.081672   0.057328  0.207371   1.000000       0.436783   \n",
       "TwoHourSerIns    -0.073535   0.331357  0.088933   0.436783       1.000000   \n",
       "BMI               0.017683   0.221071  0.281805   0.392573       0.197859   \n",
       "DiPedFunc        -0.033523   0.137337  0.041265   0.183928       0.185071   \n",
       "Age               0.544341   0.263514  0.239528  -0.113970      -0.042163   \n",
       "HasDiabetes       0.221898   0.466581  0.065068   0.074752       0.130548   \n",
       "\n",
       "                    BMI  DiPedFunc       Age  HasDiabetes  \n",
       "NumTimesPrg    0.017683  -0.033523  0.544341     0.221898  \n",
       "PlGlcConc      0.221071   0.137337  0.263514     0.466581  \n",
       "BloodP         0.281805   0.041265  0.239528     0.065068  \n",
       "SkinThick      0.392573   0.183928 -0.113970     0.074752  \n",
       "TwoHourSerIns  0.197859   0.185071 -0.042163     0.130548  \n",
       "BMI            1.000000   0.140647  0.036242     0.292695  \n",
       "DiPedFunc      0.140647   1.000000  0.033561     0.173844  \n",
       "Age            0.036242   0.033561  1.000000     0.238356  \n",
       "HasDiabetes    0.292695   0.173844  0.238356     1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TO DO:\n",
    "corr = dataset.corr()\n",
    "corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0YpKuUBM1kb"
   },
   "source": [
    "### 4. Render the corr matrix using the heatmap in seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ll0POqtIM1kc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TO DO:\n",
    "import seaborn as sns\n",
    "sns.heatmap(corr, annot = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7DgicVOM1ke"
   },
   "source": [
    "### 5. Print out the column which has the biggest corr number with 'HasDiabetes'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "DoZkwj3oM1ke"
   },
   "outputs": [],
   "source": [
    "sorted_corr = corr.unstack().sort_values()\n",
    "sorted_corr = pd.DataFrame(sorted_corr['HasDiabetes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The column which has the bigggest corr number with 'HasDiabetes' is PlGlcConc with 0.46658139830687373\n"
     ]
    }
   ],
   "source": [
    "# We have to exclude the column HasDiabetes which has the highest value - 1.0. So we will choose -2 after sort the list \n",
    "print(\"The column which has the bigggest corr number with 'HasDiabetes' is \" + sorted_corr.index[-2] + \" with \" + str(sorted_corr.iloc[-2][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZ5Msu8UM1kg"
   },
   "source": [
    "## Visualize the Dataset\n",
    "Visualizing the data is an important step of the data analysis. With a graphical visualization of the data, we have a better understanding of the various features values distribution: for example, we can understand the average age of the people or the average BMI, etc...\n",
    "\n",
    "We could, of course, limit our inspection to the table visualization, but we could miss important things that may affect our model precision.\n",
    "### 6. Manipulate histogram to represent all data columns in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "JC3CILgxM1kh"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TO DO:\n",
    "dataset.hist(bins=50, figsize=(20, 15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "VYSkabikM1kj",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "An important thing I notice in the dataset (and that wasn't obvious at the beginning) is the fact that some people have null (zero) values for some of the features: it's not quite possible to have 0 for BMI or the blood pressure.\n",
    "\n",
    "How can we deal with similar values? We will see it later during the data transformation phase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "si5Fgks4M1kj",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Data cleaning and transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "ZDAqJwOaM1kk",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "We have noticed from the previous analysis that some patients have missing data for some of the features. Machine learning algorithms don't work very well when the data are missing so we have to find a solution to \"clean\" the data we have.\n",
    "\n",
    "The easiest option could be to eliminate all those patients with null/zero values, but in this way, we would eliminate a lot of important data.\n",
    "\n",
    "Another option is to calculate the median value for a specific column and substitute that value everywhere (in the same column) we have zero or null. Let's see how to apply this second method.\n",
    "\n",
    "### 7. Interpolate missing values on ['BMI', 'BloodP', 'PlGlcConc', 'SkinThick',  'TwoHourSerIns'] using median values or any other way which is effective.\n",
    "\n",
    "We haven't transformed all the columns, because of some values which can make sense to be zero (like \"Number of times pregnant\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "button": false,
    "id": "ccZyY2RbM1kk",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NumTimesPrg  PlGlcConc  BloodP  SkinThick  TwoHourSerIns  BMI    DiPedFunc  Age    HasDiabetes\n",
       "False        False      False   False      False          False  False      False  False          768\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TO DO:\n",
    "#there is no missing value in the dataset\n",
    "dataset.isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find median value for each column\n",
    "med_BMI = dataset['BMI'].median()\n",
    "med_BloodP = dataset['BloodP'].median()\n",
    "med_PlGlcConc = dataset['PlGlcConc'].median()\n",
    "med_SkinThick = dataset['SkinThick'].median()\n",
    "med_TwoHourSerIns = dataset['TwoHourSerIns'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 0.0 with median value\n",
    "dataset['BMI'] = dataset['BMI'].replace(to_replace=0, value=med_BMI)\n",
    "dataset['BloodP'] = dataset['BloodP'].replace(to_replace=0, value=med_BloodP)\n",
    "dataset['PlGlcConc'] = dataset['PlGlcConc'].replace(to_replace=0, value=med_PlGlcConc)\n",
    "dataset['SkinThick'] = dataset['SkinThick'].replace(to_replace=0, value=med_SkinThick)\n",
    "dataset['TwoHourSerIns'] = dataset['TwoHourSerIns'].replace(to_replace=0, value=med_TwoHourSerIns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8h0P-vLM1kl"
   },
   "source": [
    "## Normalize Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNxKYsijM1km"
   },
   "source": [
    "One of the most important data transformations we need to apply is the features scaling. Basically, most of the machine learning algorithms don't work very well if the features have a different set of values. In our case, for example, the Age ranges from 20 to 80 years old, while the number of times a patient has been pregnant ranges from 0 to 17. For this reason, we need to apply a proper transformation.\n",
    "\n",
    "### 8. Execute Data Standardization using data zero mean and unit variance (don't forget to remove ground truth column before scaling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NumTimesPrg</th>\n",
       "      <th>PlGlcConc</th>\n",
       "      <th>BloodP</th>\n",
       "      <th>SkinThick</th>\n",
       "      <th>TwoHourSerIns</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiPedFunc</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>30.5</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>30.5</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>23</td>\n",
       "      <td>30.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94.0</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180.0</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>30.5</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112.0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>23</td>\n",
       "      <td>30.5</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>30.5</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     NumTimesPrg  PlGlcConc  BloodP  SkinThick  TwoHourSerIns   BMI  \\\n",
       "0              6        148      72         35           30.5  33.6   \n",
       "1              1         85      66         29           30.5  26.6   \n",
       "2              8        183      64         23           30.5  23.3   \n",
       "3              1         89      66         23           94.0  28.1   \n",
       "4              0        137      40         35          168.0  43.1   \n",
       "..           ...        ...     ...        ...            ...   ...   \n",
       "763           10        101      76         48          180.0  32.9   \n",
       "764            2        122      70         27           30.5  36.8   \n",
       "765            5        121      72         23          112.0  26.2   \n",
       "766            1        126      60         23           30.5  30.1   \n",
       "767            1         93      70         31           30.5  30.4   \n",
       "\n",
       "     DiPedFunc  Age  \n",
       "0        0.627   50  \n",
       "1        0.351   31  \n",
       "2        0.672   32  \n",
       "3        0.167   21  \n",
       "4        2.288   33  \n",
       "..         ...  ...  \n",
       "763      0.171   63  \n",
       "764      0.340   27  \n",
       "765      0.245   30  \n",
       "766      0.349   47  \n",
       "767      0.315   23  \n",
       "\n",
       "[768 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset[['NumTimesPrg','PlGlcConc','BloodP','SkinThick','TwoHourSerIns','BMI','DiPedFunc','Age']]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1\n",
       "1      0\n",
       "2      1\n",
       "3      0\n",
       "4      1\n",
       "      ..\n",
       "763    0\n",
       "764    0\n",
       "765    0\n",
       "766    1\n",
       "767    0\n",
       "Name: HasDiabetes, Length: 768, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataset['HasDiabetes']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "S22D1f6QM1km"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.63994726,  0.86604475, -0.03198993,  0.83111367, -0.60820096,\n",
       "         0.16724016,  0.46849198,  1.4259954 ],\n",
       "       [-0.84488505, -1.20506583, -0.5283186 ,  0.1805664 , -0.60820096,\n",
       "        -0.85155088, -0.36506078, -0.19067191],\n",
       "       [ 1.23388019,  2.01666174, -0.69376149, -0.46998087, -0.60820096,\n",
       "        -1.33183808,  0.60439732, -0.10558415],\n",
       "       [-0.84488505, -1.07356674, -0.5283186 , -0.46998087, -0.00618459,\n",
       "        -0.63323851, -0.92076261, -1.04154944],\n",
       "       [-1.14185152,  0.50442227, -2.67907616,  0.83111367,  0.69537779,\n",
       "         1.54988514,  5.4849091 , -0.0204964 ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TO DO:\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X.astype(float))\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "oOHQu_2rM1ko",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Splitting the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "luDui2xtM1ko"
   },
   "source": [
    "Now that we have transformed the data, we need to split the dataset into two parts: a training dataset and a test dataset. Splitting the dataset is a very important step for supervised machine learning models. Basically, we are going to use the first part to train the model (ignoring the column with the pre-assigned label), then we use the trained model to make predictions on new data (which is the test dataset, not part of the training set) and compare the predicted value with the pre-assigned label.\n",
    "\n",
    "### 9. Split the dataset into 80/20 using the stratified technique and random_state=7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Xfh4QK1oM1kp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (614, 8) (614,)\n",
      "Test set: (154, 8) (154,)\n"
     ]
    }
   ],
   "source": [
    "# Split the training dataset in 80% / 20%\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=7)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yk3Y6qVtM1kq"
   },
   "source": [
    "# Additional Question: \n",
    "### Why should we perform data normalization and data splitting before the training step?\n",
    "Type your answer in the cell bellow as the markdown format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2yXSkeUjM1kr"
   },
   "source": [
    "### TO DO:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6PaVBEAwM1ks"
   },
   "source": [
    "### 10. Print out the proportion of positive/total women who have diabetes on the full dataset, training dataset, and testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.89583333333333"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pro_dbs_full = dataset.loc[dataset['HasDiabetes'] == 1].shape[0] / dataset.shape[0] * 100\n",
    "pro_dbs_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.36482084690554"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pro_dbs_train = y_train.loc[y_train == 1].shape[0] / y_train.shape[0] * 100\n",
    "pro_dbs_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.01298701298701"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pro_dbs_test = y_test.loc[y_test == 1].shape[0] / y_test.shape[0] * 100\n",
    "pro_dbs_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "KHXGaCazM1k0",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "id": "Q-NwUyDVM1k0",
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now, it is your turn, use the training set to build an accurate model. Then use the test set to report the accuracy of the model.\n",
    "\n",
    "You should use the following algorithms:\n",
    "- K Nearest Neighbor(KNN)\n",
    "- Decision Tree\n",
    "- Support Vector Machine\n",
    "- Logistic Regression\n",
    "- Soft voting\n",
    "- Hard voting\n",
    "\n",
    "\n",
    "\n",
    "**__ Notes:__**\n",
    "\n",
    "- You must try to **FINE TUNE AT LEAST 3 PARAMETERS** on each algorithm, except on soft voting and hard voting.\n",
    "- You can go above and change the pre-processing, feature selection, feature extraction, and so on, to make a better model.\n",
    "- You should use either scikit-learn, Scipy or Numpy libraries for developing the classification algorithms.\n",
    "- You should include the code of the algorithm in the following cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8HKeDu9M1k1"
   },
   "source": [
    "# Import Evaluation Metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 322
    },
    "id": "sZrg6rrsM1k1",
    "outputId": "ae2fe388-db16-4615-ba71-bbac795f92e5"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import jaccard_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "TBXdCSP-M1k3"
   },
   "outputs": [],
   "source": [
    "# a dictionary for keeping all scores of the classifiers\n",
    "f1_scores = {'train':{'KNN': 0, 'DT': 0, 'SVM': 0, 'LR': 0, 'EN_HARD': 0, 'EN_SOFT': 0},\n",
    "             'test':{'KNN': 0, 'DT': 0, 'SVM': 0, 'LR': 0, 'EN_HARD': 0, 'EN_SOFT': 0}}\n",
    "jaccard_scores = {'train':{'KNN': 0, 'DT': 0, 'SVM': 0, 'LR': 0, 'EN_HARD': 0, 'EN_SOFT': 0}, \n",
    "                  'test':{'KNN': 0, 'DT': 0, 'SVM': 0, 'LR': 0, 'EN_HARD': 0, 'EN_SOFT': 0}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntwqYDm7M1k6"
   },
   "source": [
    "# K Nearest Neighbor(KNN)\n",
    "### 11. Finetune at least 3 parameters to get the KNN model with best accuracy. Then, print out the KNN model's parameters with the best accuracy(best estimator).\n",
    "Hint: Using GridSearchCV in sklearn.model_selection.\n",
    "\n",
    "**Warning:** You should not use the test data for finding the best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "WpD6yCUlM1k7"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([7.95483589e-04, 1.00080967e-03, 9.88316536e-04, 8.94212723e-04,\n",
       "        1.12009048e-03, 8.84127617e-04, 9.47475433e-04, 7.98821449e-04,\n",
       "        8.84509087e-04, 9.09686089e-04, 8.13484192e-04, 8.94427299e-04,\n",
       "        9.44876671e-04, 9.96994972e-04, 1.02097988e-03, 8.46314430e-04,\n",
       "        6.97302818e-04, 8.25214386e-04, 6.66809082e-04, 9.48214531e-04,\n",
       "        8.97908211e-04, 9.80591774e-04, 1.01215839e-03, 8.04114342e-04,\n",
       "        8.52823257e-04, 1.22141838e-03, 9.04512405e-04, 8.08167458e-04,\n",
       "        8.96716118e-04, 7.97104836e-04, 1.02424622e-03, 7.63678551e-04,\n",
       "        9.67907906e-04, 9.96851921e-04, 9.99832153e-04, 1.04897022e-03,\n",
       "        1.10385418e-03, 9.05060768e-04, 1.00779533e-03, 8.58163834e-04,\n",
       "        7.97224045e-04, 1.00452900e-03, 9.93084908e-04, 9.96685028e-04,\n",
       "        9.00769234e-04, 8.14008713e-04, 8.99124146e-04, 1.00643635e-03,\n",
       "        7.07483292e-04, 9.88054276e-04, 9.08613205e-04, 7.98726082e-04,\n",
       "        9.76061821e-04, 8.40997696e-04, 9.82904434e-04, 9.97686386e-04,\n",
       "        8.76641273e-04, 9.78279114e-04, 8.01563263e-04, 1.18126869e-03,\n",
       "        9.35053825e-04, 8.96239281e-04, 7.98916817e-04, 9.03487206e-04,\n",
       "        1.00979805e-03, 9.28640366e-04, 8.51368904e-04, 8.66484642e-04,\n",
       "        8.53753090e-04, 9.05179977e-04, 7.98130035e-04, 1.01683140e-03,\n",
       "        1.00266933e-03, 9.06491280e-04, 9.07111168e-04, 8.22305679e-04,\n",
       "        9.18078423e-04, 7.79533386e-04, 9.15741920e-04, 8.95643234e-04,\n",
       "        8.59665871e-04, 8.97598267e-04, 9.74869728e-04, 9.97400284e-04,\n",
       "        9.61327553e-04, 9.14120674e-04, 8.04734230e-04, 6.71339035e-04,\n",
       "        9.05370712e-04, 8.03518295e-04, 7.93552399e-04, 7.66491890e-04,\n",
       "        7.98797607e-04, 9.13047791e-04, 9.66095924e-04, 7.62724876e-04,\n",
       "        1.01521015e-03, 8.98957253e-04, 1.09519958e-03, 8.54754448e-04,\n",
       "        8.96143913e-04, 1.00176334e-03, 1.00023746e-03, 8.96263123e-04,\n",
       "        7.09629059e-04, 8.96716118e-04, 7.99822807e-04, 7.59816170e-04,\n",
       "        6.97588921e-04, 7.95722008e-04, 7.04693794e-04, 1.05044842e-03,\n",
       "        8.98575783e-04, 9.11593437e-04, 8.05354118e-04, 8.70895386e-04,\n",
       "        8.02350044e-04, 1.00426674e-03, 8.58569145e-04, 1.00185871e-03,\n",
       "        8.76498222e-04, 9.08589363e-04, 6.98280334e-04, 1.00538731e-03,\n",
       "        8.05234909e-04, 8.53109360e-04, 8.15463066e-04, 7.82537460e-04,\n",
       "        9.67216492e-04, 9.79852676e-04, 7.97843933e-04, 9.00316238e-04,\n",
       "        8.05163383e-04, 8.95881653e-04, 6.99424744e-04, 1.00746155e-03,\n",
       "        8.02803040e-04, 7.09748268e-04, 9.14549828e-04, 9.28735733e-04,\n",
       "        8.29195976e-04, 9.52458382e-04, 1.00443363e-03, 9.94539261e-04,\n",
       "        8.99934769e-04, 9.99665260e-04, 8.94999504e-04, 1.19552612e-03,\n",
       "        1.20866299e-03, 1.07867718e-03, 1.30250454e-03, 1.00414753e-03,\n",
       "        1.21507645e-03, 1.14440918e-03, 8.98528099e-04, 7.98988342e-04,\n",
       "        8.02850723e-04, 9.03725624e-04, 1.00295544e-03, 8.13961029e-04,\n",
       "        7.98439980e-04, 8.94212723e-04, 8.10194016e-04, 8.11815262e-04,\n",
       "        8.90016556e-04, 1.00758076e-03, 9.94658470e-04, 8.98051262e-04,\n",
       "        7.82275200e-04, 8.96453857e-04, 8.98647308e-04, 9.97710228e-04,\n",
       "        8.98909569e-04, 9.53102112e-04, 8.10980797e-04, 7.98654556e-04,\n",
       "        8.06021690e-04, 7.97986984e-04, 1.00376606e-03, 7.98082352e-04,\n",
       "        6.98304176e-04, 1.08699799e-03, 7.98034668e-04, 9.97424126e-04,\n",
       "        7.90810585e-04, 1.02148056e-03, 8.97598267e-04, 3.03792953e-04,\n",
       "        5.96308708e-04, 6.98876381e-04, 7.02309608e-04, 7.10082054e-04,\n",
       "        8.34345818e-04, 9.24062729e-04, 8.01420212e-04, 6.98804855e-04,\n",
       "        7.99202919e-04, 7.98273087e-04, 8.01563263e-04, 7.88402557e-04,\n",
       "        7.98034668e-04, 7.16829300e-04, 9.30476189e-04, 9.08541679e-04,\n",
       "        8.06856155e-04, 7.97939301e-04, 8.14008713e-04, 8.03375244e-04,\n",
       "        7.98559189e-04, 6.51979446e-04, 8.98647308e-04, 9.11855698e-04,\n",
       "        7.08889961e-04, 8.02850723e-04, 9.04870033e-04, 7.95245171e-04,\n",
       "        8.98575783e-04, 7.98273087e-04, 8.98432732e-04, 6.49118423e-04,\n",
       "        5.07593155e-04, 8.35609436e-04, 8.02922249e-04, 6.92987442e-04,\n",
       "        6.87861443e-04, 8.51273537e-04, 6.98280334e-04, 7.05504417e-04,\n",
       "        9.98759270e-04, 8.97789001e-04, 6.81257248e-04, 8.16512108e-04,\n",
       "        4.02402878e-04, 7.20858574e-04, 7.00163841e-04, 7.57622719e-04,\n",
       "        8.05974007e-04, 7.97963142e-04, 5.97119331e-04, 7.22098351e-04,\n",
       "        9.00673866e-04, 9.08041000e-04, 8.58068466e-04, 8.32343102e-04,\n",
       "        7.02238083e-04, 6.84380531e-04, 8.42952728e-04, 6.11257553e-04,\n",
       "        8.02445412e-04, 6.78157806e-04, 6.97159767e-04, 9.00340080e-04,\n",
       "        7.94744492e-04, 7.49874115e-04, 7.94625282e-04, 9.97877121e-04,\n",
       "        7.30490685e-04, 7.98368454e-04, 8.98480415e-04, 6.54315948e-04,\n",
       "        7.59124756e-04, 7.99345970e-04, 7.98082352e-04, 7.99298286e-04,\n",
       "        9.10735130e-04, 8.03852081e-04, 7.98487663e-04, 7.53331184e-04,\n",
       "        8.98647308e-04, 6.98709488e-04, 6.98661804e-04, 7.98773766e-04,\n",
       "        8.16798210e-04, 6.99329376e-04, 8.98170471e-04, 7.98058510e-04,\n",
       "        9.98139381e-04, 6.98661804e-04, 8.98861885e-04, 8.98551941e-04,\n",
       "        7.20262527e-04, 5.98526001e-04, 1.00965500e-03, 6.98399544e-04,\n",
       "        1.01125240e-03, 8.97836685e-04, 7.98106194e-04, 6.84285164e-04,\n",
       "        9.05513763e-04, 7.59553909e-04, 8.33845139e-04, 5.98549843e-04,\n",
       "        9.00554657e-04, 8.13388824e-04, 9.94253159e-04, 7.97843933e-04,\n",
       "        7.07340240e-04, 8.91375542e-04, 8.97884369e-04, 7.98964500e-04,\n",
       "        8.04710388e-04, 7.96937943e-04, 6.93392754e-04, 8.98385048e-04,\n",
       "        7.09819794e-04, 6.01887703e-04, 7.24029541e-04, 6.09207153e-04,\n",
       "        8.05997849e-04, 7.78889656e-04, 8.71729851e-04, 7.04622269e-04,\n",
       "        8.34655762e-04, 4.97961044e-04, 6.37888908e-04, 7.50041008e-04,\n",
       "        8.98146629e-04, 8.11338425e-04, 7.98535347e-04, 1.00436211e-03,\n",
       "        9.04560089e-04, 7.01522827e-04, 6.03318214e-04, 7.98964500e-04,\n",
       "        8.04948807e-04, 8.00466537e-04, 7.53784180e-04, 8.01777840e-04,\n",
       "        7.95984268e-04, 5.08022308e-04, 5.94830513e-04, 6.01601601e-04,\n",
       "        9.07897949e-04, 8.64171982e-04, 7.97581673e-04, 9.01317596e-04,\n",
       "        8.05902481e-04, 7.94339180e-04, 6.98518753e-04, 6.45756721e-04,\n",
       "        8.16297531e-04, 9.79924202e-04, 6.99186325e-04, 6.98471069e-04,\n",
       "        1.05695724e-03, 7.55810738e-04, 1.00574493e-03, 8.98241997e-04,\n",
       "        9.55247879e-04, 8.27026367e-04, 9.97924805e-04, 9.97519493e-04,\n",
       "        7.02214241e-04, 5.98835945e-04, 8.99767876e-04, 6.94346428e-04,\n",
       "        6.64377213e-04, 7.95173645e-04, 9.08517838e-04, 8.71682167e-04,\n",
       "        8.01205635e-04, 9.89675522e-04, 7.70306587e-04, 1.00326538e-03,\n",
       "        1.05905533e-03, 1.39238834e-03, 1.26888752e-03, 1.07805729e-03,\n",
       "        8.96906853e-04, 1.00436211e-03, 7.02047348e-04, 1.00810528e-03,\n",
       "        8.04996490e-04, 9.11402702e-04, 9.01699066e-04, 9.78541374e-04,\n",
       "        8.07619095e-04, 9.02056694e-04, 8.94665718e-04, 8.00704956e-04,\n",
       "        1.07183456e-03, 9.01150703e-04, 9.02462006e-04, 9.14311409e-04,\n",
       "        8.50367546e-04, 7.65442848e-04, 1.01392269e-03, 9.97734070e-04,\n",
       "        9.98449326e-04, 9.53149796e-04, 1.00388527e-03, 6.98471069e-04,\n",
       "        9.98067856e-04, 9.11021233e-04, 9.00411606e-04, 9.53531265e-04,\n",
       "        7.64012337e-04, 8.06331635e-04, 9.98067856e-04, 8.98265839e-04,\n",
       "        1.00657940e-03, 9.48548317e-04, 8.96859169e-04, 7.27462769e-04,\n",
       "        1.00631714e-03, 9.07874107e-04, 1.00004673e-03, 9.00673866e-04,\n",
       "        8.98241997e-04, 8.11696053e-04, 8.98838043e-04, 9.09757614e-04,\n",
       "        9.00959969e-04, 6.98113441e-04, 9.98044014e-04, 9.76228714e-04,\n",
       "        9.04488564e-04, 9.02628899e-04, 9.43684578e-04, 8.71443748e-04,\n",
       "        7.97200203e-04, 9.97471809e-04, 1.00336075e-03, 8.49413872e-04,\n",
       "        9.97638702e-04, 9.08589363e-04, 6.98304176e-04, 7.15827942e-04,\n",
       "        1.00290775e-03, 8.97693634e-04, 7.97986984e-04, 6.91127777e-04,\n",
       "        8.97836685e-04, 8.84366035e-04, 7.08150864e-04, 9.03773308e-04,\n",
       "        8.87417793e-04, 9.28831100e-04, 1.00870132e-03, 9.12880898e-04,\n",
       "        7.98130035e-04, 7.97939301e-04, 7.98034668e-04, 9.97543335e-04,\n",
       "        8.97765160e-04, 8.91160965e-04, 7.82847404e-04, 8.97717476e-04,\n",
       "        9.97757912e-04, 9.59634781e-04, 1.09384060e-03, 1.29334927e-03,\n",
       "        1.09338760e-03, 9.26995277e-04, 7.98130035e-04, 4.99057770e-04,\n",
       "        1.00531578e-03, 9.98020172e-04, 1.00011826e-03, 9.06062126e-04,\n",
       "        5.98978996e-04, 8.98265839e-04, 5.98883629e-04, 8.98098946e-04,\n",
       "        8.98075104e-04, 8.97955894e-04, 1.00510120e-03, 7.98249245e-04,\n",
       "        1.00793839e-03, 8.85939598e-04, 8.05687904e-04, 8.52966309e-04,\n",
       "        9.10162926e-04, 9.97519493e-04, 9.00816917e-04, 9.07707214e-04,\n",
       "        8.89706612e-04, 9.95731354e-04, 1.00061893e-03, 1.01602077e-03,\n",
       "        9.03201103e-04, 1.19824409e-03, 1.00495815e-03, 8.53061676e-04,\n",
       "        8.03279877e-04, 9.11879539e-04, 1.01141930e-03, 9.03844833e-04,\n",
       "        9.11235809e-04, 8.98814201e-04, 1.00011826e-03, 9.04607773e-04,\n",
       "        9.11688805e-04, 8.06236267e-04, 6.02436066e-04, 7.97772408e-04,\n",
       "        8.98742676e-04, 8.01324844e-04, 8.00347328e-04, 9.01174545e-04,\n",
       "        9.97447968e-04, 8.04686546e-04, 9.01508331e-04, 8.95142555e-04,\n",
       "        1.00347996e-03, 7.96151161e-04, 9.58633423e-04, 9.67979431e-04,\n",
       "        9.89723206e-04, 9.11760330e-04, 9.46950912e-04, 1.02345943e-03,\n",
       "        9.55295563e-04, 9.99855995e-04, 1.01890564e-03, 8.03995132e-04,\n",
       "        1.00049973e-03, 8.14652443e-04, 8.59713554e-04, 8.04042816e-04,\n",
       "        1.00696087e-03, 1.05631351e-03, 1.00128651e-03, 1.00953579e-03,\n",
       "        8.97860527e-04, 8.51559639e-04, 9.04202461e-04, 1.04010105e-03,\n",
       "        9.56559181e-04, 1.19178295e-03, 8.99243355e-04, 8.98933411e-04,\n",
       "        1.00815296e-03, 1.05147362e-03, 9.03630257e-04, 8.97932053e-04,\n",
       "        8.15892220e-04, 1.00224018e-03, 1.01196766e-03, 8.04114342e-04,\n",
       "        9.15098190e-04, 9.54723358e-04, 9.57298279e-04, 1.03950500e-03,\n",
       "        1.01003647e-03, 9.97209549e-04, 1.47426128e-03, 1.14791393e-03,\n",
       "        1.29644871e-03, 6.07609749e-04, 1.20496750e-03, 9.98258591e-04,\n",
       "        8.98146629e-04, 8.97431374e-04, 1.09715462e-03, 1.17912292e-03,\n",
       "        7.08937645e-04, 7.77840614e-04, 1.09748840e-03, 6.98828697e-04,\n",
       "        6.50382042e-04, 8.99267197e-04, 9.97400284e-04, 1.23233795e-03,\n",
       "        8.16583633e-04, 5.31673431e-04, 1.04041100e-03, 8.99624825e-04,\n",
       "        5.81336021e-04, 4.98604774e-04, 7.90524483e-04, 5.05685806e-04,\n",
       "        3.98802757e-04, 8.34631920e-04, 5.98430634e-04, 6.87074661e-04,\n",
       "        4.99033928e-04, 5.48267365e-04, 7.97986984e-04, 6.98208809e-04,\n",
       "        7.97963142e-04, 5.98382950e-04, 8.10337067e-04, 5.97572327e-04,\n",
       "        7.99393654e-04, 3.98945808e-04, 6.98351860e-04, 5.90753555e-04,\n",
       "        5.98812103e-04, 9.20653343e-04, 7.99012184e-04, 5.71656227e-04,\n",
       "        5.99312782e-04, 7.36641884e-04, 6.98089600e-04, 1.01187229e-03,\n",
       "        6.07442856e-04, 6.26611710e-04, 5.67865372e-04, 7.98177719e-04,\n",
       "        1.00207329e-03, 8.81171227e-04, 7.98797607e-04, 6.19935989e-04,\n",
       "        6.97445869e-04, 5.98502159e-04, 2.99286842e-04, 5.99241257e-04,\n",
       "        6.05010986e-04, 3.02863121e-04, 7.03382492e-04, 5.98645210e-04,\n",
       "        7.02619553e-04, 6.13141060e-04, 5.93876839e-04, 4.98437881e-04,\n",
       "        7.74836540e-04, 5.00965118e-04, 6.02126122e-04, 4.10699844e-04,\n",
       "        1.02996826e-04, 4.99391556e-04, 5.88321686e-04, 3.99231911e-04,\n",
       "        0.00000000e+00, 7.18760490e-04, 2.00676918e-04, 3.98755074e-04,\n",
       "        7.14492798e-04, 5.99026680e-04, 0.00000000e+00, 4.12821770e-04,\n",
       "        9.02175903e-04, 4.10914421e-04, 2.03251839e-04, 5.03087044e-04,\n",
       "        5.98692894e-04, 3.98230553e-04, 6.99853897e-04, 2.99811363e-04,\n",
       "        1.00135803e-04, 4.31275368e-04, 4.12034988e-04, 5.03230095e-04,\n",
       "        8.94689560e-04, 5.05518913e-04, 5.02085686e-04, 4.72950935e-04,\n",
       "        1.99198723e-04, 5.01847267e-04, 3.02648544e-04, 9.97304916e-05,\n",
       "        6.14905357e-04, 7.97176361e-04, 5.98907471e-04, 1.00183487e-04,\n",
       "        4.50444221e-04, 9.05084610e-04, 4.98700142e-04, 9.47356224e-04,\n",
       "        7.51829147e-04, 7.49468803e-04, 6.88958168e-04, 7.02285767e-04,\n",
       "        8.97598267e-04, 7.98225403e-04, 7.45058060e-04, 8.98385048e-04,\n",
       "        4.98533249e-04, 6.98447227e-04, 5.98526001e-04, 4.98652458e-04,\n",
       "        7.93766975e-04, 6.97970390e-04, 8.72206688e-04, 8.20183754e-04,\n",
       "        8.98027420e-04, 5.98454475e-04, 5.98406792e-04, 7.97653198e-04,\n",
       "        4.98676300e-04, 7.77220726e-04, 8.97550583e-04, 8.97121429e-04,\n",
       "        4.98795509e-04, 7.26222992e-04, 9.14072990e-04, 5.98502159e-04,\n",
       "        4.98628616e-04, 4.98723984e-04, 6.98113441e-04, 6.98113441e-04,\n",
       "        6.98590279e-04, 6.98208809e-04, 4.99176979e-04, 4.98867035e-04,\n",
       "        4.96864319e-04, 7.49802589e-04, 6.55508041e-04, 1.99484825e-04,\n",
       "        8.74567032e-04, 6.98494911e-04, 4.99486923e-04, 3.98802757e-04,\n",
       "        6.99067116e-04, 8.59856606e-04, 2.99453735e-04, 3.98826599e-04,\n",
       "        5.98549843e-04, 3.98945808e-04, 9.03034210e-04, 5.93042374e-04,\n",
       "        9.99140739e-04, 6.97994232e-04, 7.88497925e-04, 3.98778915e-04,\n",
       "        6.98757172e-04, 9.97471809e-04, 8.97836685e-04, 5.98549843e-04]),\n",
       " 'std_fit_time': array([3.97965836e-04, 1.89208990e-05, 3.79698411e-05, 2.98803513e-04,\n",
       "        2.58742844e-04, 2.95845584e-04, 3.40940919e-04, 3.99684713e-04,\n",
       "        2.99549457e-04, 3.05447444e-04, 4.61974767e-04, 2.98890554e-04,\n",
       "        1.48807708e-04, 9.98973846e-06, 3.90516314e-05, 3.14428715e-04,\n",
       "        4.56696163e-04, 4.67914169e-04, 4.49620902e-04, 1.49103001e-04,\n",
       "        3.00077103e-04, 8.98024048e-05, 4.48540974e-04, 4.02825205e-04,\n",
       "        3.14105489e-04, 7.32107603e-04, 3.02041747e-04, 4.05346421e-04,\n",
       "        2.98921499e-04, 3.98559327e-04, 7.76411851e-05, 4.12193158e-04,\n",
       "        3.93360109e-04, 2.54438538e-06, 4.75929350e-05, 1.52139454e-04,\n",
       "        5.41593183e-04, 3.02640856e-04, 2.72106530e-05, 3.14571793e-04,\n",
       "        3.98944047e-04, 3.61529446e-05, 9.25914752e-06, 3.42394315e-06,\n",
       "        3.00611424e-04, 4.08105614e-04, 3.00323418e-04, 3.33271396e-05,\n",
       "        4.64812086e-04, 1.95816417e-05, 3.03707184e-04, 3.78307805e-04,\n",
       "        6.46131461e-05, 4.34824968e-04, 2.67054778e-05, 4.36782241e-04,\n",
       "        2.98638214e-04, 2.81474919e-05, 4.01132496e-04, 3.68927298e-04,\n",
       "        3.36108497e-04, 2.99634458e-04, 3.99985002e-04, 3.02147692e-04,\n",
       "        4.54689362e-04, 3.14602923e-04, 3.13082895e-04, 3.03067661e-04,\n",
       "        3.19226068e-04, 3.02808326e-04, 3.99594577e-04, 4.46308436e-05,\n",
       "        2.17649525e-05, 3.12033770e-04, 3.03104195e-04, 3.69415659e-04,\n",
       "        3.09028834e-04, 3.97342244e-04, 3.07544727e-04, 2.98713328e-04,\n",
       "        3.03313078e-04, 2.99536350e-04, 4.51291726e-04, 1.48142953e-05,\n",
       "        3.66077741e-04, 3.06361147e-04, 4.02665138e-04, 4.49076274e-04,\n",
       "        3.02075553e-04, 4.01918454e-04, 3.97312129e-04, 4.08521430e-04,\n",
       "        3.99683461e-04, 3.05956650e-04, 1.22634575e-04, 3.93984873e-04,\n",
       "        7.63114112e-05, 3.00395569e-04, 3.18410350e-04, 3.16864848e-04,\n",
       "        2.99366993e-04, 2.34844237e-05, 4.46121020e-04, 2.99266944e-04,\n",
       "        4.64845214e-04, 2.99436507e-04, 3.99980107e-04, 3.94801708e-04,\n",
       "        4.56927866e-04, 3.98074147e-04, 4.61504782e-04, 1.68286955e-04,\n",
       "        3.00614185e-04, 3.51123021e-04, 4.03207710e-04, 3.13124040e-04,\n",
       "        4.01609993e-04, 3.96976313e-05, 3.21146577e-04, 3.96587925e-04,\n",
       "        4.63839409e-04, 3.04647048e-04, 4.57131859e-04, 2.40884073e-05,\n",
       "        4.03119558e-04, 3.13854399e-04, 4.11018612e-04, 3.93973407e-04,\n",
       "        1.21488142e-04, 2.05222315e-05, 3.99232380e-04, 3.00572645e-04,\n",
       "        4.03112835e-04, 2.99311394e-04, 4.57902433e-04, 4.46909343e-04,\n",
       "        4.01775768e-04, 4.66658865e-04, 3.06483916e-04, 3.18513341e-04,\n",
       "        3.36186521e-04, 1.49742412e-04, 1.89038872e-05, 4.40247666e-04,\n",
       "        3.00186663e-04, 1.59969628e-05, 2.98534212e-04, 3.93386020e-04,\n",
       "        3.84500567e-04, 3.29453088e-04, 4.61564853e-04, 2.35754989e-05,\n",
       "        3.92768834e-04, 3.57787160e-04, 3.00009783e-04, 3.99843138e-04,\n",
       "        4.01938076e-04, 3.01775320e-04, 1.00583540e-05, 3.76196520e-04,\n",
       "        3.99222360e-04, 2.98615424e-04, 4.05526788e-04, 4.06713320e-04,\n",
       "        2.97104928e-04, 4.22233111e-05, 4.38654868e-04, 2.99351974e-04,\n",
       "        3.93905815e-04, 2.98838568e-04, 2.99553012e-04, 1.41472852e-06,\n",
       "        2.99641110e-04, 1.33801654e-04, 4.07264691e-04, 3.99330392e-04,\n",
       "        3.23869470e-04, 3.98993574e-04, 1.72650119e-05, 3.99041343e-04,\n",
       "        4.57147435e-04, 3.03614894e-04, 3.99017448e-04, 1.92219204e-07,\n",
       "        4.47897161e-04, 7.22887491e-05, 2.99199963e-04, 4.64271903e-04,\n",
       "        4.87244162e-04, 4.57791301e-04, 4.59860369e-04, 4.68940145e-04,\n",
       "        4.38617659e-04, 3.24209625e-04, 4.00836902e-04, 4.57478872e-04,\n",
       "        3.99604609e-04, 3.99138334e-04, 4.00869515e-04, 4.40552000e-04,\n",
       "        3.99017476e-04, 4.53448197e-04, 3.25398478e-04, 3.04517073e-04,\n",
       "        4.04220161e-04, 3.98969821e-04, 4.08202364e-04, 4.01986383e-04,\n",
       "        3.99281143e-04, 4.47730911e-04, 2.99553448e-04, 3.04564561e-04,\n",
       "        4.64993239e-04, 4.02023897e-04, 3.02599656e-04, 3.97735634e-04,\n",
       "        2.99528867e-04, 3.99138861e-04, 2.99481430e-04, 4.43796357e-04,\n",
       "        4.46518995e-04, 4.28277497e-04, 4.01603157e-04, 4.53774362e-04,\n",
       "        4.51393098e-04, 3.16402336e-04, 4.57131908e-04, 4.62348824e-04,\n",
       "        1.49444904e-06, 2.99263266e-04, 4.62592703e-04, 4.14445877e-04,\n",
       "        4.92929807e-04, 4.76013417e-04, 4.58877223e-04, 3.97012912e-04,\n",
       "        4.03191622e-04, 3.99143712e-04, 4.87564470e-04, 4.76732994e-04,\n",
       "        3.00765639e-04, 3.02969535e-04, 4.64585162e-04, 4.36832554e-04,\n",
       "        4.60056078e-04, 4.48662392e-04, 4.38185850e-04, 4.71252579e-04,\n",
       "        4.01347806e-04, 4.57845313e-04, 4.56402320e-04, 3.00679085e-04,\n",
       "        3.97482960e-04, 4.02198714e-04, 3.97442719e-04, 1.28037659e-06,\n",
       "        4.82290513e-04, 3.99186302e-04, 2.99495859e-04, 4.50324002e-04,\n",
       "        5.27406040e-04, 3.99676419e-04, 3.99041315e-04, 3.99655201e-04,\n",
       "        3.06042737e-04, 4.02301243e-04, 3.99245454e-04, 3.99660589e-04,\n",
       "        2.99553107e-04, 4.57416756e-04, 4.57382916e-04, 3.99389921e-04,\n",
       "        3.65411136e-04, 4.57823717e-04, 2.99392431e-04, 3.99029361e-04,\n",
       "        1.04060902e-06, 4.57382940e-04, 2.99627401e-04, 2.99520276e-04,\n",
       "        4.73488830e-04, 4.88694480e-04, 4.39105666e-05, 4.57211835e-04,\n",
       "        4.00347676e-05, 2.99282101e-04, 3.99053338e-04, 4.49817572e-04,\n",
       "        1.93368991e-04, 5.22970648e-04, 4.24530698e-04, 4.88962622e-04,\n",
       "        3.01154845e-04, 4.10640455e-04, 2.50359489e-05, 3.99296660e-04,\n",
       "        4.63490339e-04, 2.97739944e-04, 2.99294925e-04, 6.04114982e-04,\n",
       "        4.03554851e-04, 3.98810679e-04, 4.54668557e-04, 3.00107523e-04,\n",
       "        4.66599679e-04, 4.91542159e-04, 4.78223202e-04, 4.97615956e-04,\n",
       "        4.03176155e-04, 3.97992491e-04, 4.86737775e-04, 4.61444821e-04,\n",
       "        4.21272349e-04, 4.98184007e-04, 5.32566529e-04, 4.02003129e-04,\n",
       "        2.99384773e-04, 4.07565818e-04, 3.99268982e-04, 4.61783999e-04,\n",
       "        5.32432952e-04, 4.59397713e-04, 4.92952472e-04, 3.99787244e-04,\n",
       "        4.02693311e-04, 4.00642857e-04, 3.96843885e-04, 4.01200545e-04,\n",
       "        3.98350190e-04, 5.08170214e-04, 4.85771117e-04, 4.91532824e-04,\n",
       "        2.77842828e-04, 3.12112472e-04, 3.99072394e-04, 3.00685137e-04,\n",
       "        4.03484642e-04, 3.97318007e-04, 4.57289306e-04, 4.44819317e-04,\n",
       "        4.10688495e-04, 3.67024467e-04, 4.57727140e-04, 4.57257363e-04,\n",
       "        1.55040682e-04, 3.98393956e-04, 2.30523027e-05, 2.99416248e-04,\n",
       "        1.29198991e-04, 4.21846771e-04, 1.10909494e-06, 1.50046380e-05,\n",
       "        4.60104447e-04, 4.89157572e-04, 3.03086855e-04, 4.54653229e-04,\n",
       "        4.50177630e-04, 3.97759080e-04, 3.03579645e-04, 3.01724688e-04,\n",
       "        4.00751977e-04, 1.33373834e-05, 4.03261645e-04, 1.51826029e-05,\n",
       "        4.87307991e-04, 7.95148934e-04, 4.18323921e-04, 5.08379149e-04,\n",
       "        2.99339619e-04, 3.32193664e-05, 4.59704831e-04, 2.04404272e-05,\n",
       "        4.03429531e-04, 3.04219436e-04, 3.01156284e-04, 1.13319177e-04,\n",
       "        4.05787570e-04, 3.01164159e-04, 2.98454759e-04, 4.00746799e-04,\n",
       "        2.25887637e-04, 3.00630174e-04, 3.01052940e-04, 2.45374871e-04,\n",
       "        4.52570554e-04, 5.37884048e-04, 4.90599223e-05, 1.14738554e-06,\n",
       "        1.60220123e-06, 1.34616915e-04, 2.22647550e-04, 4.57258258e-04,\n",
       "        1.85538067e-06, 3.06156795e-04, 3.00223377e-04, 1.37251602e-04,\n",
       "        4.09021109e-04, 4.03983127e-04, 1.27859952e-06, 2.99426346e-04,\n",
       "        2.57826187e-05, 3.46159429e-04, 2.99337523e-04, 4.26197225e-04,\n",
       "        4.49753920e-04, 3.03038032e-04, 2.32927143e-05, 5.44360065e-04,\n",
       "        2.99416874e-04, 4.07723017e-04, 2.99618666e-04, 3.05200308e-04,\n",
       "        3.00355416e-04, 4.57022539e-04, 1.13066728e-06, 4.24193757e-05,\n",
       "        3.03318138e-04, 3.01247709e-04, 3.36611462e-04, 3.05580051e-04,\n",
       "        3.98605748e-04, 2.39607707e-07, 1.65909869e-05, 3.17610383e-04,\n",
       "        7.55452133e-07, 3.04621223e-04, 4.57147634e-04, 3.93265057e-04,\n",
       "        1.53079767e-05, 2.99231270e-04, 3.98993546e-04, 4.52911379e-04,\n",
       "        2.99279062e-04, 2.97460675e-04, 4.42836808e-04, 3.01838977e-04,\n",
       "        2.97451165e-04, 3.23238899e-04, 3.22952553e-05, 3.07661130e-04,\n",
       "        3.99065046e-04, 3.98969679e-04, 3.99017448e-04, 1.84678237e-07,\n",
       "        2.99255119e-04, 2.97678916e-04, 3.94039518e-04, 2.99239216e-04,\n",
       "        6.94694628e-07, 4.49277846e-04, 5.37477716e-04, 4.59085620e-04,\n",
       "        3.00244484e-04, 3.20820109e-04, 3.99065231e-04, 4.99059098e-04,\n",
       "        2.27649670e-05, 1.04469787e-06, 4.97467093e-06, 3.02833626e-04,\n",
       "        4.89065702e-04, 2.99424182e-04, 4.88987537e-04, 2.99369090e-04,\n",
       "        2.99360684e-04, 2.99320033e-04, 1.88263287e-05, 3.99125611e-04,\n",
       "        3.07892834e-05, 2.97371657e-04, 4.03457243e-04, 4.56417934e-04,\n",
       "        3.05537018e-04, 2.24923638e-07, 3.01104374e-04, 3.05776467e-04,\n",
       "        2.96940593e-04, 2.67794482e-05, 4.46100319e-04, 5.67902095e-05,\n",
       "        3.01301059e-04, 3.91090791e-04, 6.31337921e-04, 5.35804221e-04,\n",
       "        4.02101240e-04, 2.80675016e-04, 4.71278258e-04, 3.01780119e-04,\n",
       "        3.04375452e-04, 2.99982790e-04, 1.69175749e-05, 3.01942513e-04,\n",
       "        3.05106901e-04, 4.03314991e-04, 4.92293017e-04, 3.99179699e-04,\n",
       "        5.33175956e-04, 4.01051176e-04, 4.00448834e-04, 3.02478614e-04,\n",
       "        5.45765073e-07, 4.02803549e-04, 5.19531763e-04, 2.98824307e-04,\n",
       "        9.42067203e-06, 3.98149191e-04, 1.12999330e-04, 1.14478165e-04,\n",
       "        2.23088457e-05, 3.08638902e-04, 1.41285482e-04, 6.28656086e-05,\n",
       "        1.20069916e-04, 3.18395582e-05, 6.89626059e-05, 6.09268962e-04,\n",
       "        1.89740450e-05, 4.11703415e-04, 4.62440839e-04, 4.02225148e-04,\n",
       "        2.15378561e-05, 1.53415946e-04, 1.64712731e-05, 3.99130148e-05,\n",
       "        2.99286956e-04, 3.15476686e-04, 3.01719805e-04, 1.46553837e-04,\n",
       "        1.35546968e-04, 6.00311622e-04, 5.40040324e-04, 2.99698000e-04,\n",
       "        4.47125823e-04, 1.59738057e-04, 2.81426517e-04, 2.99313039e-04,\n",
       "        4.08200145e-04, 2.67462825e-05, 1.86272669e-05, 4.02288651e-04,\n",
       "        5.74007134e-04, 5.72811820e-04, 1.18290690e-04, 4.64242288e-04,\n",
       "        3.84889414e-05, 1.45102730e-06, 5.65845472e-04, 6.32442814e-04,\n",
       "        4.56952305e-04, 4.77585590e-04, 6.07741763e-04, 1.24800227e-06,\n",
       "        5.37747367e-04, 2.99153197e-04, 5.37886738e-04, 4.11366676e-04,\n",
       "        4.65005368e-04, 3.93383637e-04, 3.00474666e-04, 7.79958580e-04,\n",
       "        4.48816518e-04, 5.38319373e-04, 1.75266037e-06, 3.95652106e-04,\n",
       "        4.12092262e-04, 4.74973111e-04, 8.86096883e-05, 2.99944143e-04,\n",
       "        4.77220179e-04, 4.98604838e-04, 3.95613043e-04, 5.06029974e-04,\n",
       "        4.88431741e-04, 3.35584598e-04, 4.88616574e-04, 4.51447563e-04,\n",
       "        4.99034810e-04, 4.70556684e-04, 3.98993717e-04, 4.57085045e-04,\n",
       "        3.98981727e-04, 4.88577889e-04, 4.06850443e-04, 4.87919031e-04,\n",
       "        3.99724180e-04, 4.88606895e-04, 4.57178893e-04, 4.96063894e-04,\n",
       "        4.88928674e-04, 3.14468850e-04, 3.99517239e-04, 4.71657047e-04,\n",
       "        4.89344223e-04, 4.10764963e-04, 4.57007073e-04, 4.37832141e-05,\n",
       "        4.96651170e-04, 4.60985807e-04, 4.72063546e-04, 3.99090565e-04,\n",
       "        5.60752186e-05, 3.16338232e-04, 3.99407258e-04, 5.10015546e-04,\n",
       "        4.61971408e-04, 4.88675041e-04, 4.57168269e-04, 4.89284072e-04,\n",
       "        4.94150815e-04, 4.62694030e-04, 4.61034782e-04, 4.89032267e-04,\n",
       "        4.60331848e-04, 5.00983317e-04, 4.85220428e-04, 4.98689390e-04,\n",
       "        4.04932538e-04, 5.01118737e-04, 4.91717176e-04, 4.86189971e-04,\n",
       "        3.08990479e-04, 4.99624791e-04, 4.82239179e-04, 4.89201080e-04,\n",
       "        0.00000000e+00, 4.71427258e-04, 3.88816569e-04, 4.88374015e-04,\n",
       "        4.70480146e-04, 4.89347257e-04, 0.00000000e+00, 5.05614582e-04,\n",
       "        3.01342183e-04, 4.79999727e-04, 4.06567385e-04, 5.03184119e-04,\n",
       "        4.89128338e-04, 4.87731880e-04, 4.58427772e-04, 4.57970345e-04,\n",
       "        3.00407410e-04, 4.77395963e-04, 5.07076331e-04, 5.03302897e-04,\n",
       "        2.98809658e-04, 5.05722012e-04, 5.02422990e-04, 4.82408379e-04,\n",
       "        3.98398733e-04, 5.01987467e-04, 4.62392599e-04, 2.99191475e-04,\n",
       "        5.04138309e-04, 3.98611212e-04, 4.89006968e-04, 3.00550461e-04,\n",
       "        4.71146688e-04, 3.02460986e-04, 4.98700149e-04, 1.50571073e-04,\n",
       "        4.00296632e-04, 5.13716018e-04, 4.51522995e-04, 4.59929365e-04,\n",
       "        2.99199792e-04, 3.99113499e-04, 3.94564236e-04, 2.99464640e-04,\n",
       "        4.98533306e-04, 4.57242023e-04, 4.88694468e-04, 4.98652515e-04,\n",
       "        3.97149165e-04, 4.56928995e-04, 3.00737080e-04, 3.57799035e-04,\n",
       "        2.99343412e-04, 4.88636053e-04, 4.88597128e-04, 3.98826770e-04,\n",
       "        4.98676327e-04, 3.93369551e-04, 2.99183650e-04, 2.99126810e-04,\n",
       "        4.98795571e-04, 4.82343260e-04, 3.06404784e-04, 4.88675099e-04,\n",
       "        6.69065849e-04, 4.98724059e-04, 4.57022639e-04, 4.57022564e-04,\n",
       "        4.57336025e-04, 4.57085020e-04, 4.99177806e-04, 4.98867529e-04,\n",
       "        4.86697213e-04, 3.99481374e-04, 4.49466364e-04, 3.98969654e-04,\n",
       "        2.99894501e-04, 4.57274094e-04, 4.99488653e-04, 4.88431671e-04,\n",
       "        4.57655942e-04, 3.08243787e-04, 4.57423812e-04, 4.88461030e-04,\n",
       "        4.88713998e-04, 4.88606837e-04, 3.01385249e-04, 4.84489622e-04,\n",
       "        4.41692538e-06, 4.56944532e-04, 3.95322446e-04, 4.88402449e-04,\n",
       "        4.57444636e-04, 3.70125167e-07, 2.99279613e-04, 4.88714068e-04]),\n",
       " 'mean_score_time': array([0.00252306, 0.00106728, 0.0023643 , 0.00120311, 0.00257511,\n",
       "        0.00117908, 0.00243602, 0.00126526, 0.00261459, 0.00110195,\n",
       "        0.00234973, 0.00122511, 0.00247576, 0.00099063, 0.00231967,\n",
       "        0.00130656, 0.0025461 , 0.00120039, 0.00299606, 0.00120022,\n",
       "        0.00279751, 0.00128789, 0.00289695, 0.00149276, 0.00268192,\n",
       "        0.00195954, 0.00252881, 0.00118635, 0.00269299, 0.00139782,\n",
       "        0.00236576, 0.0015815 , 0.00245302, 0.00149667, 0.00267577,\n",
       "        0.00143235, 0.00295362, 0.00130312, 0.0027956 , 0.00159016,\n",
       "        0.0026463 , 0.00129766, 0.00310302, 0.00166044, 0.00252614,\n",
       "        0.00140522, 0.00264702, 0.00139472, 0.00278316, 0.0015065 ,\n",
       "        0.00290616, 0.00161824, 0.00313795, 0.00154958, 0.00292161,\n",
       "        0.00138662, 0.00258186, 0.00161262, 0.00278628, 0.00157542,\n",
       "        0.00241239, 0.0010715 , 0.00249887, 0.00099182, 0.0028065 ,\n",
       "        0.0011977 , 0.00237603, 0.00109305, 0.00252566, 0.00112534,\n",
       "        0.00261359, 0.00106347, 0.00245967, 0.00128214, 0.00225656,\n",
       "        0.0011682 , 0.00250576, 0.00131335, 0.00254819, 0.00120158,\n",
       "        0.0026253 , 0.00117071, 0.00265477, 0.00140018, 0.00255253,\n",
       "        0.00128152, 0.00261755, 0.00133946, 0.00253484, 0.00131748,\n",
       "        0.00251749, 0.00142932, 0.00249197, 0.00120537, 0.00246894,\n",
       "        0.00139918, 0.00252233, 0.00145674, 0.002473  , 0.00135038,\n",
       "        0.00247669, 0.00125136, 0.00279088, 0.00146484, 0.00278728,\n",
       "        0.00141146, 0.00266917, 0.00155632, 0.00271671, 0.0013906 ,\n",
       "        0.00269344, 0.00135744, 0.00275857, 0.00136571, 0.0027354 ,\n",
       "        0.00130255, 0.0027369 , 0.00150185, 0.0026473 , 0.00149417,\n",
       "        0.0024442 , 0.00098634, 0.00239348, 0.0009959 , 0.00263643,\n",
       "        0.00109732, 0.00258443, 0.00111294, 0.00220129, 0.00110786,\n",
       "        0.0024164 , 0.00109766, 0.0025008 , 0.00101564, 0.00250657,\n",
       "        0.00110469, 0.00247333, 0.00121124, 0.00246158, 0.00132709,\n",
       "        0.00250452, 0.0013721 , 0.00253255, 0.00113323, 0.00259528,\n",
       "        0.00129306, 0.00290122, 0.00161684, 0.00307233, 0.00179341,\n",
       "        0.00300331, 0.00150328, 0.00285408, 0.00189784, 0.00295722,\n",
       "        0.00139418, 0.00281515, 0.0013943 , 0.00285001, 0.00651333,\n",
       "        0.00270951, 0.00140486, 0.00260003, 0.00139878, 0.00292053,\n",
       "        0.00160716, 0.00260661, 0.00149555, 0.00266047, 0.00154965,\n",
       "        0.00278463, 0.00129652, 0.00299935, 0.00137229, 0.00284929,\n",
       "        0.00152514, 0.00296354, 0.00159614, 0.00299995, 0.00149705,\n",
       "        0.00253727, 0.00120683, 0.00239334, 0.00099726, 0.00230091,\n",
       "        0.00109732, 0.00223022, 0.00116358, 0.00270023, 0.00118945,\n",
       "        0.00241675, 0.00100896, 0.00229185, 0.00112088, 0.00249789,\n",
       "        0.00111051, 0.00287952, 0.00123825, 0.00264695, 0.00120413,\n",
       "        0.00270498, 0.00109837, 0.00267003, 0.00129766, 0.00293713,\n",
       "        0.00129645, 0.0026962 , 0.0010973 , 0.00271776, 0.00129726,\n",
       "        0.00275295, 0.001192  , 0.00260184, 0.00118177, 0.00238955,\n",
       "        0.00124776, 0.00291011, 0.00136049, 0.00269263, 0.00131178,\n",
       "        0.00289345, 0.00129476, 0.00260882, 0.00130401, 0.00270309,\n",
       "        0.00129621, 0.00259283, 0.00139689, 0.00285411, 0.00135875,\n",
       "        0.00274117, 0.00132208, 0.00260274, 0.00140996, 0.00261335,\n",
       "        0.00145164, 0.00265164, 0.0015028 , 0.00270593, 0.00150173,\n",
       "        0.00228903, 0.00111184, 0.00231299, 0.00101266, 0.00239325,\n",
       "        0.00127318, 0.00232348, 0.00120261, 0.00242488, 0.00107324,\n",
       "        0.00292273, 0.00131531, 0.00267982, 0.00129585, 0.00252016,\n",
       "        0.00111327, 0.00279369, 0.00125027, 0.0028028 , 0.00126071,\n",
       "        0.00291026, 0.00115123, 0.0027662 , 0.00125055, 0.00279267,\n",
       "        0.00129678, 0.00285571, 0.00120628, 0.00264788, 0.00139706,\n",
       "        0.00269988, 0.001297  , 0.00260322, 0.00151651, 0.00260129,\n",
       "        0.00139658, 0.00300596, 0.00134785, 0.00300941, 0.00135   ,\n",
       "        0.00299234, 0.0014523 , 0.002495  , 0.00129738, 0.00264859,\n",
       "        0.00149627, 0.00284877, 0.00139656, 0.00280633, 0.00150554,\n",
       "        0.00244601, 0.00150714, 0.00261054, 0.00140629, 0.0025816 ,\n",
       "        0.00141065, 0.00260396, 0.00150254, 0.00265455, 0.00149302,\n",
       "        0.00259962, 0.00118713, 0.00229337, 0.00099716, 0.00230358,\n",
       "        0.00109398, 0.0023066 , 0.00106409, 0.00232251, 0.00110469,\n",
       "        0.00233471, 0.00120656, 0.00230985, 0.00118151, 0.00250404,\n",
       "        0.00125291, 0.00260057, 0.00109792, 0.0025327 , 0.00129299,\n",
       "        0.00290742, 0.00141129, 0.0024102 , 0.0011147 , 0.00239027,\n",
       "        0.00120821, 0.00251839, 0.00119705, 0.00240936, 0.0013941 ,\n",
       "        0.00249712, 0.00131209, 0.00249774, 0.00111766, 0.00259814,\n",
       "        0.00121639, 0.00265288, 0.00120699, 0.00270083, 0.00142329,\n",
       "        0.00260901, 0.00119448, 0.00315385, 0.00139709, 0.00282276,\n",
       "        0.00139687, 0.00284524, 0.00133293, 0.00289419, 0.00143065,\n",
       "        0.00297425, 0.00130763, 0.00257409, 0.00139954, 0.00262792,\n",
       "        0.00130236, 0.00261979, 0.00140226, 0.00261941, 0.00131891,\n",
       "        0.00234408, 0.00100706, 0.00289915, 0.00129995, 0.00260425,\n",
       "        0.00169721, 0.0040118 , 0.00145531, 0.00230484, 0.00116127,\n",
       "        0.00243723, 0.00106375, 0.00257211, 0.00110097, 0.00259321,\n",
       "        0.00110819, 0.00252397, 0.00129454, 0.00229585, 0.00130463,\n",
       "        0.00241239, 0.00119064, 0.00285773, 0.00119255, 0.00251508,\n",
       "        0.00140519, 0.00279317, 0.00130644, 0.00305531, 0.00099809,\n",
       "        0.00249436, 0.00135467, 0.00267799, 0.00139687, 0.00286613,\n",
       "        0.00152092, 0.00279374, 0.00149717, 0.00290055, 0.00129611,\n",
       "        0.00296407, 0.00149729, 0.00284767, 0.00128946, 0.00275915,\n",
       "        0.0016067 , 0.00315285, 0.00160389, 0.00296919, 0.00149682,\n",
       "        0.00300972, 0.0015136 , 0.00302486, 0.00160487, 0.00280714,\n",
       "        0.00152009, 0.0026171 , 0.00151329, 0.00260653, 0.00141726,\n",
       "        0.00230157, 0.00089746, 0.00244029, 0.0010973 , 0.00234907,\n",
       "        0.00108616, 0.0024929 , 0.00123067, 0.00228822, 0.00119677,\n",
       "        0.00239506, 0.00130358, 0.00224905, 0.00121007, 0.00248322,\n",
       "        0.00109091, 0.00260317, 0.00146472, 0.00303526, 0.00118148,\n",
       "        0.00251565, 0.00130317, 0.00259964, 0.00139608, 0.00244772,\n",
       "        0.00120339, 0.00266235, 0.0012964 , 0.00234656, 0.00122287,\n",
       "        0.00270724, 0.00130312, 0.00305898, 0.00119736, 0.0028481 ,\n",
       "        0.00161219, 0.00270884, 0.00145159, 0.00301476, 0.00152545,\n",
       "        0.00285168, 0.00134547, 0.00312359, 0.00139627, 0.00280056,\n",
       "        0.00135293, 0.00248556, 0.00144854, 0.00248268, 0.00120847,\n",
       "        0.00258524, 0.00129669, 0.00258045, 0.00145125, 0.00249319,\n",
       "        0.00133021, 0.00247285, 0.00121112, 0.00275667, 0.00139744,\n",
       "        0.00260434, 0.00110724, 0.00270858, 0.00107784, 0.00240576,\n",
       "        0.00108263, 0.002507  , 0.001214  , 0.00236971, 0.00110612,\n",
       "        0.00252869, 0.00156856, 0.00243475, 0.00130587, 0.00249808,\n",
       "        0.00120161, 0.0024615 , 0.00114093, 0.00250018, 0.00130405,\n",
       "        0.00291998, 0.00119915, 0.00288763, 0.00130637, 0.00249219,\n",
       "        0.00149786, 0.0028935 , 0.00122471, 0.00262668, 0.00139215,\n",
       "        0.00256815, 0.00141201, 0.00245922, 0.00140476, 0.00278032,\n",
       "        0.00160084, 0.00261397, 0.00126362, 0.00259907, 0.00132372,\n",
       "        0.00258107, 0.0012826 , 0.00247872, 0.0013458 , 0.00264807,\n",
       "        0.00119693, 0.00286171, 0.00150843, 0.00240519, 0.0016557 ,\n",
       "        0.00304585, 0.00169508, 0.00304322, 0.00139654, 0.0024632 ,\n",
       "        0.00131655, 0.00284369, 0.00130761, 0.00280385, 0.00160487,\n",
       "        0.00426764, 0.00133927, 0.00403264, 0.00176387, 0.00402429,\n",
       "        0.00169604, 0.00413227, 0.00184634, 0.00468688, 0.00139713,\n",
       "        0.00449216, 0.0019084 , 0.00392876, 0.00183058, 0.00429721,\n",
       "        0.00199656, 0.00318036, 0.00151622, 0.00436907, 0.00139639,\n",
       "        0.00406468, 0.00189888, 0.00430164, 0.00219436, 0.00350308,\n",
       "        0.00144286, 0.00332947, 0.00109508, 0.00296388, 0.0013963 ,\n",
       "        0.00323176, 0.00109665, 0.00357513, 0.00135968, 0.00369749,\n",
       "        0.00160728, 0.00329838, 0.00129678, 0.00369012, 0.00115592,\n",
       "        0.00304956, 0.00145111, 0.00367765, 0.0014976 , 0.00369477,\n",
       "        0.00129662, 0.00335813, 0.00136671, 0.00371335, 0.00137322,\n",
       "        0.00323994, 0.00172145, 0.00279102, 0.00179532, 0.00360956,\n",
       "        0.00198021, 0.00331745, 0.00109713, 0.00389888, 0.00141184,\n",
       "        0.00318666, 0.00135105, 0.00309217, 0.0011755 , 0.00361726,\n",
       "        0.00129654, 0.00262885, 0.00099661, 0.00227804, 0.00100341,\n",
       "        0.00232031, 0.001021  , 0.00212235, 0.00110106, 0.0023519 ,\n",
       "        0.0010077 , 0.0021868 , 0.00101008, 0.00203357, 0.00099335,\n",
       "        0.00260367, 0.00102184, 0.00240145, 0.00101755, 0.00258904,\n",
       "        0.00099413, 0.00210192, 0.00110028, 0.00227208, 0.00101492,\n",
       "        0.00250912, 0.00099616, 0.00210621, 0.00108154, 0.0023684 ,\n",
       "        0.00099626, 0.00203669, 0.00098574, 0.00231419, 0.00128107,\n",
       "        0.00281138, 0.00105674, 0.00266523, 0.00120103, 0.00210094,\n",
       "        0.00110044, 0.00210593, 0.00099406, 0.0027189 , 0.00099463,\n",
       "        0.00244603, 0.00140274, 0.00265493, 0.0011579 , 0.00253685,\n",
       "        0.00131333, 0.00280752, 0.00099752, 0.00241096, 0.00099814,\n",
       "        0.00249345, 0.00089836, 0.00335655, 0.00074778, 0.00330532,\n",
       "        0.00139649, 0.00329199, 0.00120621, 0.00319219, 0.00159645,\n",
       "        0.00289207, 0.00139625, 0.00340466, 0.00149639, 0.00291796,\n",
       "        0.00137415, 0.0030437 , 0.00148621, 0.00299184, 0.00149598,\n",
       "        0.00351202, 0.00119672, 0.00316799, 0.00129521, 0.00374296,\n",
       "        0.00146823, 0.00317502, 0.0016957 , 0.00302029, 0.00147853,\n",
       "        0.00339134, 0.00152354, 0.00309172, 0.00149808, 0.00306478,\n",
       "        0.00159609, 0.0031565 , 0.00139663, 0.00358896, 0.00134487,\n",
       "        0.00364506, 0.00129662, 0.00314362, 0.00184379, 0.00333509,\n",
       "        0.00152462, 0.0031961 , 0.0014961 , 0.00340717, 0.00171285,\n",
       "        0.00334146, 0.00160182, 0.00361254, 0.00119867, 0.00340064,\n",
       "        0.00189519, 0.00340958, 0.00159614, 0.0032912 , 0.00146046]),\n",
       " 'std_score_time': array([4.57846381e-04, 2.12967087e-04, 4.59322711e-04, 4.02894213e-04,\n",
       "        4.85880145e-04, 4.79966057e-04, 4.96018451e-04, 4.14566822e-04,\n",
       "        5.02287531e-04, 2.98534726e-04, 4.54078750e-04, 3.86743439e-04,\n",
       "        5.05839192e-04, 2.93233530e-05, 4.12838719e-04, 5.04566884e-04,\n",
       "        5.54237538e-04, 4.06302011e-04, 7.73239959e-04, 3.97882586e-04,\n",
       "        4.89742569e-04, 4.55225459e-04, 5.82496425e-04, 5.01274611e-04,\n",
       "        3.81215127e-04, 1.14717915e-03, 5.35856576e-04, 4.06530783e-04,\n",
       "        4.57779874e-04, 4.90054324e-04, 5.15031482e-04, 4.86587088e-04,\n",
       "        4.74767940e-04, 4.99276743e-04, 4.47240541e-04, 4.52194599e-04,\n",
       "        4.69839078e-04, 4.80399617e-04, 3.88401899e-04, 4.96239510e-04,\n",
       "        4.35868656e-04, 4.44053100e-04, 4.79147286e-04, 4.45897642e-04,\n",
       "        4.70754695e-04, 4.76835018e-04, 4.39244951e-04, 4.78266463e-04,\n",
       "        3.95507409e-04, 5.06268950e-04, 3.15681956e-04, 4.60170491e-04,\n",
       "        6.34094310e-04, 4.78346548e-04, 1.68668581e-04, 4.25035862e-04,\n",
       "        5.25017227e-04, 4.93923189e-04, 5.92364337e-04, 4.65764651e-04,\n",
       "        4.78594475e-04, 3.27254471e-04, 5.06807647e-04, 1.33833334e-05,\n",
       "        1.17363590e-03, 4.04858297e-04, 4.65972749e-04, 3.01082477e-04,\n",
       "        5.94173016e-04, 3.04787228e-04, 4.47323754e-04, 3.38378700e-04,\n",
       "        4.65414761e-04, 4.25015060e-04, 4.80706656e-04, 3.63636433e-04,\n",
       "        4.47736399e-04, 4.55776177e-04, 4.65698555e-04, 3.99019257e-04,\n",
       "        5.15140768e-04, 3.16381114e-04, 6.28214483e-04, 6.59480234e-04,\n",
       "        4.75853387e-04, 4.66704286e-04, 4.22776323e-04, 4.62119548e-04,\n",
       "        4.09455829e-04, 4.52194428e-04, 4.52395902e-04, 5.21759121e-04,\n",
       "        5.95687028e-04, 3.98622632e-04, 4.90393511e-04, 4.75419503e-04,\n",
       "        4.86604449e-04, 4.70059071e-04, 6.60747843e-04, 4.46081970e-04,\n",
       "        4.24416305e-04, 3.99471894e-04, 5.96308839e-04, 4.63573571e-04,\n",
       "        3.97666767e-04, 4.94017362e-04, 4.44526924e-04, 4.76367768e-04,\n",
       "        4.94112046e-04, 4.85900740e-04, 3.84888062e-04, 4.65507831e-04,\n",
       "        4.14347031e-04, 4.49674718e-04, 3.98565793e-04, 4.51269074e-04,\n",
       "        4.41930895e-04, 5.01146947e-04, 4.38615132e-04, 4.83736761e-04,\n",
       "        6.69504655e-04, 3.32996593e-05, 4.88470609e-04, 3.27536195e-05,\n",
       "        4.58878746e-04, 2.99097628e-04, 4.81754559e-04, 2.97799923e-04,\n",
       "        3.99323739e-04, 3.02672608e-04, 5.04010002e-04, 3.08806375e-04,\n",
       "        4.77811515e-04, 3.14398902e-05, 5.22564034e-04, 3.08661230e-04,\n",
       "        4.78255243e-04, 4.02677758e-04, 4.76702864e-04, 4.43846968e-04,\n",
       "        4.97603725e-04, 5.06267108e-04, 5.48510086e-04, 2.97251627e-04,\n",
       "        4.88012562e-04, 4.56993718e-04, 5.52852312e-04, 4.61254817e-04,\n",
       "        2.72142940e-04, 3.97767363e-04, 4.63696616e-05, 5.05450692e-04,\n",
       "        5.13790029e-04, 5.30861209e-04, 5.63680137e-04, 4.99836840e-04,\n",
       "        6.08599644e-04, 4.86243554e-04, 3.18731753e-04, 1.58873424e-02,\n",
       "        4.69265490e-04, 4.80558137e-04, 4.88677251e-04, 4.95444184e-04,\n",
       "        5.51898042e-04, 4.88859625e-04, 6.54657482e-04, 4.98295535e-04,\n",
       "        4.62459748e-04, 4.71305110e-04, 3.94973075e-04, 4.56955066e-04,\n",
       "        2.10691889e-05, 4.63450356e-04, 6.45482555e-04, 5.30236128e-04,\n",
       "        4.55437739e-04, 4.89047280e-04, 2.35800796e-05, 4.98847022e-04,\n",
       "        4.90869109e-04, 5.95860660e-04, 4.88636132e-04, 2.33601546e-07,\n",
       "        4.98898224e-04, 2.99176127e-04, 4.37289544e-04, 3.15003138e-04,\n",
       "        4.47045469e-04, 3.25055565e-04, 4.84717205e-04, 2.20055182e-05,\n",
       "        4.75741380e-04, 3.04762125e-04, 4.95000339e-04, 2.97576031e-04,\n",
       "        3.11438264e-04, 4.24273886e-04, 4.45709087e-04, 3.95815661e-04,\n",
       "        6.28377531e-04, 2.98751902e-04, 4.54912189e-04, 4.57353828e-04,\n",
       "        3.27762369e-04, 4.57157850e-04, 4.58567344e-04, 2.99187355e-04,\n",
       "        4.76567424e-04, 4.57305971e-04, 3.88307079e-04, 4.07753631e-04,\n",
       "        4.87550563e-04, 3.55735717e-04, 4.76771902e-04, 4.02895207e-04,\n",
       "        3.07077937e-04, 4.42369493e-04, 4.57012311e-04, 4.68820404e-04,\n",
       "        2.99698603e-04, 4.50734548e-04, 4.98703953e-04, 4.57504967e-04,\n",
       "        4.64961272e-04, 4.57057881e-04, 4.88538884e-04, 4.88764612e-04,\n",
       "        4.58306907e-04, 4.58272115e-04, 4.13753186e-04, 4.58015963e-04,\n",
       "        5.16616247e-04, 4.78753041e-04, 4.63480503e-04, 4.75785851e-04,\n",
       "        5.45772716e-04, 6.73002396e-04, 4.55575175e-04, 5.08907884e-04,\n",
       "        4.71987289e-04, 3.02311904e-04, 4.45134105e-04, 1.53209493e-05,\n",
       "        4.85458202e-04, 4.88510784e-04, 4.90759128e-04, 3.96347055e-04,\n",
       "        4.71536826e-04, 3.18498065e-04, 5.24887735e-04, 4.48728149e-04,\n",
       "        4.63591608e-04, 4.57664280e-04, 5.26592175e-04, 2.97728015e-04,\n",
       "        3.98533884e-04, 4.04378546e-04, 3.80232844e-04, 3.98386399e-04,\n",
       "        3.09763402e-04, 4.42922460e-04, 5.27424201e-04, 4.04310896e-04,\n",
       "        3.99030871e-04, 4.56733120e-04, 4.34734820e-04, 4.51644254e-04,\n",
       "        5.55871330e-04, 4.88628441e-04, 6.08088242e-04, 4.57737284e-04,\n",
       "        4.96876812e-04, 4.98823657e-04, 4.78781755e-04, 4.88141090e-04,\n",
       "        2.91447478e-05, 4.49278820e-04, 2.31635354e-04, 4.50952643e-04,\n",
       "        1.65112397e-06, 4.71008514e-04, 4.98729313e-04, 4.57590937e-04,\n",
       "        5.55888703e-04, 4.98867172e-04, 3.13969682e-04, 4.88256572e-04,\n",
       "        3.82779558e-04, 4.87639194e-04, 4.81381554e-04, 5.08130138e-04,\n",
       "        4.76156371e-04, 4.89039610e-04, 4.36778698e-04, 4.83322118e-04,\n",
       "        5.03971117e-04, 4.92833861e-04, 6.38170072e-04, 4.98163886e-04,\n",
       "        4.87657322e-04, 4.28649432e-04, 4.58368699e-04, 2.10223005e-05,\n",
       "        4.56452285e-04, 2.89648868e-04, 4.42975743e-04, 3.16707750e-04,\n",
       "        4.80671889e-04, 2.88312189e-04, 4.41832114e-04, 3.97072570e-04,\n",
       "        4.48258985e-04, 4.04103740e-04, 4.97100634e-04, 4.06889724e-04,\n",
       "        4.94074669e-04, 2.98901656e-04, 5.50077364e-04, 4.51621492e-04,\n",
       "        3.18906239e-04, 4.73651019e-04, 5.02026861e-04, 2.95352108e-04,\n",
       "        4.91972960e-04, 3.86232479e-04, 5.11794005e-04, 4.05355392e-04,\n",
       "        4.89906523e-04, 4.86530076e-04, 5.01524745e-04, 4.73520691e-04,\n",
       "        5.00983419e-04, 2.98839078e-04, 4.85902577e-04, 4.47266207e-04,\n",
       "        4.57893467e-04, 3.95196933e-04, 4.63049177e-04, 4.81986342e-04,\n",
       "        5.09107145e-04, 3.92255170e-04, 4.89209616e-04, 4.89485093e-04,\n",
       "        3.47550234e-04, 4.35706968e-04, 3.18111249e-04, 4.45894593e-04,\n",
       "        3.01039754e-04, 4.71061673e-04, 7.91745312e-05, 4.75714915e-04,\n",
       "        4.70726729e-04, 4.86554090e-04, 5.12758930e-04, 4.48711674e-04,\n",
       "        4.46699090e-04, 4.93861458e-04, 4.74194550e-04, 4.90702477e-04,\n",
       "        4.87871433e-04, 1.61441070e-05, 5.56616852e-04, 4.65266685e-04,\n",
       "        4.75866331e-04, 8.97088810e-04, 1.59420176e-03, 5.67909412e-04,\n",
       "        4.72408697e-04, 3.40765180e-04, 5.13703370e-04, 1.69270880e-04,\n",
       "        4.59993870e-04, 3.08913458e-04, 5.36357937e-04, 2.84966009e-04,\n",
       "        4.77134636e-04, 4.57207459e-04, 5.10917066e-04, 4.59246234e-04,\n",
       "        4.76431997e-04, 4.02290804e-04, 3.25722709e-04, 4.02546856e-04,\n",
       "        5.23223888e-04, 4.99540656e-04, 3.98269073e-04, 4.72841295e-04,\n",
       "        1.62917730e-04, 1.88953305e-06, 4.98704713e-04, 4.60455024e-04,\n",
       "        4.10258759e-04, 4.89026606e-04, 5.54473090e-04, 4.92706433e-04,\n",
       "        3.99450572e-04, 4.99203326e-04, 1.83346423e-04, 4.56028247e-04,\n",
       "        3.77422843e-04, 4.97380614e-04, 5.52862170e-04, 4.64253139e-04,\n",
       "        3.95555091e-04, 5.00432351e-04, 5.53680899e-04, 5.01061280e-04,\n",
       "        3.78815057e-04, 4.98559455e-04, 3.56540696e-05, 5.17517491e-04,\n",
       "        1.05974513e-04, 4.78001651e-04, 3.22100959e-04, 5.23991882e-04,\n",
       "        4.76108620e-04, 4.86765297e-04, 4.80814631e-04, 4.95286101e-04,\n",
       "        4.59743891e-04, 2.99151855e-04, 4.64688478e-04, 2.99105343e-04,\n",
       "        4.51109450e-04, 2.66258202e-04, 4.98580987e-04, 3.93802598e-04,\n",
       "        4.60507090e-04, 3.98862386e-04, 4.87208377e-04, 4.53008114e-04,\n",
       "        4.05793756e-04, 4.26582999e-04, 4.89555792e-04, 3.01969460e-04,\n",
       "        4.98152001e-04, 4.75831739e-04, 3.45314573e-04, 3.69983099e-04,\n",
       "        4.80255027e-04, 4.52923599e-04, 4.80400339e-04, 4.88499785e-04,\n",
       "        4.71129135e-04, 3.96422239e-04, 4.61470391e-04, 4.57137025e-04,\n",
       "        4.49870093e-04, 3.97865585e-04, 4.61182136e-04, 4.52134080e-04,\n",
       "        5.62985622e-04, 3.98864228e-04, 4.56139953e-04, 5.03671197e-04,\n",
       "        4.67745621e-04, 4.71079882e-04, 7.25982655e-05, 4.77233017e-04,\n",
       "        3.20459295e-04, 5.45442977e-04, 2.95618542e-04, 4.88830749e-04,\n",
       "        4.03602309e-04, 4.54915722e-04, 4.91398550e-04, 4.70767928e-04,\n",
       "        4.89209937e-04, 3.94651488e-04, 4.98057257e-04, 4.56690325e-04,\n",
       "        5.04359318e-04, 4.71239698e-04, 4.86261923e-04, 4.47941167e-04,\n",
       "        4.50135167e-04, 3.93312993e-04, 3.75343347e-04, 4.89144487e-04,\n",
       "        4.76508125e-04, 2.96309627e-04, 7.60751076e-04, 3.12291951e-04,\n",
       "        4.69235254e-04, 2.78935054e-04, 4.82560446e-04, 4.25655193e-04,\n",
       "        4.38486421e-04, 2.96518268e-04, 6.84580417e-04, 4.66718141e-04,\n",
       "        4.66210940e-04, 4.59930744e-04, 5.03457557e-04, 3.99814798e-04,\n",
       "        4.63763790e-04, 4.62516905e-04, 4.91711893e-04, 4.45992236e-04,\n",
       "        2.70189438e-04, 3.98530076e-04, 5.40253072e-04, 4.72462122e-04,\n",
       "        5.00926479e-04, 5.02722388e-04, 5.04214844e-04, 4.50378916e-04,\n",
       "        5.00809067e-04, 4.83673190e-04, 4.77544751e-04, 4.68511960e-04,\n",
       "        4.69782573e-04, 6.53127783e-04, 3.96667305e-04, 4.84564599e-04,\n",
       "        4.50892585e-04, 4.98120663e-04, 4.89914875e-04, 4.78420067e-04,\n",
       "        4.81762020e-04, 4.10983028e-04, 4.90876633e-04, 4.42642364e-04,\n",
       "        4.47189518e-04, 3.98779774e-04, 9.54449181e-04, 5.02948215e-04,\n",
       "        4.80671634e-04, 6.34082459e-04, 6.51172512e-04, 4.56201950e-04,\n",
       "        3.44295115e-04, 4.89157261e-04, 4.89232963e-04, 4.47258105e-04,\n",
       "        4.42139500e-04, 4.66133264e-04, 3.79930846e-04, 4.89509842e-04,\n",
       "        7.77053464e-04, 4.46861412e-04, 9.74933606e-04, 5.40399846e-04,\n",
       "        9.01628865e-04, 6.39028324e-04, 7.04890930e-04, 4.51930369e-04,\n",
       "        6.38525130e-04, 4.89250122e-04, 8.14764748e-04, 3.51129026e-04,\n",
       "        4.25068463e-04, 4.27726346e-04, 4.88459936e-04, 6.28160375e-04,\n",
       "        7.36533541e-04, 6.86425484e-04, 8.32527123e-04, 4.87958713e-04,\n",
       "        4.73258096e-04, 5.42441338e-04, 1.17090031e-03, 3.99148161e-04,\n",
       "        8.18352336e-04, 4.67513080e-04, 6.44931827e-04, 2.99910169e-04,\n",
       "        7.64873811e-04, 4.88422037e-04, 7.49634603e-04, 2.99833333e-04,\n",
       "        6.73561111e-04, 4.54702504e-04, 4.46073404e-04, 4.98712198e-04,\n",
       "        6.41027909e-04, 4.57200141e-04, 7.79567734e-04, 3.23161588e-04,\n",
       "        5.81623302e-04, 4.70831895e-04, 6.33681912e-04, 4.98062315e-04,\n",
       "        6.04485367e-04, 4.56684838e-04, 7.01251614e-04, 5.01190834e-04,\n",
       "        9.24706282e-04, 4.64636108e-04, 1.01059842e-03, 4.72825761e-04,\n",
       "        7.45141492e-04, 3.98946464e-04, 6.45932925e-04, 4.34427438e-05,\n",
       "        8.05687959e-04, 2.99641242e-04, 6.99401887e-04, 4.77662767e-04,\n",
       "        8.66950034e-04, 5.42365901e-04, 5.36968738e-04, 6.09221364e-04,\n",
       "        6.62411022e-04, 4.56939361e-04, 4.89468626e-04, 2.52419865e-06,\n",
       "        4.11265923e-04, 1.36720947e-05, 4.42636320e-04, 5.44106719e-05,\n",
       "        3.06086482e-04, 3.11342748e-04, 4.53173856e-04, 1.54289061e-05,\n",
       "        3.95225400e-04, 3.98737094e-05, 1.31300218e-04, 1.79144871e-05,\n",
       "        4.93437294e-04, 6.66969274e-05, 4.94645529e-04, 4.27117352e-05,\n",
       "        5.28782576e-04, 1.80327211e-05, 3.11010205e-04, 2.87851538e-04,\n",
       "        3.97266710e-04, 4.27771635e-05, 5.12037123e-04, 2.71892949e-05,\n",
       "        2.97424162e-04, 3.10374622e-04, 5.21425137e-04, 1.55832397e-05,\n",
       "        1.06974580e-04, 6.32851344e-05, 4.52612153e-04, 4.41445437e-04,\n",
       "        4.09458527e-04, 1.67617555e-04, 7.07857444e-04, 3.88319114e-04,\n",
       "        2.98955356e-04, 3.01744652e-04, 2.95997784e-04, 1.06779588e-05,\n",
       "        4.52671933e-04, 3.99048389e-04, 4.67962144e-04, 4.95991336e-04,\n",
       "        4.46522880e-04, 3.29859117e-04, 5.14994959e-04, 5.10610560e-04,\n",
       "        4.62147651e-04, 1.34215049e-06, 4.41041314e-04, 1.44336804e-06,\n",
       "        6.69155364e-04, 5.37566468e-04, 4.62723208e-04, 4.00913587e-04,\n",
       "        6.04118621e-04, 4.88364469e-04, 6.38771200e-04, 3.91069948e-04,\n",
       "        7.45907170e-04, 4.88862852e-04, 6.98266899e-04, 4.88606954e-04,\n",
       "        6.60882925e-04, 4.98176634e-04, 9.73053911e-04, 5.10783751e-04,\n",
       "        7.19005972e-04, 4.88980245e-04, 6.30864679e-04, 4.98676407e-04,\n",
       "        7.66074521e-04, 3.98886285e-04, 4.16647463e-04, 4.57671291e-04,\n",
       "        8.06982578e-04, 5.32273072e-04, 7.29311530e-04, 4.57210915e-04,\n",
       "        8.12411957e-04, 4.83930450e-04, 4.88462068e-04, 4.77344348e-04,\n",
       "        8.28759855e-04, 5.00805614e-04, 5.58990673e-04, 4.88715359e-04,\n",
       "        6.03167125e-04, 4.88247494e-04, 8.03699367e-04, 4.47720546e-04,\n",
       "        7.12679453e-04, 4.56788958e-04, 5.51038671e-04, 3.21269884e-04,\n",
       "        7.80533717e-04, 5.33268359e-04, 8.68673512e-04, 4.98461951e-04,\n",
       "        6.53799538e-04, 4.71065179e-04, 7.77397159e-04, 4.94161341e-04,\n",
       "        6.42809673e-04, 3.97937039e-04, 6.55844227e-04, 2.99136030e-04,\n",
       "        6.52128047e-04, 4.88851074e-04, 5.99630728e-04, 4.73296013e-04]),\n",
       " 'param_algorithm': masked_array(data=['auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'ball_tree',\n",
       "                    'ball_tree', 'ball_tree', 'ball_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree',\n",
       "                    'kd_tree', 'kd_tree', 'kd_tree', 'kd_tree', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute', 'brute',\n",
       "                    'brute', 'brute', 'brute', 'brute', 'brute'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_metric': masked_array(data=['euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'euclidean', 'euclidean', 'euclidean', 'euclidean',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'manhattan', 'manhattan', 'manhattan', 'manhattan',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski',\n",
       "                    'minkowski', 'minkowski', 'minkowski', 'minkowski'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_neighbors': masked_array(data=[1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9,\n",
       "                    10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16,\n",
       "                    17, 17, 18, 18, 19, 19, 20, 20, 21, 21, 22, 22, 23, 23,\n",
       "                    24, 24, 25, 25, 26, 26, 27, 27, 28, 28, 29, 29, 30, 30,\n",
       "                    1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9,\n",
       "                    10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16,\n",
       "                    17, 17, 18, 18, 19, 19, 20, 20, 21, 21, 22, 22, 23, 23,\n",
       "                    24, 24, 25, 25, 26, 26, 27, 27, 28, 28, 29, 29, 30, 30,\n",
       "                    1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9,\n",
       "                    10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16,\n",
       "                    17, 17, 18, 18, 19, 19, 20, 20, 21, 21, 22, 22, 23, 23,\n",
       "                    24, 24, 25, 25, 26, 26, 27, 27, 28, 28, 29, 29, 30, 30,\n",
       "                    1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9,\n",
       "                    10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16,\n",
       "                    17, 17, 18, 18, 19, 19, 20, 20, 21, 21, 22, 22, 23, 23,\n",
       "                    24, 24, 25, 25, 26, 26, 27, 27, 28, 28, 29, 29, 30, 30,\n",
       "                    1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9,\n",
       "                    10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16,\n",
       "                    17, 17, 18, 18, 19, 19, 20, 20, 21, 21, 22, 22, 23, 23,\n",
       "                    24, 24, 25, 25, 26, 26, 27, 27, 28, 28, 29, 29, 30, 30,\n",
       "                    1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9,\n",
       "                    10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16,\n",
       "                    17, 17, 18, 18, 19, 19, 20, 20, 21, 21, 22, 22, 23, 23,\n",
       "                    24, 24, 25, 25, 26, 26, 27, 27, 28, 28, 29, 29, 30, 30,\n",
       "                    1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9,\n",
       "                    10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16,\n",
       "                    17, 17, 18, 18, 19, 19, 20, 20, 21, 21, 22, 22, 23, 23,\n",
       "                    24, 24, 25, 25, 26, 26, 27, 27, 28, 28, 29, 29, 30, 30,\n",
       "                    1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9,\n",
       "                    10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16,\n",
       "                    17, 17, 18, 18, 19, 19, 20, 20, 21, 21, 22, 22, 23, 23,\n",
       "                    24, 24, 25, 25, 26, 26, 27, 27, 28, 28, 29, 29, 30, 30,\n",
       "                    1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9,\n",
       "                    10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16,\n",
       "                    17, 17, 18, 18, 19, 19, 20, 20, 21, 21, 22, 22, 23, 23,\n",
       "                    24, 24, 25, 25, 26, 26, 27, 27, 28, 28, 29, 29, 30, 30,\n",
       "                    1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9,\n",
       "                    10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16,\n",
       "                    17, 17, 18, 18, 19, 19, 20, 20, 21, 21, 22, 22, 23, 23,\n",
       "                    24, 24, 25, 25, 26, 26, 27, 27, 28, 28, 29, 29, 30, 30,\n",
       "                    1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9,\n",
       "                    10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16,\n",
       "                    17, 17, 18, 18, 19, 19, 20, 20, 21, 21, 22, 22, 23, 23,\n",
       "                    24, 24, 25, 25, 26, 26, 27, 27, 28, 28, 29, 29, 30, 30,\n",
       "                    1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9,\n",
       "                    10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 15, 15, 16, 16,\n",
       "                    17, 17, 18, 18, 19, 19, 20, 20, 21, 21, 22, 22, 23, 23,\n",
       "                    24, 24, 25, 25, 26, 26, 27, 27, 28, 28, 29, 29, 30, 30],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_weights': masked_array(data=['uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance',\n",
       "                    'uniform', 'distance', 'uniform', 'distance'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 2,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 2,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 3,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 3,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 11,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 11,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 12,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 12,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 13,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 13,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 14,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 14,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 15,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 15,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 16,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 16,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 17,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 17,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 18,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 18,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 19,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 19,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 20,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 20,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 21,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 21,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 22,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 22,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 23,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 23,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 24,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 24,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 25,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 25,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 26,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 26,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 27,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 27,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 28,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 28,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 29,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 29,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 30,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 30,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 2,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 2,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 3,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 3,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 11,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 11,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 12,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 12,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 13,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 13,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 14,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 14,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 15,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 15,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 16,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 16,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 17,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 17,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 18,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 18,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 19,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 19,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 20,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 20,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 21,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 21,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 22,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 22,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 23,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 23,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 24,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 24,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 25,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 25,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 26,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 26,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 27,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 27,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 28,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 28,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 29,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 29,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 30,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 30,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 2,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 2,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 3,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 3,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 11,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 11,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 12,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 12,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 13,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 13,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 14,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 14,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 15,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 15,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 16,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 16,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 17,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 17,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 18,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 18,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 19,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 19,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 20,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 20,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 21,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 21,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 22,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 22,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 23,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 23,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 24,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 24,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 25,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 25,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 26,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 26,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 27,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 27,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 28,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 28,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 29,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 29,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 30,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'auto',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 30,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 2,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 2,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 3,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 3,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 11,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 11,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 12,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 12,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 13,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 13,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 14,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 14,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 15,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 15,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 16,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 16,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 17,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 17,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 18,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 18,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 19,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 19,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 20,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 20,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 21,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 21,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 22,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 22,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 23,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 23,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 24,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 24,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 25,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 25,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 26,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 26,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 27,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 27,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 28,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 28,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 29,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 29,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 30,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 30,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 2,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 2,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 3,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 3,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 11,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 11,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 12,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 12,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 13,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 13,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 14,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 14,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 15,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 15,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 16,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 16,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 17,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 17,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 18,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 18,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 19,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 19,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 20,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 20,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 21,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 21,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 22,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 22,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 23,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 23,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 24,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 24,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 25,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 25,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 26,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 26,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 27,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 27,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 28,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 28,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 29,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 29,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 30,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 30,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 2,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 2,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 3,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 3,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 11,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 11,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 12,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 12,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 13,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 13,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 14,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 14,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 15,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 15,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 16,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 16,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 17,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 17,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 18,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 18,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 19,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 19,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 20,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 20,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 21,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 21,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 22,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 22,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 23,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 23,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 24,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 24,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 25,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 25,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 26,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 26,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 27,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 27,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 28,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 28,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 29,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 29,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 30,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'ball_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 30,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 2,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 2,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 3,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 3,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 11,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 11,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 12,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 12,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 13,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 13,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 14,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 14,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 15,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 15,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 16,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 16,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 17,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 17,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 18,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 18,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 19,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 19,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 20,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 20,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 21,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 21,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 22,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 22,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 23,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 23,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 24,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 24,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 25,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 25,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 26,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 26,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 27,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 27,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 28,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 28,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 29,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 29,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 30,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 30,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 2,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 2,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 3,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 3,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 11,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 11,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 12,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 12,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 13,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 13,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 14,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 14,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 15,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 15,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 16,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 16,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 17,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 17,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 18,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 18,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 19,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 19,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 20,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 20,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 21,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 21,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 22,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 22,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 23,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 23,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 24,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 24,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 25,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 25,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 26,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 26,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 27,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 27,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 28,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 28,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 29,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 29,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 30,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 30,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 2,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 2,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 3,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 3,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 11,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 11,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 12,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 12,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 13,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 13,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 14,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 14,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 15,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 15,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 16,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 16,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 17,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 17,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 18,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 18,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 19,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 19,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 20,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 20,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 21,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 21,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 22,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 22,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 23,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 23,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 24,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 24,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 25,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 25,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 26,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 26,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 27,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 27,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 28,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 28,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 29,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 29,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 30,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'kd_tree',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 30,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 2,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 2,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 3,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 3,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 11,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 11,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 12,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 12,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 13,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 13,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 14,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 14,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 15,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 15,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 16,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 16,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 17,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 17,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 18,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 18,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 19,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 19,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 20,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 20,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 21,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 21,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 22,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 22,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 23,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 23,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 24,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 24,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 25,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 25,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 26,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 26,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 27,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 27,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 28,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 28,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 29,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 29,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 30,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'euclidean',\n",
       "   'n_neighbors': 30,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 2,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 2,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 3,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 3,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 11,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 11,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 12,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 12,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 13,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 13,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 14,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 14,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 15,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 15,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 16,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 16,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 17,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 17,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 18,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 18,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 19,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 19,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 20,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 20,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 21,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 21,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 22,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 22,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 23,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 23,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 24,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 24,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 25,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 25,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 26,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 26,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 27,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 27,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 28,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 28,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 29,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 29,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 30,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'manhattan',\n",
       "   'n_neighbors': 30,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 1,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 2,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 2,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 3,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 3,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 4,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 5,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 6,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 7,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 8,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 9,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 10,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 11,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 11,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 12,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 12,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 13,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 13,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 14,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 14,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 15,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 15,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 16,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 16,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 17,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 17,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 18,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 18,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 19,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 19,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 20,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 20,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 21,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 21,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 22,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 22,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 23,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 23,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 24,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 24,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 25,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 25,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 26,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 26,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 27,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 27,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 28,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 28,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 29,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 29,\n",
       "   'weights': 'distance'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 30,\n",
       "   'weights': 'uniform'},\n",
       "  {'algorithm': 'brute',\n",
       "   'metric': 'minkowski',\n",
       "   'n_neighbors': 30,\n",
       "   'weights': 'distance'}],\n",
       " 'split0_test_score': array([0.58064516, 0.58064516, 0.59677419, 0.58064516, 0.62903226,\n",
       "        0.62903226, 0.66129032, 0.61290323, 0.67741935, 0.67741935,\n",
       "        0.62903226, 0.67741935, 0.67741935, 0.67741935, 0.64516129,\n",
       "        0.67741935, 0.67741935, 0.67741935, 0.67741935, 0.66129032,\n",
       "        0.64516129, 0.64516129, 0.64516129, 0.66129032, 0.62903226,\n",
       "        0.62903226, 0.64516129, 0.64516129, 0.67741935, 0.67741935,\n",
       "        0.67741935, 0.67741935, 0.70967742, 0.70967742, 0.69354839,\n",
       "        0.70967742, 0.70967742, 0.70967742, 0.67741935, 0.69354839,\n",
       "        0.70967742, 0.70967742, 0.69354839, 0.70967742, 0.70967742,\n",
       "        0.70967742, 0.70967742, 0.70967742, 0.70967742, 0.70967742,\n",
       "        0.70967742, 0.70967742, 0.69354839, 0.72580645, 0.70967742,\n",
       "        0.70967742, 0.69354839, 0.72580645, 0.70967742, 0.69354839,\n",
       "        0.58064516, 0.58064516, 0.56451613, 0.58064516, 0.61290323,\n",
       "        0.61290323, 0.62903226, 0.61290323, 0.66129032, 0.66129032,\n",
       "        0.69354839, 0.62903226, 0.67741935, 0.67741935, 0.67741935,\n",
       "        0.67741935, 0.64516129, 0.64516129, 0.64516129, 0.64516129,\n",
       "        0.64516129, 0.66129032, 0.62903226, 0.64516129, 0.64516129,\n",
       "        0.66129032, 0.66129032, 0.64516129, 0.66129032, 0.66129032,\n",
       "        0.64516129, 0.64516129, 0.66129032, 0.67741935, 0.62903226,\n",
       "        0.67741935, 0.64516129, 0.66129032, 0.67741935, 0.66129032,\n",
       "        0.66129032, 0.66129032, 0.62903226, 0.66129032, 0.62903226,\n",
       "        0.64516129, 0.64516129, 0.64516129, 0.66129032, 0.66129032,\n",
       "        0.66129032, 0.67741935, 0.69354839, 0.67741935, 0.67741935,\n",
       "        0.69354839, 0.66129032, 0.67741935, 0.67741935, 0.67741935,\n",
       "        0.58064516, 0.58064516, 0.59677419, 0.58064516, 0.62903226,\n",
       "        0.62903226, 0.66129032, 0.61290323, 0.67741935, 0.67741935,\n",
       "        0.62903226, 0.67741935, 0.67741935, 0.67741935, 0.64516129,\n",
       "        0.67741935, 0.67741935, 0.67741935, 0.67741935, 0.66129032,\n",
       "        0.64516129, 0.64516129, 0.64516129, 0.66129032, 0.62903226,\n",
       "        0.62903226, 0.64516129, 0.64516129, 0.67741935, 0.67741935,\n",
       "        0.67741935, 0.67741935, 0.70967742, 0.70967742, 0.69354839,\n",
       "        0.70967742, 0.70967742, 0.70967742, 0.67741935, 0.69354839,\n",
       "        0.70967742, 0.70967742, 0.69354839, 0.70967742, 0.70967742,\n",
       "        0.70967742, 0.70967742, 0.70967742, 0.70967742, 0.70967742,\n",
       "        0.70967742, 0.70967742, 0.69354839, 0.72580645, 0.70967742,\n",
       "        0.70967742, 0.69354839, 0.72580645, 0.70967742, 0.69354839,\n",
       "        0.58064516, 0.58064516, 0.59677419, 0.58064516, 0.62903226,\n",
       "        0.62903226, 0.66129032, 0.61290323, 0.67741935, 0.67741935,\n",
       "        0.62903226, 0.67741935, 0.67741935, 0.67741935, 0.64516129,\n",
       "        0.67741935, 0.67741935, 0.67741935, 0.67741935, 0.66129032,\n",
       "        0.64516129, 0.64516129, 0.64516129, 0.66129032, 0.62903226,\n",
       "        0.62903226, 0.64516129, 0.64516129, 0.67741935, 0.67741935,\n",
       "        0.67741935, 0.67741935, 0.70967742, 0.70967742, 0.69354839,\n",
       "        0.70967742, 0.70967742, 0.70967742, 0.67741935, 0.69354839,\n",
       "        0.70967742, 0.70967742, 0.69354839, 0.70967742, 0.70967742,\n",
       "        0.70967742, 0.70967742, 0.70967742, 0.70967742, 0.70967742,\n",
       "        0.70967742, 0.70967742, 0.69354839, 0.72580645, 0.70967742,\n",
       "        0.70967742, 0.69354839, 0.72580645, 0.70967742, 0.69354839,\n",
       "        0.58064516, 0.58064516, 0.56451613, 0.58064516, 0.61290323,\n",
       "        0.61290323, 0.62903226, 0.61290323, 0.66129032, 0.66129032,\n",
       "        0.69354839, 0.62903226, 0.67741935, 0.67741935, 0.67741935,\n",
       "        0.67741935, 0.64516129, 0.64516129, 0.64516129, 0.64516129,\n",
       "        0.64516129, 0.66129032, 0.62903226, 0.64516129, 0.64516129,\n",
       "        0.66129032, 0.66129032, 0.64516129, 0.66129032, 0.66129032,\n",
       "        0.64516129, 0.64516129, 0.66129032, 0.67741935, 0.62903226,\n",
       "        0.67741935, 0.64516129, 0.66129032, 0.67741935, 0.66129032,\n",
       "        0.66129032, 0.66129032, 0.62903226, 0.66129032, 0.62903226,\n",
       "        0.64516129, 0.64516129, 0.64516129, 0.66129032, 0.66129032,\n",
       "        0.66129032, 0.67741935, 0.69354839, 0.67741935, 0.67741935,\n",
       "        0.69354839, 0.66129032, 0.67741935, 0.67741935, 0.67741935,\n",
       "        0.58064516, 0.58064516, 0.59677419, 0.58064516, 0.62903226,\n",
       "        0.62903226, 0.66129032, 0.61290323, 0.67741935, 0.67741935,\n",
       "        0.62903226, 0.67741935, 0.67741935, 0.67741935, 0.64516129,\n",
       "        0.67741935, 0.67741935, 0.67741935, 0.67741935, 0.66129032,\n",
       "        0.64516129, 0.64516129, 0.64516129, 0.66129032, 0.62903226,\n",
       "        0.62903226, 0.64516129, 0.64516129, 0.67741935, 0.67741935,\n",
       "        0.67741935, 0.67741935, 0.70967742, 0.70967742, 0.69354839,\n",
       "        0.70967742, 0.70967742, 0.70967742, 0.67741935, 0.69354839,\n",
       "        0.70967742, 0.70967742, 0.69354839, 0.70967742, 0.70967742,\n",
       "        0.70967742, 0.70967742, 0.70967742, 0.70967742, 0.70967742,\n",
       "        0.70967742, 0.70967742, 0.69354839, 0.72580645, 0.70967742,\n",
       "        0.70967742, 0.69354839, 0.72580645, 0.70967742, 0.69354839,\n",
       "        0.58064516, 0.58064516, 0.59677419, 0.58064516, 0.62903226,\n",
       "        0.62903226, 0.66129032, 0.61290323, 0.67741935, 0.67741935,\n",
       "        0.62903226, 0.67741935, 0.67741935, 0.67741935, 0.64516129,\n",
       "        0.67741935, 0.67741935, 0.67741935, 0.67741935, 0.66129032,\n",
       "        0.64516129, 0.64516129, 0.64516129, 0.66129032, 0.62903226,\n",
       "        0.62903226, 0.64516129, 0.64516129, 0.67741935, 0.67741935,\n",
       "        0.67741935, 0.67741935, 0.70967742, 0.70967742, 0.69354839,\n",
       "        0.70967742, 0.70967742, 0.70967742, 0.67741935, 0.69354839,\n",
       "        0.70967742, 0.70967742, 0.69354839, 0.70967742, 0.70967742,\n",
       "        0.70967742, 0.70967742, 0.70967742, 0.70967742, 0.70967742,\n",
       "        0.70967742, 0.70967742, 0.69354839, 0.72580645, 0.70967742,\n",
       "        0.70967742, 0.69354839, 0.72580645, 0.70967742, 0.69354839,\n",
       "        0.58064516, 0.58064516, 0.56451613, 0.58064516, 0.61290323,\n",
       "        0.61290323, 0.62903226, 0.61290323, 0.66129032, 0.66129032,\n",
       "        0.69354839, 0.62903226, 0.67741935, 0.67741935, 0.67741935,\n",
       "        0.67741935, 0.64516129, 0.64516129, 0.64516129, 0.64516129,\n",
       "        0.64516129, 0.66129032, 0.62903226, 0.64516129, 0.64516129,\n",
       "        0.66129032, 0.66129032, 0.64516129, 0.66129032, 0.66129032,\n",
       "        0.64516129, 0.64516129, 0.66129032, 0.67741935, 0.62903226,\n",
       "        0.67741935, 0.64516129, 0.66129032, 0.67741935, 0.66129032,\n",
       "        0.66129032, 0.66129032, 0.62903226, 0.66129032, 0.62903226,\n",
       "        0.64516129, 0.64516129, 0.64516129, 0.66129032, 0.66129032,\n",
       "        0.66129032, 0.67741935, 0.69354839, 0.67741935, 0.67741935,\n",
       "        0.69354839, 0.66129032, 0.67741935, 0.67741935, 0.67741935,\n",
       "        0.58064516, 0.58064516, 0.59677419, 0.58064516, 0.62903226,\n",
       "        0.62903226, 0.66129032, 0.61290323, 0.67741935, 0.67741935,\n",
       "        0.62903226, 0.67741935, 0.67741935, 0.67741935, 0.64516129,\n",
       "        0.67741935, 0.67741935, 0.67741935, 0.67741935, 0.66129032,\n",
       "        0.64516129, 0.64516129, 0.64516129, 0.66129032, 0.62903226,\n",
       "        0.62903226, 0.64516129, 0.64516129, 0.67741935, 0.67741935,\n",
       "        0.67741935, 0.67741935, 0.70967742, 0.70967742, 0.69354839,\n",
       "        0.70967742, 0.70967742, 0.70967742, 0.67741935, 0.69354839,\n",
       "        0.70967742, 0.70967742, 0.69354839, 0.70967742, 0.70967742,\n",
       "        0.70967742, 0.70967742, 0.70967742, 0.70967742, 0.70967742,\n",
       "        0.70967742, 0.70967742, 0.69354839, 0.72580645, 0.70967742,\n",
       "        0.70967742, 0.69354839, 0.72580645, 0.70967742, 0.69354839,\n",
       "        0.58064516, 0.58064516, 0.59677419, 0.58064516, 0.62903226,\n",
       "        0.62903226, 0.66129032, 0.61290323, 0.67741935, 0.67741935,\n",
       "        0.62903226, 0.67741935, 0.67741935, 0.67741935, 0.64516129,\n",
       "        0.67741935, 0.67741935, 0.67741935, 0.67741935, 0.66129032,\n",
       "        0.64516129, 0.64516129, 0.64516129, 0.66129032, 0.62903226,\n",
       "        0.62903226, 0.64516129, 0.64516129, 0.67741935, 0.67741935,\n",
       "        0.67741935, 0.67741935, 0.70967742, 0.70967742, 0.69354839,\n",
       "        0.70967742, 0.70967742, 0.70967742, 0.67741935, 0.69354839,\n",
       "        0.70967742, 0.70967742, 0.69354839, 0.70967742, 0.70967742,\n",
       "        0.70967742, 0.70967742, 0.70967742, 0.70967742, 0.70967742,\n",
       "        0.70967742, 0.70967742, 0.69354839, 0.72580645, 0.70967742,\n",
       "        0.70967742, 0.69354839, 0.72580645, 0.70967742, 0.69354839,\n",
       "        0.58064516, 0.58064516, 0.56451613, 0.58064516, 0.61290323,\n",
       "        0.61290323, 0.62903226, 0.61290323, 0.66129032, 0.66129032,\n",
       "        0.69354839, 0.62903226, 0.67741935, 0.67741935, 0.67741935,\n",
       "        0.67741935, 0.64516129, 0.64516129, 0.64516129, 0.64516129,\n",
       "        0.64516129, 0.66129032, 0.62903226, 0.64516129, 0.64516129,\n",
       "        0.66129032, 0.66129032, 0.64516129, 0.66129032, 0.66129032,\n",
       "        0.64516129, 0.64516129, 0.66129032, 0.67741935, 0.62903226,\n",
       "        0.67741935, 0.64516129, 0.66129032, 0.67741935, 0.66129032,\n",
       "        0.66129032, 0.66129032, 0.62903226, 0.66129032, 0.62903226,\n",
       "        0.64516129, 0.64516129, 0.64516129, 0.66129032, 0.66129032,\n",
       "        0.66129032, 0.67741935, 0.69354839, 0.67741935, 0.67741935,\n",
       "        0.69354839, 0.66129032, 0.67741935, 0.67741935, 0.67741935,\n",
       "        0.58064516, 0.58064516, 0.59677419, 0.58064516, 0.62903226,\n",
       "        0.62903226, 0.66129032, 0.61290323, 0.67741935, 0.67741935,\n",
       "        0.62903226, 0.67741935, 0.67741935, 0.67741935, 0.64516129,\n",
       "        0.67741935, 0.67741935, 0.67741935, 0.67741935, 0.66129032,\n",
       "        0.64516129, 0.64516129, 0.64516129, 0.66129032, 0.62903226,\n",
       "        0.62903226, 0.64516129, 0.64516129, 0.67741935, 0.67741935,\n",
       "        0.67741935, 0.67741935, 0.70967742, 0.70967742, 0.69354839,\n",
       "        0.70967742, 0.70967742, 0.70967742, 0.67741935, 0.69354839,\n",
       "        0.70967742, 0.70967742, 0.69354839, 0.70967742, 0.70967742,\n",
       "        0.70967742, 0.70967742, 0.70967742, 0.70967742, 0.70967742,\n",
       "        0.70967742, 0.70967742, 0.69354839, 0.72580645, 0.70967742,\n",
       "        0.70967742, 0.69354839, 0.72580645, 0.70967742, 0.69354839]),\n",
       " 'split1_test_score': array([0.67741935, 0.67741935, 0.74193548, 0.67741935, 0.79032258,\n",
       "        0.77419355, 0.79032258, 0.75806452, 0.80645161, 0.79032258,\n",
       "        0.75806452, 0.74193548, 0.79032258, 0.79032258, 0.75806452,\n",
       "        0.79032258, 0.75806452, 0.75806452, 0.79032258, 0.77419355,\n",
       "        0.75806452, 0.74193548, 0.79032258, 0.79032258, 0.82258065,\n",
       "        0.80645161, 0.83870968, 0.80645161, 0.83870968, 0.82258065,\n",
       "        0.83870968, 0.82258065, 0.85483871, 0.83870968, 0.83870968,\n",
       "        0.82258065, 0.83870968, 0.83870968, 0.85483871, 0.83870968,\n",
       "        0.85483871, 0.83870968, 0.85483871, 0.83870968, 0.83870968,\n",
       "        0.83870968, 0.83870968, 0.83870968, 0.82258065, 0.83870968,\n",
       "        0.85483871, 0.82258065, 0.83870968, 0.83870968, 0.85483871,\n",
       "        0.82258065, 0.82258065, 0.80645161, 0.83870968, 0.80645161,\n",
       "        0.67741935, 0.67741935, 0.72580645, 0.67741935, 0.69354839,\n",
       "        0.69354839, 0.75806452, 0.74193548, 0.75806452, 0.74193548,\n",
       "        0.79032258, 0.75806452, 0.75806452, 0.74193548, 0.79032258,\n",
       "        0.80645161, 0.82258065, 0.80645161, 0.82258065, 0.82258065,\n",
       "        0.83870968, 0.83870968, 0.80645161, 0.83870968, 0.85483871,\n",
       "        0.82258065, 0.82258065, 0.82258065, 0.83870968, 0.80645161,\n",
       "        0.83870968, 0.83870968, 0.82258065, 0.83870968, 0.77419355,\n",
       "        0.82258065, 0.82258065, 0.82258065, 0.83870968, 0.83870968,\n",
       "        0.80645161, 0.80645161, 0.82258065, 0.83870968, 0.82258065,\n",
       "        0.82258065, 0.80645161, 0.82258065, 0.80645161, 0.82258065,\n",
       "        0.83870968, 0.82258065, 0.82258065, 0.82258065, 0.82258065,\n",
       "        0.83870968, 0.82258065, 0.82258065, 0.79032258, 0.82258065,\n",
       "        0.67741935, 0.67741935, 0.74193548, 0.67741935, 0.79032258,\n",
       "        0.77419355, 0.79032258, 0.75806452, 0.80645161, 0.79032258,\n",
       "        0.75806452, 0.74193548, 0.79032258, 0.79032258, 0.75806452,\n",
       "        0.79032258, 0.75806452, 0.75806452, 0.79032258, 0.77419355,\n",
       "        0.75806452, 0.74193548, 0.79032258, 0.79032258, 0.82258065,\n",
       "        0.80645161, 0.83870968, 0.80645161, 0.83870968, 0.82258065,\n",
       "        0.83870968, 0.82258065, 0.85483871, 0.83870968, 0.83870968,\n",
       "        0.82258065, 0.83870968, 0.83870968, 0.85483871, 0.83870968,\n",
       "        0.85483871, 0.83870968, 0.85483871, 0.83870968, 0.83870968,\n",
       "        0.83870968, 0.83870968, 0.83870968, 0.82258065, 0.83870968,\n",
       "        0.85483871, 0.82258065, 0.83870968, 0.83870968, 0.85483871,\n",
       "        0.82258065, 0.82258065, 0.80645161, 0.83870968, 0.80645161,\n",
       "        0.67741935, 0.67741935, 0.74193548, 0.67741935, 0.79032258,\n",
       "        0.77419355, 0.79032258, 0.75806452, 0.80645161, 0.79032258,\n",
       "        0.75806452, 0.74193548, 0.79032258, 0.79032258, 0.75806452,\n",
       "        0.79032258, 0.75806452, 0.75806452, 0.79032258, 0.77419355,\n",
       "        0.75806452, 0.74193548, 0.79032258, 0.79032258, 0.82258065,\n",
       "        0.80645161, 0.83870968, 0.80645161, 0.83870968, 0.82258065,\n",
       "        0.83870968, 0.82258065, 0.85483871, 0.83870968, 0.83870968,\n",
       "        0.82258065, 0.83870968, 0.83870968, 0.85483871, 0.83870968,\n",
       "        0.85483871, 0.83870968, 0.85483871, 0.83870968, 0.83870968,\n",
       "        0.83870968, 0.83870968, 0.83870968, 0.82258065, 0.83870968,\n",
       "        0.85483871, 0.82258065, 0.83870968, 0.83870968, 0.85483871,\n",
       "        0.82258065, 0.82258065, 0.80645161, 0.83870968, 0.80645161,\n",
       "        0.67741935, 0.67741935, 0.72580645, 0.67741935, 0.69354839,\n",
       "        0.69354839, 0.75806452, 0.74193548, 0.75806452, 0.74193548,\n",
       "        0.79032258, 0.75806452, 0.75806452, 0.74193548, 0.79032258,\n",
       "        0.80645161, 0.82258065, 0.80645161, 0.82258065, 0.82258065,\n",
       "        0.83870968, 0.83870968, 0.80645161, 0.83870968, 0.85483871,\n",
       "        0.82258065, 0.82258065, 0.82258065, 0.83870968, 0.80645161,\n",
       "        0.83870968, 0.83870968, 0.82258065, 0.83870968, 0.77419355,\n",
       "        0.82258065, 0.82258065, 0.82258065, 0.83870968, 0.83870968,\n",
       "        0.80645161, 0.80645161, 0.82258065, 0.83870968, 0.82258065,\n",
       "        0.82258065, 0.80645161, 0.82258065, 0.80645161, 0.82258065,\n",
       "        0.83870968, 0.82258065, 0.82258065, 0.82258065, 0.82258065,\n",
       "        0.83870968, 0.82258065, 0.82258065, 0.79032258, 0.82258065,\n",
       "        0.67741935, 0.67741935, 0.74193548, 0.67741935, 0.79032258,\n",
       "        0.77419355, 0.79032258, 0.75806452, 0.80645161, 0.79032258,\n",
       "        0.75806452, 0.74193548, 0.79032258, 0.79032258, 0.75806452,\n",
       "        0.79032258, 0.75806452, 0.75806452, 0.79032258, 0.77419355,\n",
       "        0.75806452, 0.74193548, 0.79032258, 0.79032258, 0.82258065,\n",
       "        0.80645161, 0.83870968, 0.80645161, 0.83870968, 0.82258065,\n",
       "        0.83870968, 0.82258065, 0.85483871, 0.83870968, 0.83870968,\n",
       "        0.82258065, 0.83870968, 0.83870968, 0.85483871, 0.83870968,\n",
       "        0.85483871, 0.83870968, 0.85483871, 0.83870968, 0.83870968,\n",
       "        0.83870968, 0.83870968, 0.83870968, 0.82258065, 0.83870968,\n",
       "        0.85483871, 0.82258065, 0.83870968, 0.83870968, 0.85483871,\n",
       "        0.82258065, 0.82258065, 0.80645161, 0.83870968, 0.80645161,\n",
       "        0.67741935, 0.67741935, 0.74193548, 0.67741935, 0.79032258,\n",
       "        0.77419355, 0.79032258, 0.75806452, 0.80645161, 0.79032258,\n",
       "        0.75806452, 0.74193548, 0.79032258, 0.79032258, 0.75806452,\n",
       "        0.79032258, 0.75806452, 0.75806452, 0.79032258, 0.77419355,\n",
       "        0.75806452, 0.74193548, 0.79032258, 0.79032258, 0.82258065,\n",
       "        0.80645161, 0.83870968, 0.80645161, 0.83870968, 0.82258065,\n",
       "        0.83870968, 0.82258065, 0.85483871, 0.83870968, 0.83870968,\n",
       "        0.82258065, 0.83870968, 0.83870968, 0.85483871, 0.83870968,\n",
       "        0.85483871, 0.83870968, 0.85483871, 0.83870968, 0.83870968,\n",
       "        0.83870968, 0.83870968, 0.83870968, 0.82258065, 0.83870968,\n",
       "        0.85483871, 0.82258065, 0.83870968, 0.83870968, 0.85483871,\n",
       "        0.82258065, 0.82258065, 0.80645161, 0.83870968, 0.80645161,\n",
       "        0.67741935, 0.67741935, 0.72580645, 0.67741935, 0.69354839,\n",
       "        0.69354839, 0.75806452, 0.74193548, 0.75806452, 0.74193548,\n",
       "        0.79032258, 0.75806452, 0.75806452, 0.74193548, 0.79032258,\n",
       "        0.80645161, 0.82258065, 0.80645161, 0.82258065, 0.82258065,\n",
       "        0.83870968, 0.83870968, 0.80645161, 0.83870968, 0.85483871,\n",
       "        0.82258065, 0.82258065, 0.82258065, 0.83870968, 0.80645161,\n",
       "        0.83870968, 0.83870968, 0.82258065, 0.83870968, 0.77419355,\n",
       "        0.82258065, 0.82258065, 0.82258065, 0.83870968, 0.83870968,\n",
       "        0.80645161, 0.80645161, 0.82258065, 0.83870968, 0.82258065,\n",
       "        0.82258065, 0.80645161, 0.82258065, 0.80645161, 0.82258065,\n",
       "        0.83870968, 0.82258065, 0.82258065, 0.82258065, 0.82258065,\n",
       "        0.83870968, 0.82258065, 0.82258065, 0.79032258, 0.82258065,\n",
       "        0.67741935, 0.67741935, 0.74193548, 0.67741935, 0.79032258,\n",
       "        0.77419355, 0.79032258, 0.75806452, 0.80645161, 0.79032258,\n",
       "        0.75806452, 0.74193548, 0.79032258, 0.79032258, 0.75806452,\n",
       "        0.79032258, 0.75806452, 0.75806452, 0.79032258, 0.77419355,\n",
       "        0.75806452, 0.74193548, 0.79032258, 0.79032258, 0.82258065,\n",
       "        0.80645161, 0.83870968, 0.80645161, 0.83870968, 0.82258065,\n",
       "        0.83870968, 0.82258065, 0.85483871, 0.83870968, 0.83870968,\n",
       "        0.82258065, 0.83870968, 0.83870968, 0.85483871, 0.83870968,\n",
       "        0.85483871, 0.83870968, 0.85483871, 0.83870968, 0.83870968,\n",
       "        0.83870968, 0.83870968, 0.83870968, 0.82258065, 0.83870968,\n",
       "        0.85483871, 0.82258065, 0.83870968, 0.83870968, 0.85483871,\n",
       "        0.82258065, 0.82258065, 0.80645161, 0.83870968, 0.80645161,\n",
       "        0.67741935, 0.67741935, 0.74193548, 0.67741935, 0.79032258,\n",
       "        0.77419355, 0.79032258, 0.75806452, 0.80645161, 0.79032258,\n",
       "        0.75806452, 0.74193548, 0.79032258, 0.79032258, 0.75806452,\n",
       "        0.79032258, 0.75806452, 0.75806452, 0.79032258, 0.77419355,\n",
       "        0.75806452, 0.74193548, 0.79032258, 0.79032258, 0.82258065,\n",
       "        0.80645161, 0.83870968, 0.80645161, 0.83870968, 0.82258065,\n",
       "        0.83870968, 0.82258065, 0.85483871, 0.83870968, 0.83870968,\n",
       "        0.82258065, 0.83870968, 0.83870968, 0.85483871, 0.83870968,\n",
       "        0.85483871, 0.83870968, 0.85483871, 0.83870968, 0.83870968,\n",
       "        0.83870968, 0.83870968, 0.83870968, 0.82258065, 0.83870968,\n",
       "        0.85483871, 0.82258065, 0.83870968, 0.83870968, 0.85483871,\n",
       "        0.82258065, 0.82258065, 0.80645161, 0.83870968, 0.80645161,\n",
       "        0.67741935, 0.67741935, 0.72580645, 0.67741935, 0.69354839,\n",
       "        0.69354839, 0.75806452, 0.74193548, 0.75806452, 0.74193548,\n",
       "        0.79032258, 0.75806452, 0.75806452, 0.74193548, 0.79032258,\n",
       "        0.80645161, 0.82258065, 0.80645161, 0.82258065, 0.82258065,\n",
       "        0.83870968, 0.83870968, 0.80645161, 0.83870968, 0.85483871,\n",
       "        0.82258065, 0.82258065, 0.82258065, 0.83870968, 0.80645161,\n",
       "        0.83870968, 0.83870968, 0.82258065, 0.83870968, 0.77419355,\n",
       "        0.82258065, 0.82258065, 0.82258065, 0.83870968, 0.83870968,\n",
       "        0.80645161, 0.80645161, 0.82258065, 0.83870968, 0.82258065,\n",
       "        0.82258065, 0.80645161, 0.82258065, 0.80645161, 0.82258065,\n",
       "        0.83870968, 0.82258065, 0.82258065, 0.82258065, 0.82258065,\n",
       "        0.83870968, 0.82258065, 0.82258065, 0.79032258, 0.82258065,\n",
       "        0.67741935, 0.67741935, 0.74193548, 0.67741935, 0.79032258,\n",
       "        0.77419355, 0.79032258, 0.75806452, 0.80645161, 0.79032258,\n",
       "        0.75806452, 0.74193548, 0.79032258, 0.79032258, 0.75806452,\n",
       "        0.79032258, 0.75806452, 0.75806452, 0.79032258, 0.77419355,\n",
       "        0.75806452, 0.74193548, 0.79032258, 0.79032258, 0.82258065,\n",
       "        0.80645161, 0.83870968, 0.80645161, 0.83870968, 0.82258065,\n",
       "        0.83870968, 0.82258065, 0.85483871, 0.83870968, 0.83870968,\n",
       "        0.82258065, 0.83870968, 0.83870968, 0.85483871, 0.83870968,\n",
       "        0.85483871, 0.83870968, 0.85483871, 0.83870968, 0.83870968,\n",
       "        0.83870968, 0.83870968, 0.83870968, 0.82258065, 0.83870968,\n",
       "        0.85483871, 0.82258065, 0.83870968, 0.83870968, 0.85483871,\n",
       "        0.82258065, 0.82258065, 0.80645161, 0.83870968, 0.80645161]),\n",
       " 'split2_test_score': array([0.77419355, 0.77419355, 0.67741935, 0.77419355, 0.74193548,\n",
       "        0.74193548, 0.69354839, 0.74193548, 0.74193548, 0.75806452,\n",
       "        0.75806452, 0.74193548, 0.70967742, 0.72580645, 0.72580645,\n",
       "        0.74193548, 0.70967742, 0.70967742, 0.70967742, 0.72580645,\n",
       "        0.70967742, 0.74193548, 0.69354839, 0.70967742, 0.74193548,\n",
       "        0.72580645, 0.70967742, 0.74193548, 0.72580645, 0.74193548,\n",
       "        0.70967742, 0.74193548, 0.70967742, 0.70967742, 0.70967742,\n",
       "        0.70967742, 0.70967742, 0.70967742, 0.70967742, 0.72580645,\n",
       "        0.72580645, 0.70967742, 0.72580645, 0.74193548, 0.70967742,\n",
       "        0.70967742, 0.69354839, 0.72580645, 0.74193548, 0.72580645,\n",
       "        0.70967742, 0.72580645, 0.72580645, 0.69354839, 0.72580645,\n",
       "        0.74193548, 0.74193548, 0.70967742, 0.70967742, 0.74193548,\n",
       "        0.70967742, 0.70967742, 0.67741935, 0.70967742, 0.74193548,\n",
       "        0.74193548, 0.69354839, 0.70967742, 0.70967742, 0.70967742,\n",
       "        0.74193548, 0.72580645, 0.75806452, 0.77419355, 0.74193548,\n",
       "        0.74193548, 0.77419355, 0.75806452, 0.74193548, 0.70967742,\n",
       "        0.72580645, 0.72580645, 0.72580645, 0.70967742, 0.74193548,\n",
       "        0.70967742, 0.74193548, 0.72580645, 0.74193548, 0.72580645,\n",
       "        0.74193548, 0.74193548, 0.75806452, 0.74193548, 0.74193548,\n",
       "        0.74193548, 0.75806452, 0.75806452, 0.74193548, 0.74193548,\n",
       "        0.72580645, 0.72580645, 0.74193548, 0.74193548, 0.75806452,\n",
       "        0.74193548, 0.74193548, 0.75806452, 0.75806452, 0.77419355,\n",
       "        0.75806452, 0.77419355, 0.75806452, 0.77419355, 0.75806452,\n",
       "        0.77419355, 0.75806452, 0.77419355, 0.77419355, 0.75806452,\n",
       "        0.77419355, 0.77419355, 0.67741935, 0.77419355, 0.74193548,\n",
       "        0.74193548, 0.69354839, 0.74193548, 0.74193548, 0.75806452,\n",
       "        0.75806452, 0.74193548, 0.70967742, 0.72580645, 0.72580645,\n",
       "        0.74193548, 0.70967742, 0.70967742, 0.70967742, 0.72580645,\n",
       "        0.70967742, 0.74193548, 0.69354839, 0.70967742, 0.74193548,\n",
       "        0.72580645, 0.70967742, 0.74193548, 0.72580645, 0.74193548,\n",
       "        0.70967742, 0.74193548, 0.70967742, 0.70967742, 0.70967742,\n",
       "        0.70967742, 0.70967742, 0.70967742, 0.70967742, 0.72580645,\n",
       "        0.72580645, 0.70967742, 0.72580645, 0.74193548, 0.70967742,\n",
       "        0.70967742, 0.69354839, 0.72580645, 0.74193548, 0.72580645,\n",
       "        0.70967742, 0.72580645, 0.72580645, 0.69354839, 0.72580645,\n",
       "        0.74193548, 0.74193548, 0.70967742, 0.70967742, 0.74193548,\n",
       "        0.77419355, 0.77419355, 0.67741935, 0.77419355, 0.74193548,\n",
       "        0.74193548, 0.69354839, 0.74193548, 0.74193548, 0.75806452,\n",
       "        0.75806452, 0.74193548, 0.70967742, 0.72580645, 0.72580645,\n",
       "        0.74193548, 0.70967742, 0.70967742, 0.70967742, 0.72580645,\n",
       "        0.70967742, 0.74193548, 0.69354839, 0.70967742, 0.74193548,\n",
       "        0.72580645, 0.70967742, 0.74193548, 0.72580645, 0.74193548,\n",
       "        0.70967742, 0.74193548, 0.70967742, 0.70967742, 0.70967742,\n",
       "        0.70967742, 0.70967742, 0.70967742, 0.70967742, 0.72580645,\n",
       "        0.72580645, 0.70967742, 0.72580645, 0.74193548, 0.70967742,\n",
       "        0.70967742, 0.69354839, 0.72580645, 0.74193548, 0.72580645,\n",
       "        0.70967742, 0.72580645, 0.72580645, 0.69354839, 0.72580645,\n",
       "        0.74193548, 0.74193548, 0.70967742, 0.70967742, 0.74193548,\n",
       "        0.70967742, 0.70967742, 0.67741935, 0.70967742, 0.74193548,\n",
       "        0.74193548, 0.69354839, 0.70967742, 0.70967742, 0.70967742,\n",
       "        0.74193548, 0.72580645, 0.75806452, 0.77419355, 0.74193548,\n",
       "        0.74193548, 0.77419355, 0.75806452, 0.74193548, 0.70967742,\n",
       "        0.72580645, 0.72580645, 0.72580645, 0.70967742, 0.74193548,\n",
       "        0.70967742, 0.74193548, 0.72580645, 0.74193548, 0.72580645,\n",
       "        0.74193548, 0.74193548, 0.75806452, 0.74193548, 0.74193548,\n",
       "        0.74193548, 0.75806452, 0.75806452, 0.74193548, 0.74193548,\n",
       "        0.72580645, 0.72580645, 0.74193548, 0.74193548, 0.75806452,\n",
       "        0.74193548, 0.74193548, 0.75806452, 0.75806452, 0.77419355,\n",
       "        0.75806452, 0.77419355, 0.75806452, 0.77419355, 0.75806452,\n",
       "        0.77419355, 0.75806452, 0.77419355, 0.77419355, 0.75806452,\n",
       "        0.77419355, 0.77419355, 0.67741935, 0.77419355, 0.74193548,\n",
       "        0.74193548, 0.69354839, 0.74193548, 0.74193548, 0.75806452,\n",
       "        0.75806452, 0.74193548, 0.70967742, 0.72580645, 0.72580645,\n",
       "        0.74193548, 0.70967742, 0.70967742, 0.70967742, 0.72580645,\n",
       "        0.70967742, 0.74193548, 0.69354839, 0.70967742, 0.74193548,\n",
       "        0.72580645, 0.70967742, 0.74193548, 0.72580645, 0.74193548,\n",
       "        0.70967742, 0.74193548, 0.70967742, 0.70967742, 0.70967742,\n",
       "        0.70967742, 0.70967742, 0.70967742, 0.70967742, 0.72580645,\n",
       "        0.72580645, 0.70967742, 0.72580645, 0.74193548, 0.70967742,\n",
       "        0.70967742, 0.69354839, 0.72580645, 0.74193548, 0.72580645,\n",
       "        0.70967742, 0.72580645, 0.72580645, 0.69354839, 0.72580645,\n",
       "        0.74193548, 0.74193548, 0.70967742, 0.70967742, 0.74193548,\n",
       "        0.77419355, 0.77419355, 0.67741935, 0.77419355, 0.74193548,\n",
       "        0.74193548, 0.69354839, 0.74193548, 0.74193548, 0.75806452,\n",
       "        0.75806452, 0.74193548, 0.70967742, 0.72580645, 0.72580645,\n",
       "        0.74193548, 0.70967742, 0.70967742, 0.70967742, 0.72580645,\n",
       "        0.70967742, 0.74193548, 0.69354839, 0.70967742, 0.74193548,\n",
       "        0.72580645, 0.70967742, 0.74193548, 0.72580645, 0.74193548,\n",
       "        0.70967742, 0.74193548, 0.70967742, 0.70967742, 0.70967742,\n",
       "        0.70967742, 0.70967742, 0.70967742, 0.70967742, 0.72580645,\n",
       "        0.72580645, 0.70967742, 0.72580645, 0.74193548, 0.70967742,\n",
       "        0.70967742, 0.69354839, 0.72580645, 0.74193548, 0.72580645,\n",
       "        0.70967742, 0.72580645, 0.72580645, 0.69354839, 0.72580645,\n",
       "        0.74193548, 0.74193548, 0.70967742, 0.70967742, 0.74193548,\n",
       "        0.70967742, 0.70967742, 0.67741935, 0.70967742, 0.74193548,\n",
       "        0.74193548, 0.69354839, 0.70967742, 0.70967742, 0.70967742,\n",
       "        0.74193548, 0.72580645, 0.75806452, 0.77419355, 0.74193548,\n",
       "        0.74193548, 0.77419355, 0.75806452, 0.74193548, 0.70967742,\n",
       "        0.72580645, 0.72580645, 0.72580645, 0.70967742, 0.74193548,\n",
       "        0.70967742, 0.74193548, 0.72580645, 0.74193548, 0.72580645,\n",
       "        0.74193548, 0.74193548, 0.75806452, 0.74193548, 0.74193548,\n",
       "        0.74193548, 0.75806452, 0.75806452, 0.74193548, 0.74193548,\n",
       "        0.72580645, 0.72580645, 0.74193548, 0.74193548, 0.75806452,\n",
       "        0.74193548, 0.74193548, 0.75806452, 0.75806452, 0.77419355,\n",
       "        0.75806452, 0.77419355, 0.75806452, 0.77419355, 0.75806452,\n",
       "        0.77419355, 0.75806452, 0.77419355, 0.77419355, 0.75806452,\n",
       "        0.77419355, 0.77419355, 0.67741935, 0.77419355, 0.74193548,\n",
       "        0.74193548, 0.69354839, 0.74193548, 0.74193548, 0.75806452,\n",
       "        0.75806452, 0.74193548, 0.70967742, 0.72580645, 0.72580645,\n",
       "        0.74193548, 0.70967742, 0.70967742, 0.70967742, 0.72580645,\n",
       "        0.70967742, 0.74193548, 0.69354839, 0.70967742, 0.74193548,\n",
       "        0.72580645, 0.70967742, 0.74193548, 0.72580645, 0.74193548,\n",
       "        0.70967742, 0.74193548, 0.70967742, 0.70967742, 0.70967742,\n",
       "        0.70967742, 0.70967742, 0.70967742, 0.70967742, 0.72580645,\n",
       "        0.72580645, 0.70967742, 0.72580645, 0.74193548, 0.70967742,\n",
       "        0.70967742, 0.69354839, 0.72580645, 0.74193548, 0.72580645,\n",
       "        0.70967742, 0.72580645, 0.72580645, 0.69354839, 0.72580645,\n",
       "        0.74193548, 0.74193548, 0.70967742, 0.70967742, 0.74193548,\n",
       "        0.77419355, 0.77419355, 0.67741935, 0.77419355, 0.74193548,\n",
       "        0.74193548, 0.69354839, 0.74193548, 0.74193548, 0.75806452,\n",
       "        0.75806452, 0.74193548, 0.70967742, 0.72580645, 0.72580645,\n",
       "        0.74193548, 0.70967742, 0.70967742, 0.70967742, 0.72580645,\n",
       "        0.70967742, 0.74193548, 0.69354839, 0.70967742, 0.74193548,\n",
       "        0.72580645, 0.70967742, 0.74193548, 0.72580645, 0.74193548,\n",
       "        0.70967742, 0.74193548, 0.70967742, 0.70967742, 0.70967742,\n",
       "        0.70967742, 0.70967742, 0.70967742, 0.70967742, 0.72580645,\n",
       "        0.72580645, 0.70967742, 0.72580645, 0.74193548, 0.70967742,\n",
       "        0.70967742, 0.69354839, 0.72580645, 0.74193548, 0.72580645,\n",
       "        0.70967742, 0.72580645, 0.72580645, 0.69354839, 0.72580645,\n",
       "        0.74193548, 0.74193548, 0.70967742, 0.70967742, 0.74193548,\n",
       "        0.70967742, 0.70967742, 0.67741935, 0.70967742, 0.74193548,\n",
       "        0.74193548, 0.69354839, 0.70967742, 0.70967742, 0.70967742,\n",
       "        0.74193548, 0.72580645, 0.75806452, 0.77419355, 0.74193548,\n",
       "        0.74193548, 0.77419355, 0.75806452, 0.74193548, 0.70967742,\n",
       "        0.72580645, 0.72580645, 0.72580645, 0.70967742, 0.74193548,\n",
       "        0.70967742, 0.74193548, 0.72580645, 0.74193548, 0.72580645,\n",
       "        0.74193548, 0.74193548, 0.75806452, 0.74193548, 0.74193548,\n",
       "        0.74193548, 0.75806452, 0.75806452, 0.74193548, 0.74193548,\n",
       "        0.72580645, 0.72580645, 0.74193548, 0.74193548, 0.75806452,\n",
       "        0.74193548, 0.74193548, 0.75806452, 0.75806452, 0.77419355,\n",
       "        0.75806452, 0.77419355, 0.75806452, 0.77419355, 0.75806452,\n",
       "        0.77419355, 0.75806452, 0.77419355, 0.77419355, 0.75806452,\n",
       "        0.77419355, 0.77419355, 0.67741935, 0.77419355, 0.74193548,\n",
       "        0.74193548, 0.69354839, 0.74193548, 0.74193548, 0.75806452,\n",
       "        0.75806452, 0.74193548, 0.70967742, 0.72580645, 0.72580645,\n",
       "        0.74193548, 0.70967742, 0.70967742, 0.70967742, 0.72580645,\n",
       "        0.70967742, 0.74193548, 0.69354839, 0.70967742, 0.74193548,\n",
       "        0.72580645, 0.70967742, 0.74193548, 0.72580645, 0.74193548,\n",
       "        0.70967742, 0.74193548, 0.70967742, 0.70967742, 0.70967742,\n",
       "        0.70967742, 0.70967742, 0.70967742, 0.70967742, 0.72580645,\n",
       "        0.72580645, 0.70967742, 0.72580645, 0.74193548, 0.70967742,\n",
       "        0.70967742, 0.69354839, 0.72580645, 0.74193548, 0.72580645,\n",
       "        0.70967742, 0.72580645, 0.72580645, 0.69354839, 0.72580645,\n",
       "        0.74193548, 0.74193548, 0.70967742, 0.70967742, 0.74193548]),\n",
       " 'split3_test_score': array([0.72580645, 0.72580645, 0.72580645, 0.72580645, 0.69354839,\n",
       "        0.67741935, 0.72580645, 0.75806452, 0.69354839, 0.69354839,\n",
       "        0.70967742, 0.72580645, 0.74193548, 0.74193548, 0.77419355,\n",
       "        0.75806452, 0.77419355, 0.75806452, 0.77419355, 0.79032258,\n",
       "        0.77419355, 0.75806452, 0.80645161, 0.75806452, 0.80645161,\n",
       "        0.79032258, 0.77419355, 0.77419355, 0.77419355, 0.77419355,\n",
       "        0.75806452, 0.77419355, 0.79032258, 0.77419355, 0.80645161,\n",
       "        0.79032258, 0.80645161, 0.77419355, 0.80645161, 0.80645161,\n",
       "        0.82258065, 0.80645161, 0.80645161, 0.79032258, 0.79032258,\n",
       "        0.80645161, 0.75806452, 0.75806452, 0.74193548, 0.77419355,\n",
       "        0.74193548, 0.77419355, 0.77419355, 0.79032258, 0.75806452,\n",
       "        0.77419355, 0.79032258, 0.79032258, 0.79032258, 0.79032258,\n",
       "        0.69354839, 0.69354839, 0.69354839, 0.69354839, 0.70967742,\n",
       "        0.69354839, 0.75806452, 0.70967742, 0.77419355, 0.77419355,\n",
       "        0.77419355, 0.79032258, 0.77419355, 0.77419355, 0.77419355,\n",
       "        0.79032258, 0.79032258, 0.79032258, 0.75806452, 0.79032258,\n",
       "        0.77419355, 0.75806452, 0.77419355, 0.75806452, 0.82258065,\n",
       "        0.79032258, 0.79032258, 0.82258065, 0.87096774, 0.82258065,\n",
       "        0.82258065, 0.82258065, 0.80645161, 0.75806452, 0.79032258,\n",
       "        0.79032258, 0.79032258, 0.77419355, 0.77419355, 0.80645161,\n",
       "        0.80645161, 0.79032258, 0.80645161, 0.80645161, 0.80645161,\n",
       "        0.79032258, 0.79032258, 0.80645161, 0.82258065, 0.80645161,\n",
       "        0.79032258, 0.80645161, 0.80645161, 0.80645161, 0.77419355,\n",
       "        0.79032258, 0.77419355, 0.77419355, 0.75806452, 0.80645161,\n",
       "        0.72580645, 0.72580645, 0.72580645, 0.72580645, 0.69354839,\n",
       "        0.67741935, 0.72580645, 0.75806452, 0.69354839, 0.69354839,\n",
       "        0.70967742, 0.72580645, 0.74193548, 0.74193548, 0.77419355,\n",
       "        0.75806452, 0.77419355, 0.75806452, 0.77419355, 0.79032258,\n",
       "        0.77419355, 0.75806452, 0.80645161, 0.75806452, 0.80645161,\n",
       "        0.79032258, 0.77419355, 0.77419355, 0.77419355, 0.77419355,\n",
       "        0.75806452, 0.77419355, 0.79032258, 0.77419355, 0.80645161,\n",
       "        0.79032258, 0.80645161, 0.77419355, 0.80645161, 0.80645161,\n",
       "        0.82258065, 0.80645161, 0.80645161, 0.79032258, 0.79032258,\n",
       "        0.80645161, 0.75806452, 0.75806452, 0.74193548, 0.77419355,\n",
       "        0.74193548, 0.77419355, 0.77419355, 0.79032258, 0.75806452,\n",
       "        0.77419355, 0.79032258, 0.79032258, 0.79032258, 0.79032258,\n",
       "        0.72580645, 0.72580645, 0.72580645, 0.72580645, 0.69354839,\n",
       "        0.67741935, 0.72580645, 0.75806452, 0.69354839, 0.69354839,\n",
       "        0.70967742, 0.72580645, 0.74193548, 0.74193548, 0.77419355,\n",
       "        0.75806452, 0.77419355, 0.75806452, 0.77419355, 0.79032258,\n",
       "        0.77419355, 0.75806452, 0.80645161, 0.75806452, 0.80645161,\n",
       "        0.79032258, 0.77419355, 0.77419355, 0.77419355, 0.77419355,\n",
       "        0.75806452, 0.77419355, 0.79032258, 0.77419355, 0.80645161,\n",
       "        0.79032258, 0.80645161, 0.77419355, 0.80645161, 0.80645161,\n",
       "        0.82258065, 0.80645161, 0.80645161, 0.79032258, 0.79032258,\n",
       "        0.80645161, 0.75806452, 0.75806452, 0.74193548, 0.77419355,\n",
       "        0.74193548, 0.77419355, 0.77419355, 0.79032258, 0.75806452,\n",
       "        0.77419355, 0.79032258, 0.79032258, 0.79032258, 0.79032258,\n",
       "        0.69354839, 0.69354839, 0.69354839, 0.69354839, 0.70967742,\n",
       "        0.69354839, 0.75806452, 0.70967742, 0.77419355, 0.77419355,\n",
       "        0.77419355, 0.79032258, 0.77419355, 0.77419355, 0.77419355,\n",
       "        0.79032258, 0.79032258, 0.79032258, 0.75806452, 0.79032258,\n",
       "        0.77419355, 0.75806452, 0.77419355, 0.75806452, 0.82258065,\n",
       "        0.79032258, 0.79032258, 0.82258065, 0.87096774, 0.82258065,\n",
       "        0.82258065, 0.82258065, 0.80645161, 0.75806452, 0.79032258,\n",
       "        0.79032258, 0.79032258, 0.77419355, 0.77419355, 0.80645161,\n",
       "        0.80645161, 0.79032258, 0.80645161, 0.80645161, 0.80645161,\n",
       "        0.79032258, 0.79032258, 0.80645161, 0.82258065, 0.80645161,\n",
       "        0.79032258, 0.80645161, 0.80645161, 0.80645161, 0.77419355,\n",
       "        0.79032258, 0.77419355, 0.77419355, 0.75806452, 0.80645161,\n",
       "        0.72580645, 0.72580645, 0.72580645, 0.72580645, 0.69354839,\n",
       "        0.67741935, 0.72580645, 0.75806452, 0.69354839, 0.69354839,\n",
       "        0.70967742, 0.72580645, 0.74193548, 0.74193548, 0.77419355,\n",
       "        0.75806452, 0.77419355, 0.75806452, 0.77419355, 0.79032258,\n",
       "        0.77419355, 0.75806452, 0.80645161, 0.75806452, 0.80645161,\n",
       "        0.79032258, 0.77419355, 0.77419355, 0.77419355, 0.77419355,\n",
       "        0.75806452, 0.77419355, 0.79032258, 0.77419355, 0.80645161,\n",
       "        0.79032258, 0.80645161, 0.77419355, 0.80645161, 0.80645161,\n",
       "        0.82258065, 0.80645161, 0.80645161, 0.79032258, 0.79032258,\n",
       "        0.80645161, 0.75806452, 0.75806452, 0.74193548, 0.77419355,\n",
       "        0.74193548, 0.77419355, 0.77419355, 0.79032258, 0.75806452,\n",
       "        0.77419355, 0.79032258, 0.79032258, 0.79032258, 0.79032258,\n",
       "        0.72580645, 0.72580645, 0.72580645, 0.72580645, 0.69354839,\n",
       "        0.67741935, 0.72580645, 0.75806452, 0.69354839, 0.69354839,\n",
       "        0.70967742, 0.72580645, 0.74193548, 0.74193548, 0.77419355,\n",
       "        0.75806452, 0.77419355, 0.75806452, 0.77419355, 0.79032258,\n",
       "        0.77419355, 0.75806452, 0.80645161, 0.75806452, 0.80645161,\n",
       "        0.79032258, 0.77419355, 0.77419355, 0.77419355, 0.77419355,\n",
       "        0.75806452, 0.77419355, 0.79032258, 0.77419355, 0.80645161,\n",
       "        0.79032258, 0.80645161, 0.77419355, 0.80645161, 0.80645161,\n",
       "        0.82258065, 0.80645161, 0.80645161, 0.79032258, 0.79032258,\n",
       "        0.80645161, 0.75806452, 0.75806452, 0.74193548, 0.77419355,\n",
       "        0.74193548, 0.77419355, 0.77419355, 0.79032258, 0.75806452,\n",
       "        0.77419355, 0.79032258, 0.79032258, 0.79032258, 0.79032258,\n",
       "        0.69354839, 0.69354839, 0.69354839, 0.69354839, 0.70967742,\n",
       "        0.69354839, 0.75806452, 0.70967742, 0.77419355, 0.77419355,\n",
       "        0.77419355, 0.79032258, 0.77419355, 0.77419355, 0.77419355,\n",
       "        0.79032258, 0.79032258, 0.79032258, 0.75806452, 0.79032258,\n",
       "        0.77419355, 0.75806452, 0.77419355, 0.75806452, 0.82258065,\n",
       "        0.79032258, 0.79032258, 0.82258065, 0.87096774, 0.82258065,\n",
       "        0.82258065, 0.82258065, 0.80645161, 0.75806452, 0.79032258,\n",
       "        0.79032258, 0.79032258, 0.77419355, 0.77419355, 0.80645161,\n",
       "        0.80645161, 0.79032258, 0.80645161, 0.80645161, 0.80645161,\n",
       "        0.79032258, 0.79032258, 0.80645161, 0.82258065, 0.80645161,\n",
       "        0.79032258, 0.80645161, 0.80645161, 0.80645161, 0.77419355,\n",
       "        0.79032258, 0.77419355, 0.77419355, 0.75806452, 0.80645161,\n",
       "        0.72580645, 0.72580645, 0.72580645, 0.72580645, 0.69354839,\n",
       "        0.67741935, 0.72580645, 0.75806452, 0.69354839, 0.69354839,\n",
       "        0.70967742, 0.72580645, 0.74193548, 0.74193548, 0.77419355,\n",
       "        0.75806452, 0.77419355, 0.75806452, 0.77419355, 0.79032258,\n",
       "        0.77419355, 0.75806452, 0.80645161, 0.75806452, 0.80645161,\n",
       "        0.79032258, 0.77419355, 0.77419355, 0.77419355, 0.77419355,\n",
       "        0.75806452, 0.77419355, 0.79032258, 0.77419355, 0.80645161,\n",
       "        0.79032258, 0.80645161, 0.77419355, 0.80645161, 0.80645161,\n",
       "        0.82258065, 0.80645161, 0.80645161, 0.79032258, 0.79032258,\n",
       "        0.80645161, 0.75806452, 0.75806452, 0.74193548, 0.77419355,\n",
       "        0.74193548, 0.77419355, 0.77419355, 0.79032258, 0.75806452,\n",
       "        0.77419355, 0.79032258, 0.79032258, 0.79032258, 0.79032258,\n",
       "        0.72580645, 0.72580645, 0.72580645, 0.72580645, 0.69354839,\n",
       "        0.67741935, 0.72580645, 0.75806452, 0.69354839, 0.69354839,\n",
       "        0.70967742, 0.72580645, 0.74193548, 0.74193548, 0.77419355,\n",
       "        0.75806452, 0.77419355, 0.75806452, 0.77419355, 0.79032258,\n",
       "        0.77419355, 0.75806452, 0.80645161, 0.75806452, 0.80645161,\n",
       "        0.79032258, 0.77419355, 0.77419355, 0.77419355, 0.77419355,\n",
       "        0.75806452, 0.77419355, 0.79032258, 0.77419355, 0.80645161,\n",
       "        0.79032258, 0.80645161, 0.77419355, 0.80645161, 0.80645161,\n",
       "        0.82258065, 0.80645161, 0.80645161, 0.79032258, 0.79032258,\n",
       "        0.80645161, 0.75806452, 0.75806452, 0.74193548, 0.77419355,\n",
       "        0.74193548, 0.77419355, 0.77419355, 0.79032258, 0.75806452,\n",
       "        0.77419355, 0.79032258, 0.79032258, 0.79032258, 0.79032258,\n",
       "        0.69354839, 0.69354839, 0.69354839, 0.69354839, 0.70967742,\n",
       "        0.69354839, 0.75806452, 0.70967742, 0.77419355, 0.77419355,\n",
       "        0.77419355, 0.79032258, 0.77419355, 0.77419355, 0.77419355,\n",
       "        0.79032258, 0.79032258, 0.79032258, 0.75806452, 0.79032258,\n",
       "        0.77419355, 0.75806452, 0.77419355, 0.75806452, 0.82258065,\n",
       "        0.79032258, 0.79032258, 0.82258065, 0.87096774, 0.82258065,\n",
       "        0.82258065, 0.82258065, 0.80645161, 0.75806452, 0.79032258,\n",
       "        0.79032258, 0.79032258, 0.77419355, 0.77419355, 0.80645161,\n",
       "        0.80645161, 0.79032258, 0.80645161, 0.80645161, 0.80645161,\n",
       "        0.79032258, 0.79032258, 0.80645161, 0.82258065, 0.80645161,\n",
       "        0.79032258, 0.80645161, 0.80645161, 0.80645161, 0.77419355,\n",
       "        0.79032258, 0.77419355, 0.77419355, 0.75806452, 0.80645161,\n",
       "        0.72580645, 0.72580645, 0.72580645, 0.72580645, 0.69354839,\n",
       "        0.67741935, 0.72580645, 0.75806452, 0.69354839, 0.69354839,\n",
       "        0.70967742, 0.72580645, 0.74193548, 0.74193548, 0.77419355,\n",
       "        0.75806452, 0.77419355, 0.75806452, 0.77419355, 0.79032258,\n",
       "        0.77419355, 0.75806452, 0.80645161, 0.75806452, 0.80645161,\n",
       "        0.79032258, 0.77419355, 0.77419355, 0.77419355, 0.77419355,\n",
       "        0.75806452, 0.77419355, 0.79032258, 0.77419355, 0.80645161,\n",
       "        0.79032258, 0.80645161, 0.77419355, 0.80645161, 0.80645161,\n",
       "        0.82258065, 0.80645161, 0.80645161, 0.79032258, 0.79032258,\n",
       "        0.80645161, 0.75806452, 0.75806452, 0.74193548, 0.77419355,\n",
       "        0.74193548, 0.77419355, 0.77419355, 0.79032258, 0.75806452,\n",
       "        0.77419355, 0.79032258, 0.79032258, 0.79032258, 0.79032258]),\n",
       " 'split4_test_score': array([0.72131148, 0.72131148, 0.6557377 , 0.72131148, 0.67213115,\n",
       "        0.67213115, 0.67213115, 0.67213115, 0.72131148, 0.72131148,\n",
       "        0.73770492, 0.68852459, 0.72131148, 0.72131148, 0.75409836,\n",
       "        0.73770492, 0.70491803, 0.68852459, 0.68852459, 0.70491803,\n",
       "        0.68852459, 0.68852459, 0.73770492, 0.72131148, 0.73770492,\n",
       "        0.73770492, 0.70491803, 0.72131148, 0.75409836, 0.75409836,\n",
       "        0.75409836, 0.78688525, 0.7704918 , 0.7704918 , 0.75409836,\n",
       "        0.75409836, 0.75409836, 0.75409836, 0.72131148, 0.7704918 ,\n",
       "        0.73770492, 0.75409836, 0.72131148, 0.7704918 , 0.73770492,\n",
       "        0.73770492, 0.73770492, 0.75409836, 0.75409836, 0.7704918 ,\n",
       "        0.78688525, 0.78688525, 0.75409836, 0.7704918 , 0.7704918 ,\n",
       "        0.7704918 , 0.75409836, 0.75409836, 0.73770492, 0.75409836,\n",
       "        0.70491803, 0.70491803, 0.68852459, 0.70491803, 0.59016393,\n",
       "        0.59016393, 0.62295082, 0.62295082, 0.59016393, 0.59016393,\n",
       "        0.63934426, 0.60655738, 0.60655738, 0.60655738, 0.62295082,\n",
       "        0.59016393, 0.63934426, 0.63934426, 0.67213115, 0.6557377 ,\n",
       "        0.68852459, 0.68852459, 0.68852459, 0.72131148, 0.70491803,\n",
       "        0.70491803, 0.73770492, 0.72131148, 0.72131148, 0.72131148,\n",
       "        0.70491803, 0.72131148, 0.72131148, 0.72131148, 0.70491803,\n",
       "        0.72131148, 0.72131148, 0.72131148, 0.68852459, 0.70491803,\n",
       "        0.68852459, 0.68852459, 0.70491803, 0.68852459, 0.68852459,\n",
       "        0.68852459, 0.68852459, 0.68852459, 0.72131148, 0.70491803,\n",
       "        0.70491803, 0.73770492, 0.73770492, 0.73770492, 0.73770492,\n",
       "        0.75409836, 0.73770492, 0.73770492, 0.72131148, 0.73770492,\n",
       "        0.72131148, 0.72131148, 0.6557377 , 0.72131148, 0.67213115,\n",
       "        0.67213115, 0.67213115, 0.67213115, 0.72131148, 0.72131148,\n",
       "        0.73770492, 0.68852459, 0.72131148, 0.72131148, 0.75409836,\n",
       "        0.73770492, 0.70491803, 0.68852459, 0.68852459, 0.70491803,\n",
       "        0.68852459, 0.68852459, 0.73770492, 0.72131148, 0.73770492,\n",
       "        0.73770492, 0.70491803, 0.72131148, 0.75409836, 0.75409836,\n",
       "        0.75409836, 0.78688525, 0.7704918 , 0.7704918 , 0.75409836,\n",
       "        0.75409836, 0.75409836, 0.75409836, 0.72131148, 0.7704918 ,\n",
       "        0.73770492, 0.75409836, 0.72131148, 0.7704918 , 0.73770492,\n",
       "        0.73770492, 0.73770492, 0.75409836, 0.75409836, 0.7704918 ,\n",
       "        0.78688525, 0.78688525, 0.75409836, 0.7704918 , 0.7704918 ,\n",
       "        0.7704918 , 0.75409836, 0.75409836, 0.73770492, 0.75409836,\n",
       "        0.72131148, 0.72131148, 0.6557377 , 0.72131148, 0.67213115,\n",
       "        0.67213115, 0.67213115, 0.67213115, 0.72131148, 0.72131148,\n",
       "        0.73770492, 0.68852459, 0.72131148, 0.72131148, 0.75409836,\n",
       "        0.73770492, 0.70491803, 0.68852459, 0.68852459, 0.70491803,\n",
       "        0.68852459, 0.68852459, 0.73770492, 0.72131148, 0.73770492,\n",
       "        0.73770492, 0.70491803, 0.72131148, 0.75409836, 0.75409836,\n",
       "        0.75409836, 0.78688525, 0.7704918 , 0.7704918 , 0.75409836,\n",
       "        0.75409836, 0.75409836, 0.75409836, 0.72131148, 0.7704918 ,\n",
       "        0.73770492, 0.75409836, 0.72131148, 0.7704918 , 0.73770492,\n",
       "        0.73770492, 0.73770492, 0.75409836, 0.75409836, 0.7704918 ,\n",
       "        0.78688525, 0.78688525, 0.75409836, 0.7704918 , 0.7704918 ,\n",
       "        0.7704918 , 0.75409836, 0.75409836, 0.73770492, 0.75409836,\n",
       "        0.70491803, 0.70491803, 0.68852459, 0.70491803, 0.59016393,\n",
       "        0.59016393, 0.62295082, 0.62295082, 0.59016393, 0.59016393,\n",
       "        0.63934426, 0.60655738, 0.60655738, 0.60655738, 0.62295082,\n",
       "        0.59016393, 0.63934426, 0.63934426, 0.67213115, 0.6557377 ,\n",
       "        0.68852459, 0.68852459, 0.68852459, 0.72131148, 0.70491803,\n",
       "        0.70491803, 0.73770492, 0.72131148, 0.72131148, 0.72131148,\n",
       "        0.70491803, 0.72131148, 0.72131148, 0.72131148, 0.70491803,\n",
       "        0.72131148, 0.72131148, 0.72131148, 0.68852459, 0.70491803,\n",
       "        0.68852459, 0.68852459, 0.70491803, 0.68852459, 0.68852459,\n",
       "        0.68852459, 0.68852459, 0.68852459, 0.72131148, 0.70491803,\n",
       "        0.70491803, 0.73770492, 0.73770492, 0.73770492, 0.73770492,\n",
       "        0.75409836, 0.73770492, 0.73770492, 0.72131148, 0.73770492,\n",
       "        0.72131148, 0.72131148, 0.6557377 , 0.72131148, 0.67213115,\n",
       "        0.67213115, 0.67213115, 0.67213115, 0.72131148, 0.72131148,\n",
       "        0.73770492, 0.68852459, 0.72131148, 0.72131148, 0.75409836,\n",
       "        0.73770492, 0.70491803, 0.68852459, 0.68852459, 0.70491803,\n",
       "        0.68852459, 0.68852459, 0.73770492, 0.72131148, 0.73770492,\n",
       "        0.73770492, 0.70491803, 0.72131148, 0.75409836, 0.75409836,\n",
       "        0.75409836, 0.78688525, 0.7704918 , 0.7704918 , 0.75409836,\n",
       "        0.75409836, 0.75409836, 0.75409836, 0.72131148, 0.7704918 ,\n",
       "        0.73770492, 0.75409836, 0.72131148, 0.7704918 , 0.73770492,\n",
       "        0.73770492, 0.73770492, 0.75409836, 0.75409836, 0.7704918 ,\n",
       "        0.78688525, 0.78688525, 0.75409836, 0.7704918 , 0.7704918 ,\n",
       "        0.7704918 , 0.75409836, 0.75409836, 0.73770492, 0.75409836,\n",
       "        0.72131148, 0.72131148, 0.6557377 , 0.72131148, 0.67213115,\n",
       "        0.67213115, 0.67213115, 0.67213115, 0.72131148, 0.72131148,\n",
       "        0.73770492, 0.68852459, 0.72131148, 0.72131148, 0.75409836,\n",
       "        0.73770492, 0.70491803, 0.68852459, 0.68852459, 0.70491803,\n",
       "        0.68852459, 0.68852459, 0.73770492, 0.72131148, 0.73770492,\n",
       "        0.73770492, 0.70491803, 0.72131148, 0.75409836, 0.75409836,\n",
       "        0.75409836, 0.78688525, 0.7704918 , 0.7704918 , 0.75409836,\n",
       "        0.75409836, 0.75409836, 0.75409836, 0.72131148, 0.7704918 ,\n",
       "        0.73770492, 0.75409836, 0.72131148, 0.7704918 , 0.73770492,\n",
       "        0.73770492, 0.73770492, 0.75409836, 0.75409836, 0.7704918 ,\n",
       "        0.78688525, 0.78688525, 0.75409836, 0.7704918 , 0.7704918 ,\n",
       "        0.7704918 , 0.75409836, 0.75409836, 0.73770492, 0.75409836,\n",
       "        0.70491803, 0.70491803, 0.68852459, 0.70491803, 0.59016393,\n",
       "        0.59016393, 0.62295082, 0.62295082, 0.59016393, 0.59016393,\n",
       "        0.63934426, 0.60655738, 0.60655738, 0.60655738, 0.62295082,\n",
       "        0.59016393, 0.63934426, 0.63934426, 0.67213115, 0.6557377 ,\n",
       "        0.68852459, 0.68852459, 0.68852459, 0.72131148, 0.70491803,\n",
       "        0.70491803, 0.73770492, 0.72131148, 0.72131148, 0.72131148,\n",
       "        0.70491803, 0.72131148, 0.72131148, 0.72131148, 0.70491803,\n",
       "        0.72131148, 0.72131148, 0.72131148, 0.68852459, 0.70491803,\n",
       "        0.68852459, 0.68852459, 0.70491803, 0.68852459, 0.68852459,\n",
       "        0.68852459, 0.68852459, 0.68852459, 0.72131148, 0.70491803,\n",
       "        0.70491803, 0.73770492, 0.73770492, 0.73770492, 0.73770492,\n",
       "        0.75409836, 0.73770492, 0.73770492, 0.72131148, 0.73770492,\n",
       "        0.72131148, 0.72131148, 0.6557377 , 0.72131148, 0.67213115,\n",
       "        0.67213115, 0.67213115, 0.67213115, 0.72131148, 0.72131148,\n",
       "        0.73770492, 0.68852459, 0.72131148, 0.72131148, 0.75409836,\n",
       "        0.73770492, 0.70491803, 0.68852459, 0.68852459, 0.70491803,\n",
       "        0.68852459, 0.68852459, 0.73770492, 0.72131148, 0.73770492,\n",
       "        0.73770492, 0.70491803, 0.72131148, 0.75409836, 0.75409836,\n",
       "        0.75409836, 0.78688525, 0.7704918 , 0.7704918 , 0.75409836,\n",
       "        0.75409836, 0.75409836, 0.75409836, 0.72131148, 0.7704918 ,\n",
       "        0.73770492, 0.75409836, 0.72131148, 0.7704918 , 0.73770492,\n",
       "        0.73770492, 0.73770492, 0.75409836, 0.75409836, 0.7704918 ,\n",
       "        0.78688525, 0.78688525, 0.75409836, 0.7704918 , 0.7704918 ,\n",
       "        0.7704918 , 0.75409836, 0.75409836, 0.73770492, 0.75409836,\n",
       "        0.72131148, 0.72131148, 0.6557377 , 0.72131148, 0.67213115,\n",
       "        0.67213115, 0.67213115, 0.67213115, 0.72131148, 0.72131148,\n",
       "        0.73770492, 0.68852459, 0.72131148, 0.72131148, 0.75409836,\n",
       "        0.73770492, 0.70491803, 0.68852459, 0.68852459, 0.70491803,\n",
       "        0.68852459, 0.68852459, 0.73770492, 0.72131148, 0.73770492,\n",
       "        0.73770492, 0.70491803, 0.72131148, 0.75409836, 0.75409836,\n",
       "        0.75409836, 0.78688525, 0.7704918 , 0.7704918 , 0.75409836,\n",
       "        0.75409836, 0.75409836, 0.75409836, 0.72131148, 0.7704918 ,\n",
       "        0.73770492, 0.75409836, 0.72131148, 0.7704918 , 0.73770492,\n",
       "        0.73770492, 0.73770492, 0.75409836, 0.75409836, 0.7704918 ,\n",
       "        0.78688525, 0.78688525, 0.75409836, 0.7704918 , 0.7704918 ,\n",
       "        0.7704918 , 0.75409836, 0.75409836, 0.73770492, 0.75409836,\n",
       "        0.70491803, 0.70491803, 0.68852459, 0.70491803, 0.59016393,\n",
       "        0.59016393, 0.62295082, 0.62295082, 0.59016393, 0.59016393,\n",
       "        0.63934426, 0.60655738, 0.60655738, 0.60655738, 0.62295082,\n",
       "        0.59016393, 0.63934426, 0.63934426, 0.67213115, 0.6557377 ,\n",
       "        0.68852459, 0.68852459, 0.68852459, 0.72131148, 0.70491803,\n",
       "        0.70491803, 0.73770492, 0.72131148, 0.72131148, 0.72131148,\n",
       "        0.70491803, 0.72131148, 0.72131148, 0.72131148, 0.70491803,\n",
       "        0.72131148, 0.72131148, 0.72131148, 0.68852459, 0.70491803,\n",
       "        0.68852459, 0.68852459, 0.70491803, 0.68852459, 0.68852459,\n",
       "        0.68852459, 0.68852459, 0.68852459, 0.72131148, 0.70491803,\n",
       "        0.70491803, 0.73770492, 0.73770492, 0.73770492, 0.73770492,\n",
       "        0.75409836, 0.73770492, 0.73770492, 0.72131148, 0.73770492,\n",
       "        0.72131148, 0.72131148, 0.6557377 , 0.72131148, 0.67213115,\n",
       "        0.67213115, 0.67213115, 0.67213115, 0.72131148, 0.72131148,\n",
       "        0.73770492, 0.68852459, 0.72131148, 0.72131148, 0.75409836,\n",
       "        0.73770492, 0.70491803, 0.68852459, 0.68852459, 0.70491803,\n",
       "        0.68852459, 0.68852459, 0.73770492, 0.72131148, 0.73770492,\n",
       "        0.73770492, 0.70491803, 0.72131148, 0.75409836, 0.75409836,\n",
       "        0.75409836, 0.78688525, 0.7704918 , 0.7704918 , 0.75409836,\n",
       "        0.75409836, 0.75409836, 0.75409836, 0.72131148, 0.7704918 ,\n",
       "        0.73770492, 0.75409836, 0.72131148, 0.7704918 , 0.73770492,\n",
       "        0.73770492, 0.73770492, 0.75409836, 0.75409836, 0.7704918 ,\n",
       "        0.78688525, 0.78688525, 0.75409836, 0.7704918 , 0.7704918 ,\n",
       "        0.7704918 , 0.75409836, 0.75409836, 0.73770492, 0.75409836]),\n",
       " 'split5_test_score': array([0.55737705, 0.55737705, 0.60655738, 0.55737705, 0.60655738,\n",
       "        0.60655738, 0.63934426, 0.60655738, 0.63934426, 0.63934426,\n",
       "        0.67213115, 0.6557377 , 0.62295082, 0.59016393, 0.6557377 ,\n",
       "        0.62295082, 0.6557377 , 0.60655738, 0.67213115, 0.67213115,\n",
       "        0.67213115, 0.67213115, 0.6557377 , 0.6557377 , 0.6557377 ,\n",
       "        0.6557377 , 0.67213115, 0.6557377 , 0.63934426, 0.63934426,\n",
       "        0.63934426, 0.62295082, 0.63934426, 0.62295082, 0.60655738,\n",
       "        0.62295082, 0.62295082, 0.62295082, 0.62295082, 0.60655738,\n",
       "        0.60655738, 0.60655738, 0.63934426, 0.59016393, 0.62295082,\n",
       "        0.62295082, 0.6557377 , 0.62295082, 0.67213115, 0.6557377 ,\n",
       "        0.6557377 , 0.63934426, 0.68852459, 0.6557377 , 0.68852459,\n",
       "        0.62295082, 0.67213115, 0.67213115, 0.70491803, 0.6557377 ,\n",
       "        0.62295082, 0.62295082, 0.63934426, 0.62295082, 0.63934426,\n",
       "        0.63934426, 0.63934426, 0.59016393, 0.63934426, 0.62295082,\n",
       "        0.68852459, 0.62295082, 0.68852459, 0.6557377 , 0.68852459,\n",
       "        0.70491803, 0.68852459, 0.67213115, 0.68852459, 0.67213115,\n",
       "        0.63934426, 0.63934426, 0.67213115, 0.63934426, 0.63934426,\n",
       "        0.62295082, 0.60655738, 0.60655738, 0.62295082, 0.59016393,\n",
       "        0.67213115, 0.63934426, 0.63934426, 0.62295082, 0.63934426,\n",
       "        0.63934426, 0.60655738, 0.62295082, 0.62295082, 0.62295082,\n",
       "        0.63934426, 0.63934426, 0.6557377 , 0.63934426, 0.68852459,\n",
       "        0.6557377 , 0.68852459, 0.67213115, 0.68852459, 0.67213115,\n",
       "        0.67213115, 0.6557377 , 0.6557377 , 0.6557377 , 0.67213115,\n",
       "        0.63934426, 0.6557377 , 0.63934426, 0.6557377 , 0.63934426,\n",
       "        0.55737705, 0.55737705, 0.60655738, 0.55737705, 0.60655738,\n",
       "        0.60655738, 0.63934426, 0.60655738, 0.63934426, 0.63934426,\n",
       "        0.67213115, 0.6557377 , 0.62295082, 0.59016393, 0.6557377 ,\n",
       "        0.62295082, 0.6557377 , 0.60655738, 0.67213115, 0.67213115,\n",
       "        0.67213115, 0.67213115, 0.6557377 , 0.6557377 , 0.6557377 ,\n",
       "        0.6557377 , 0.67213115, 0.6557377 , 0.63934426, 0.63934426,\n",
       "        0.63934426, 0.62295082, 0.63934426, 0.62295082, 0.60655738,\n",
       "        0.62295082, 0.62295082, 0.62295082, 0.62295082, 0.60655738,\n",
       "        0.60655738, 0.60655738, 0.63934426, 0.59016393, 0.62295082,\n",
       "        0.62295082, 0.6557377 , 0.62295082, 0.67213115, 0.6557377 ,\n",
       "        0.6557377 , 0.63934426, 0.68852459, 0.6557377 , 0.68852459,\n",
       "        0.62295082, 0.67213115, 0.67213115, 0.70491803, 0.6557377 ,\n",
       "        0.55737705, 0.55737705, 0.60655738, 0.55737705, 0.60655738,\n",
       "        0.60655738, 0.63934426, 0.60655738, 0.63934426, 0.63934426,\n",
       "        0.67213115, 0.6557377 , 0.62295082, 0.59016393, 0.6557377 ,\n",
       "        0.62295082, 0.6557377 , 0.60655738, 0.67213115, 0.67213115,\n",
       "        0.67213115, 0.67213115, 0.6557377 , 0.6557377 , 0.6557377 ,\n",
       "        0.6557377 , 0.67213115, 0.6557377 , 0.63934426, 0.63934426,\n",
       "        0.63934426, 0.62295082, 0.63934426, 0.62295082, 0.60655738,\n",
       "        0.62295082, 0.62295082, 0.62295082, 0.62295082, 0.60655738,\n",
       "        0.60655738, 0.60655738, 0.63934426, 0.59016393, 0.62295082,\n",
       "        0.62295082, 0.6557377 , 0.62295082, 0.67213115, 0.6557377 ,\n",
       "        0.6557377 , 0.63934426, 0.68852459, 0.6557377 , 0.68852459,\n",
       "        0.62295082, 0.67213115, 0.67213115, 0.70491803, 0.6557377 ,\n",
       "        0.62295082, 0.62295082, 0.63934426, 0.62295082, 0.63934426,\n",
       "        0.63934426, 0.63934426, 0.59016393, 0.63934426, 0.62295082,\n",
       "        0.68852459, 0.62295082, 0.68852459, 0.6557377 , 0.68852459,\n",
       "        0.70491803, 0.68852459, 0.67213115, 0.68852459, 0.67213115,\n",
       "        0.63934426, 0.63934426, 0.67213115, 0.63934426, 0.63934426,\n",
       "        0.62295082, 0.60655738, 0.60655738, 0.62295082, 0.59016393,\n",
       "        0.67213115, 0.63934426, 0.63934426, 0.62295082, 0.63934426,\n",
       "        0.63934426, 0.60655738, 0.62295082, 0.62295082, 0.62295082,\n",
       "        0.63934426, 0.63934426, 0.6557377 , 0.63934426, 0.68852459,\n",
       "        0.6557377 , 0.68852459, 0.67213115, 0.68852459, 0.67213115,\n",
       "        0.67213115, 0.6557377 , 0.6557377 , 0.6557377 , 0.67213115,\n",
       "        0.63934426, 0.6557377 , 0.63934426, 0.6557377 , 0.63934426,\n",
       "        0.55737705, 0.55737705, 0.60655738, 0.55737705, 0.60655738,\n",
       "        0.60655738, 0.63934426, 0.60655738, 0.63934426, 0.63934426,\n",
       "        0.67213115, 0.6557377 , 0.62295082, 0.59016393, 0.6557377 ,\n",
       "        0.62295082, 0.6557377 , 0.60655738, 0.67213115, 0.67213115,\n",
       "        0.67213115, 0.67213115, 0.6557377 , 0.6557377 , 0.6557377 ,\n",
       "        0.6557377 , 0.67213115, 0.6557377 , 0.63934426, 0.63934426,\n",
       "        0.63934426, 0.62295082, 0.63934426, 0.62295082, 0.60655738,\n",
       "        0.62295082, 0.62295082, 0.62295082, 0.62295082, 0.60655738,\n",
       "        0.60655738, 0.60655738, 0.63934426, 0.59016393, 0.62295082,\n",
       "        0.62295082, 0.6557377 , 0.62295082, 0.67213115, 0.6557377 ,\n",
       "        0.6557377 , 0.63934426, 0.68852459, 0.6557377 , 0.68852459,\n",
       "        0.62295082, 0.67213115, 0.67213115, 0.70491803, 0.6557377 ,\n",
       "        0.55737705, 0.55737705, 0.60655738, 0.55737705, 0.60655738,\n",
       "        0.60655738, 0.63934426, 0.60655738, 0.63934426, 0.63934426,\n",
       "        0.67213115, 0.6557377 , 0.62295082, 0.59016393, 0.6557377 ,\n",
       "        0.62295082, 0.6557377 , 0.60655738, 0.67213115, 0.67213115,\n",
       "        0.67213115, 0.67213115, 0.6557377 , 0.6557377 , 0.6557377 ,\n",
       "        0.6557377 , 0.67213115, 0.6557377 , 0.63934426, 0.63934426,\n",
       "        0.63934426, 0.62295082, 0.63934426, 0.62295082, 0.60655738,\n",
       "        0.62295082, 0.62295082, 0.62295082, 0.62295082, 0.60655738,\n",
       "        0.60655738, 0.60655738, 0.63934426, 0.59016393, 0.62295082,\n",
       "        0.62295082, 0.6557377 , 0.62295082, 0.67213115, 0.6557377 ,\n",
       "        0.6557377 , 0.63934426, 0.68852459, 0.6557377 , 0.68852459,\n",
       "        0.62295082, 0.67213115, 0.67213115, 0.70491803, 0.6557377 ,\n",
       "        0.62295082, 0.62295082, 0.63934426, 0.62295082, 0.63934426,\n",
       "        0.63934426, 0.63934426, 0.59016393, 0.63934426, 0.62295082,\n",
       "        0.68852459, 0.62295082, 0.68852459, 0.6557377 , 0.68852459,\n",
       "        0.70491803, 0.68852459, 0.67213115, 0.68852459, 0.67213115,\n",
       "        0.63934426, 0.63934426, 0.67213115, 0.63934426, 0.63934426,\n",
       "        0.62295082, 0.60655738, 0.60655738, 0.62295082, 0.59016393,\n",
       "        0.67213115, 0.63934426, 0.63934426, 0.62295082, 0.63934426,\n",
       "        0.63934426, 0.60655738, 0.62295082, 0.62295082, 0.62295082,\n",
       "        0.63934426, 0.63934426, 0.6557377 , 0.63934426, 0.68852459,\n",
       "        0.6557377 , 0.68852459, 0.67213115, 0.68852459, 0.67213115,\n",
       "        0.67213115, 0.6557377 , 0.6557377 , 0.6557377 , 0.67213115,\n",
       "        0.63934426, 0.6557377 , 0.63934426, 0.6557377 , 0.63934426,\n",
       "        0.55737705, 0.55737705, 0.60655738, 0.55737705, 0.60655738,\n",
       "        0.60655738, 0.63934426, 0.60655738, 0.63934426, 0.63934426,\n",
       "        0.67213115, 0.6557377 , 0.62295082, 0.59016393, 0.6557377 ,\n",
       "        0.62295082, 0.6557377 , 0.60655738, 0.67213115, 0.67213115,\n",
       "        0.67213115, 0.67213115, 0.6557377 , 0.6557377 , 0.6557377 ,\n",
       "        0.6557377 , 0.67213115, 0.6557377 , 0.63934426, 0.63934426,\n",
       "        0.63934426, 0.62295082, 0.63934426, 0.62295082, 0.60655738,\n",
       "        0.62295082, 0.62295082, 0.62295082, 0.62295082, 0.60655738,\n",
       "        0.60655738, 0.60655738, 0.63934426, 0.59016393, 0.62295082,\n",
       "        0.62295082, 0.6557377 , 0.62295082, 0.67213115, 0.6557377 ,\n",
       "        0.6557377 , 0.63934426, 0.68852459, 0.6557377 , 0.68852459,\n",
       "        0.62295082, 0.67213115, 0.67213115, 0.70491803, 0.6557377 ,\n",
       "        0.55737705, 0.55737705, 0.60655738, 0.55737705, 0.60655738,\n",
       "        0.60655738, 0.63934426, 0.60655738, 0.63934426, 0.63934426,\n",
       "        0.67213115, 0.6557377 , 0.62295082, 0.59016393, 0.6557377 ,\n",
       "        0.62295082, 0.6557377 , 0.60655738, 0.67213115, 0.67213115,\n",
       "        0.67213115, 0.67213115, 0.6557377 , 0.6557377 , 0.6557377 ,\n",
       "        0.6557377 , 0.67213115, 0.6557377 , 0.63934426, 0.63934426,\n",
       "        0.63934426, 0.62295082, 0.63934426, 0.62295082, 0.60655738,\n",
       "        0.62295082, 0.62295082, 0.62295082, 0.62295082, 0.60655738,\n",
       "        0.60655738, 0.60655738, 0.63934426, 0.59016393, 0.62295082,\n",
       "        0.62295082, 0.6557377 , 0.62295082, 0.67213115, 0.6557377 ,\n",
       "        0.6557377 , 0.63934426, 0.68852459, 0.6557377 , 0.68852459,\n",
       "        0.62295082, 0.67213115, 0.67213115, 0.70491803, 0.6557377 ,\n",
       "        0.62295082, 0.62295082, 0.63934426, 0.62295082, 0.63934426,\n",
       "        0.63934426, 0.63934426, 0.59016393, 0.63934426, 0.62295082,\n",
       "        0.68852459, 0.62295082, 0.68852459, 0.6557377 , 0.68852459,\n",
       "        0.70491803, 0.68852459, 0.67213115, 0.68852459, 0.67213115,\n",
       "        0.63934426, 0.63934426, 0.67213115, 0.63934426, 0.63934426,\n",
       "        0.62295082, 0.60655738, 0.60655738, 0.62295082, 0.59016393,\n",
       "        0.67213115, 0.63934426, 0.63934426, 0.62295082, 0.63934426,\n",
       "        0.63934426, 0.60655738, 0.62295082, 0.62295082, 0.62295082,\n",
       "        0.63934426, 0.63934426, 0.6557377 , 0.63934426, 0.68852459,\n",
       "        0.6557377 , 0.68852459, 0.67213115, 0.68852459, 0.67213115,\n",
       "        0.67213115, 0.6557377 , 0.6557377 , 0.6557377 , 0.67213115,\n",
       "        0.63934426, 0.6557377 , 0.63934426, 0.6557377 , 0.63934426,\n",
       "        0.55737705, 0.55737705, 0.60655738, 0.55737705, 0.60655738,\n",
       "        0.60655738, 0.63934426, 0.60655738, 0.63934426, 0.63934426,\n",
       "        0.67213115, 0.6557377 , 0.62295082, 0.59016393, 0.6557377 ,\n",
       "        0.62295082, 0.6557377 , 0.60655738, 0.67213115, 0.67213115,\n",
       "        0.67213115, 0.67213115, 0.6557377 , 0.6557377 , 0.6557377 ,\n",
       "        0.6557377 , 0.67213115, 0.6557377 , 0.63934426, 0.63934426,\n",
       "        0.63934426, 0.62295082, 0.63934426, 0.62295082, 0.60655738,\n",
       "        0.62295082, 0.62295082, 0.62295082, 0.62295082, 0.60655738,\n",
       "        0.60655738, 0.60655738, 0.63934426, 0.59016393, 0.62295082,\n",
       "        0.62295082, 0.6557377 , 0.62295082, 0.67213115, 0.6557377 ,\n",
       "        0.6557377 , 0.63934426, 0.68852459, 0.6557377 , 0.68852459,\n",
       "        0.62295082, 0.67213115, 0.67213115, 0.70491803, 0.6557377 ]),\n",
       " 'split6_test_score': array([0.70491803, 0.70491803, 0.72131148, 0.70491803, 0.70491803,\n",
       "        0.72131148, 0.75409836, 0.72131148, 0.70491803, 0.72131148,\n",
       "        0.75409836, 0.78688525, 0.72131148, 0.75409836, 0.7704918 ,\n",
       "        0.73770492, 0.7704918 , 0.7704918 , 0.78688525, 0.78688525,\n",
       "        0.80327869, 0.80327869, 0.80327869, 0.80327869, 0.81967213,\n",
       "        0.80327869, 0.85245902, 0.86885246, 0.8852459 , 0.8852459 ,\n",
       "        0.80327869, 0.86885246, 0.81967213, 0.81967213, 0.80327869,\n",
       "        0.86885246, 0.80327869, 0.80327869, 0.78688525, 0.85245902,\n",
       "        0.83606557, 0.83606557, 0.80327869, 0.83606557, 0.83606557,\n",
       "        0.83606557, 0.83606557, 0.83606557, 0.81967213, 0.81967213,\n",
       "        0.86885246, 0.83606557, 0.83606557, 0.83606557, 0.80327869,\n",
       "        0.81967213, 0.83606557, 0.83606557, 0.83606557, 0.81967213,\n",
       "        0.67213115, 0.67213115, 0.75409836, 0.67213115, 0.75409836,\n",
       "        0.75409836, 0.72131148, 0.73770492, 0.7704918 , 0.78688525,\n",
       "        0.73770492, 0.78688525, 0.75409836, 0.7704918 , 0.72131148,\n",
       "        0.78688525, 0.80327869, 0.80327869, 0.81967213, 0.78688525,\n",
       "        0.80327869, 0.80327869, 0.81967213, 0.81967213, 0.83606557,\n",
       "        0.83606557, 0.85245902, 0.83606557, 0.83606557, 0.83606557,\n",
       "        0.80327869, 0.81967213, 0.78688525, 0.78688525, 0.78688525,\n",
       "        0.78688525, 0.78688525, 0.78688525, 0.78688525, 0.7704918 ,\n",
       "        0.78688525, 0.78688525, 0.80327869, 0.78688525, 0.78688525,\n",
       "        0.78688525, 0.7704918 , 0.78688525, 0.80327869, 0.81967213,\n",
       "        0.78688525, 0.78688525, 0.80327869, 0.80327869, 0.78688525,\n",
       "        0.78688525, 0.80327869, 0.81967213, 0.78688525, 0.80327869,\n",
       "        0.70491803, 0.70491803, 0.72131148, 0.70491803, 0.70491803,\n",
       "        0.72131148, 0.75409836, 0.72131148, 0.70491803, 0.72131148,\n",
       "        0.75409836, 0.78688525, 0.72131148, 0.75409836, 0.7704918 ,\n",
       "        0.73770492, 0.7704918 , 0.7704918 , 0.78688525, 0.78688525,\n",
       "        0.80327869, 0.80327869, 0.80327869, 0.80327869, 0.81967213,\n",
       "        0.80327869, 0.85245902, 0.86885246, 0.8852459 , 0.8852459 ,\n",
       "        0.80327869, 0.86885246, 0.81967213, 0.81967213, 0.80327869,\n",
       "        0.86885246, 0.80327869, 0.80327869, 0.78688525, 0.85245902,\n",
       "        0.83606557, 0.83606557, 0.80327869, 0.83606557, 0.83606557,\n",
       "        0.83606557, 0.83606557, 0.83606557, 0.81967213, 0.81967213,\n",
       "        0.86885246, 0.83606557, 0.83606557, 0.83606557, 0.80327869,\n",
       "        0.81967213, 0.83606557, 0.83606557, 0.83606557, 0.81967213,\n",
       "        0.70491803, 0.70491803, 0.72131148, 0.70491803, 0.70491803,\n",
       "        0.72131148, 0.75409836, 0.72131148, 0.70491803, 0.72131148,\n",
       "        0.75409836, 0.78688525, 0.72131148, 0.75409836, 0.7704918 ,\n",
       "        0.73770492, 0.7704918 , 0.7704918 , 0.78688525, 0.78688525,\n",
       "        0.80327869, 0.80327869, 0.80327869, 0.80327869, 0.81967213,\n",
       "        0.80327869, 0.85245902, 0.86885246, 0.8852459 , 0.8852459 ,\n",
       "        0.80327869, 0.86885246, 0.81967213, 0.81967213, 0.80327869,\n",
       "        0.86885246, 0.80327869, 0.80327869, 0.78688525, 0.85245902,\n",
       "        0.83606557, 0.83606557, 0.80327869, 0.83606557, 0.83606557,\n",
       "        0.83606557, 0.83606557, 0.83606557, 0.81967213, 0.81967213,\n",
       "        0.86885246, 0.83606557, 0.83606557, 0.83606557, 0.80327869,\n",
       "        0.81967213, 0.83606557, 0.83606557, 0.83606557, 0.81967213,\n",
       "        0.67213115, 0.67213115, 0.75409836, 0.67213115, 0.75409836,\n",
       "        0.75409836, 0.72131148, 0.73770492, 0.7704918 , 0.78688525,\n",
       "        0.73770492, 0.78688525, 0.75409836, 0.7704918 , 0.72131148,\n",
       "        0.78688525, 0.80327869, 0.80327869, 0.81967213, 0.78688525,\n",
       "        0.80327869, 0.80327869, 0.81967213, 0.81967213, 0.83606557,\n",
       "        0.83606557, 0.85245902, 0.83606557, 0.83606557, 0.83606557,\n",
       "        0.80327869, 0.81967213, 0.78688525, 0.78688525, 0.78688525,\n",
       "        0.78688525, 0.78688525, 0.78688525, 0.78688525, 0.7704918 ,\n",
       "        0.78688525, 0.78688525, 0.80327869, 0.78688525, 0.78688525,\n",
       "        0.78688525, 0.7704918 , 0.78688525, 0.80327869, 0.81967213,\n",
       "        0.78688525, 0.78688525, 0.80327869, 0.80327869, 0.78688525,\n",
       "        0.78688525, 0.80327869, 0.81967213, 0.78688525, 0.80327869,\n",
       "        0.70491803, 0.70491803, 0.72131148, 0.70491803, 0.70491803,\n",
       "        0.72131148, 0.75409836, 0.72131148, 0.70491803, 0.72131148,\n",
       "        0.75409836, 0.78688525, 0.72131148, 0.75409836, 0.7704918 ,\n",
       "        0.73770492, 0.7704918 , 0.7704918 , 0.78688525, 0.78688525,\n",
       "        0.80327869, 0.80327869, 0.80327869, 0.80327869, 0.81967213,\n",
       "        0.80327869, 0.85245902, 0.86885246, 0.8852459 , 0.8852459 ,\n",
       "        0.80327869, 0.86885246, 0.81967213, 0.81967213, 0.80327869,\n",
       "        0.86885246, 0.80327869, 0.80327869, 0.78688525, 0.85245902,\n",
       "        0.83606557, 0.83606557, 0.80327869, 0.83606557, 0.83606557,\n",
       "        0.83606557, 0.83606557, 0.83606557, 0.81967213, 0.81967213,\n",
       "        0.86885246, 0.83606557, 0.83606557, 0.83606557, 0.80327869,\n",
       "        0.81967213, 0.83606557, 0.83606557, 0.83606557, 0.81967213,\n",
       "        0.70491803, 0.70491803, 0.72131148, 0.70491803, 0.70491803,\n",
       "        0.72131148, 0.75409836, 0.72131148, 0.70491803, 0.72131148,\n",
       "        0.75409836, 0.78688525, 0.72131148, 0.75409836, 0.7704918 ,\n",
       "        0.73770492, 0.7704918 , 0.7704918 , 0.78688525, 0.78688525,\n",
       "        0.80327869, 0.80327869, 0.80327869, 0.80327869, 0.81967213,\n",
       "        0.80327869, 0.85245902, 0.86885246, 0.8852459 , 0.8852459 ,\n",
       "        0.80327869, 0.86885246, 0.81967213, 0.81967213, 0.80327869,\n",
       "        0.86885246, 0.80327869, 0.80327869, 0.78688525, 0.85245902,\n",
       "        0.83606557, 0.83606557, 0.80327869, 0.83606557, 0.83606557,\n",
       "        0.83606557, 0.83606557, 0.83606557, 0.81967213, 0.81967213,\n",
       "        0.86885246, 0.83606557, 0.83606557, 0.83606557, 0.80327869,\n",
       "        0.81967213, 0.83606557, 0.83606557, 0.83606557, 0.81967213,\n",
       "        0.67213115, 0.67213115, 0.75409836, 0.67213115, 0.75409836,\n",
       "        0.75409836, 0.72131148, 0.73770492, 0.7704918 , 0.78688525,\n",
       "        0.73770492, 0.78688525, 0.75409836, 0.7704918 , 0.72131148,\n",
       "        0.78688525, 0.80327869, 0.80327869, 0.81967213, 0.78688525,\n",
       "        0.80327869, 0.80327869, 0.81967213, 0.81967213, 0.83606557,\n",
       "        0.83606557, 0.85245902, 0.83606557, 0.83606557, 0.83606557,\n",
       "        0.80327869, 0.81967213, 0.78688525, 0.78688525, 0.78688525,\n",
       "        0.78688525, 0.78688525, 0.78688525, 0.78688525, 0.7704918 ,\n",
       "        0.78688525, 0.78688525, 0.80327869, 0.78688525, 0.78688525,\n",
       "        0.78688525, 0.7704918 , 0.78688525, 0.80327869, 0.81967213,\n",
       "        0.78688525, 0.78688525, 0.80327869, 0.80327869, 0.78688525,\n",
       "        0.78688525, 0.80327869, 0.81967213, 0.78688525, 0.80327869,\n",
       "        0.70491803, 0.70491803, 0.72131148, 0.70491803, 0.70491803,\n",
       "        0.72131148, 0.75409836, 0.72131148, 0.70491803, 0.72131148,\n",
       "        0.75409836, 0.78688525, 0.72131148, 0.75409836, 0.7704918 ,\n",
       "        0.73770492, 0.7704918 , 0.7704918 , 0.78688525, 0.78688525,\n",
       "        0.80327869, 0.80327869, 0.80327869, 0.80327869, 0.81967213,\n",
       "        0.80327869, 0.85245902, 0.86885246, 0.8852459 , 0.8852459 ,\n",
       "        0.80327869, 0.86885246, 0.81967213, 0.81967213, 0.80327869,\n",
       "        0.86885246, 0.80327869, 0.80327869, 0.78688525, 0.85245902,\n",
       "        0.83606557, 0.83606557, 0.80327869, 0.83606557, 0.83606557,\n",
       "        0.83606557, 0.83606557, 0.83606557, 0.81967213, 0.81967213,\n",
       "        0.86885246, 0.83606557, 0.83606557, 0.83606557, 0.80327869,\n",
       "        0.81967213, 0.83606557, 0.83606557, 0.83606557, 0.81967213,\n",
       "        0.70491803, 0.70491803, 0.72131148, 0.70491803, 0.70491803,\n",
       "        0.72131148, 0.75409836, 0.72131148, 0.70491803, 0.72131148,\n",
       "        0.75409836, 0.78688525, 0.72131148, 0.75409836, 0.7704918 ,\n",
       "        0.73770492, 0.7704918 , 0.7704918 , 0.78688525, 0.78688525,\n",
       "        0.80327869, 0.80327869, 0.80327869, 0.80327869, 0.81967213,\n",
       "        0.80327869, 0.85245902, 0.86885246, 0.8852459 , 0.8852459 ,\n",
       "        0.80327869, 0.86885246, 0.81967213, 0.81967213, 0.80327869,\n",
       "        0.86885246, 0.80327869, 0.80327869, 0.78688525, 0.85245902,\n",
       "        0.83606557, 0.83606557, 0.80327869, 0.83606557, 0.83606557,\n",
       "        0.83606557, 0.83606557, 0.83606557, 0.81967213, 0.81967213,\n",
       "        0.86885246, 0.83606557, 0.83606557, 0.83606557, 0.80327869,\n",
       "        0.81967213, 0.83606557, 0.83606557, 0.83606557, 0.81967213,\n",
       "        0.67213115, 0.67213115, 0.75409836, 0.67213115, 0.75409836,\n",
       "        0.75409836, 0.72131148, 0.73770492, 0.7704918 , 0.78688525,\n",
       "        0.73770492, 0.78688525, 0.75409836, 0.7704918 , 0.72131148,\n",
       "        0.78688525, 0.80327869, 0.80327869, 0.81967213, 0.78688525,\n",
       "        0.80327869, 0.80327869, 0.81967213, 0.81967213, 0.83606557,\n",
       "        0.83606557, 0.85245902, 0.83606557, 0.83606557, 0.83606557,\n",
       "        0.80327869, 0.81967213, 0.78688525, 0.78688525, 0.78688525,\n",
       "        0.78688525, 0.78688525, 0.78688525, 0.78688525, 0.7704918 ,\n",
       "        0.78688525, 0.78688525, 0.80327869, 0.78688525, 0.78688525,\n",
       "        0.78688525, 0.7704918 , 0.78688525, 0.80327869, 0.81967213,\n",
       "        0.78688525, 0.78688525, 0.80327869, 0.80327869, 0.78688525,\n",
       "        0.78688525, 0.80327869, 0.81967213, 0.78688525, 0.80327869,\n",
       "        0.70491803, 0.70491803, 0.72131148, 0.70491803, 0.70491803,\n",
       "        0.72131148, 0.75409836, 0.72131148, 0.70491803, 0.72131148,\n",
       "        0.75409836, 0.78688525, 0.72131148, 0.75409836, 0.7704918 ,\n",
       "        0.73770492, 0.7704918 , 0.7704918 , 0.78688525, 0.78688525,\n",
       "        0.80327869, 0.80327869, 0.80327869, 0.80327869, 0.81967213,\n",
       "        0.80327869, 0.85245902, 0.86885246, 0.8852459 , 0.8852459 ,\n",
       "        0.80327869, 0.86885246, 0.81967213, 0.81967213, 0.80327869,\n",
       "        0.86885246, 0.80327869, 0.80327869, 0.78688525, 0.85245902,\n",
       "        0.83606557, 0.83606557, 0.80327869, 0.83606557, 0.83606557,\n",
       "        0.83606557, 0.83606557, 0.83606557, 0.81967213, 0.81967213,\n",
       "        0.86885246, 0.83606557, 0.83606557, 0.83606557, 0.80327869,\n",
       "        0.81967213, 0.83606557, 0.83606557, 0.83606557, 0.81967213]),\n",
       " 'split7_test_score': array([0.73770492, 0.73770492, 0.67213115, 0.73770492, 0.72131148,\n",
       "        0.70491803, 0.67213115, 0.73770492, 0.70491803, 0.70491803,\n",
       "        0.72131148, 0.78688525, 0.80327869, 0.80327869, 0.83606557,\n",
       "        0.78688525, 0.81967213, 0.81967213, 0.80327869, 0.81967213,\n",
       "        0.80327869, 0.78688525, 0.7704918 , 0.78688525, 0.80327869,\n",
       "        0.78688525, 0.78688525, 0.80327869, 0.75409836, 0.75409836,\n",
       "        0.73770492, 0.7704918 , 0.73770492, 0.73770492, 0.7704918 ,\n",
       "        0.75409836, 0.7704918 , 0.7704918 , 0.78688525, 0.75409836,\n",
       "        0.78688525, 0.78688525, 0.75409836, 0.7704918 , 0.78688525,\n",
       "        0.80327869, 0.7704918 , 0.78688525, 0.78688525, 0.80327869,\n",
       "        0.78688525, 0.7704918 , 0.7704918 , 0.7704918 , 0.78688525,\n",
       "        0.78688525, 0.80327869, 0.80327869, 0.7704918 , 0.80327869,\n",
       "        0.72131148, 0.72131148, 0.70491803, 0.72131148, 0.75409836,\n",
       "        0.75409836, 0.72131148, 0.73770492, 0.72131148, 0.72131148,\n",
       "        0.72131148, 0.73770492, 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "        0.75409836, 0.78688525, 0.78688525, 0.78688525, 0.7704918 ,\n",
       "        0.78688525, 0.78688525, 0.83606557, 0.7704918 , 0.78688525,\n",
       "        0.78688525, 0.7704918 , 0.7704918 , 0.73770492, 0.73770492,\n",
       "        0.7704918 , 0.78688525, 0.78688525, 0.78688525, 0.80327869,\n",
       "        0.7704918 , 0.80327869, 0.80327869, 0.81967213, 0.78688525,\n",
       "        0.78688525, 0.78688525, 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "        0.7704918 , 0.75409836, 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "        0.75409836, 0.75409836, 0.75409836, 0.75409836, 0.7704918 ,\n",
       "        0.75409836, 0.78688525, 0.78688525, 0.7704918 , 0.7704918 ,\n",
       "        0.73770492, 0.73770492, 0.67213115, 0.73770492, 0.72131148,\n",
       "        0.70491803, 0.67213115, 0.73770492, 0.70491803, 0.70491803,\n",
       "        0.72131148, 0.78688525, 0.80327869, 0.80327869, 0.83606557,\n",
       "        0.78688525, 0.81967213, 0.81967213, 0.80327869, 0.81967213,\n",
       "        0.80327869, 0.78688525, 0.7704918 , 0.78688525, 0.80327869,\n",
       "        0.78688525, 0.78688525, 0.80327869, 0.75409836, 0.75409836,\n",
       "        0.73770492, 0.7704918 , 0.73770492, 0.73770492, 0.7704918 ,\n",
       "        0.75409836, 0.7704918 , 0.7704918 , 0.78688525, 0.75409836,\n",
       "        0.78688525, 0.78688525, 0.75409836, 0.7704918 , 0.78688525,\n",
       "        0.80327869, 0.7704918 , 0.78688525, 0.78688525, 0.80327869,\n",
       "        0.78688525, 0.7704918 , 0.7704918 , 0.7704918 , 0.78688525,\n",
       "        0.78688525, 0.80327869, 0.80327869, 0.7704918 , 0.80327869,\n",
       "        0.73770492, 0.73770492, 0.67213115, 0.73770492, 0.72131148,\n",
       "        0.70491803, 0.67213115, 0.73770492, 0.70491803, 0.70491803,\n",
       "        0.72131148, 0.78688525, 0.80327869, 0.80327869, 0.83606557,\n",
       "        0.78688525, 0.81967213, 0.81967213, 0.80327869, 0.81967213,\n",
       "        0.80327869, 0.78688525, 0.7704918 , 0.78688525, 0.80327869,\n",
       "        0.78688525, 0.78688525, 0.80327869, 0.75409836, 0.75409836,\n",
       "        0.73770492, 0.7704918 , 0.73770492, 0.73770492, 0.7704918 ,\n",
       "        0.75409836, 0.7704918 , 0.7704918 , 0.78688525, 0.75409836,\n",
       "        0.78688525, 0.78688525, 0.75409836, 0.7704918 , 0.78688525,\n",
       "        0.80327869, 0.7704918 , 0.78688525, 0.78688525, 0.80327869,\n",
       "        0.78688525, 0.7704918 , 0.7704918 , 0.7704918 , 0.78688525,\n",
       "        0.78688525, 0.80327869, 0.80327869, 0.7704918 , 0.80327869,\n",
       "        0.72131148, 0.72131148, 0.70491803, 0.72131148, 0.75409836,\n",
       "        0.75409836, 0.72131148, 0.73770492, 0.72131148, 0.72131148,\n",
       "        0.72131148, 0.73770492, 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "        0.75409836, 0.78688525, 0.78688525, 0.78688525, 0.7704918 ,\n",
       "        0.78688525, 0.78688525, 0.83606557, 0.7704918 , 0.78688525,\n",
       "        0.78688525, 0.7704918 , 0.7704918 , 0.73770492, 0.73770492,\n",
       "        0.7704918 , 0.78688525, 0.78688525, 0.78688525, 0.80327869,\n",
       "        0.7704918 , 0.80327869, 0.80327869, 0.81967213, 0.78688525,\n",
       "        0.78688525, 0.78688525, 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "        0.7704918 , 0.75409836, 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "        0.75409836, 0.75409836, 0.75409836, 0.75409836, 0.7704918 ,\n",
       "        0.75409836, 0.78688525, 0.78688525, 0.7704918 , 0.7704918 ,\n",
       "        0.73770492, 0.73770492, 0.67213115, 0.73770492, 0.72131148,\n",
       "        0.70491803, 0.67213115, 0.73770492, 0.70491803, 0.70491803,\n",
       "        0.72131148, 0.78688525, 0.80327869, 0.80327869, 0.83606557,\n",
       "        0.78688525, 0.81967213, 0.81967213, 0.80327869, 0.81967213,\n",
       "        0.80327869, 0.78688525, 0.7704918 , 0.78688525, 0.80327869,\n",
       "        0.78688525, 0.78688525, 0.80327869, 0.75409836, 0.75409836,\n",
       "        0.73770492, 0.7704918 , 0.73770492, 0.73770492, 0.7704918 ,\n",
       "        0.75409836, 0.7704918 , 0.7704918 , 0.78688525, 0.75409836,\n",
       "        0.78688525, 0.78688525, 0.75409836, 0.7704918 , 0.78688525,\n",
       "        0.80327869, 0.7704918 , 0.78688525, 0.78688525, 0.80327869,\n",
       "        0.78688525, 0.7704918 , 0.7704918 , 0.7704918 , 0.78688525,\n",
       "        0.78688525, 0.80327869, 0.80327869, 0.7704918 , 0.80327869,\n",
       "        0.73770492, 0.73770492, 0.67213115, 0.73770492, 0.72131148,\n",
       "        0.70491803, 0.67213115, 0.73770492, 0.70491803, 0.70491803,\n",
       "        0.72131148, 0.78688525, 0.80327869, 0.80327869, 0.83606557,\n",
       "        0.78688525, 0.81967213, 0.81967213, 0.80327869, 0.81967213,\n",
       "        0.80327869, 0.78688525, 0.7704918 , 0.78688525, 0.80327869,\n",
       "        0.78688525, 0.78688525, 0.80327869, 0.75409836, 0.75409836,\n",
       "        0.73770492, 0.7704918 , 0.73770492, 0.73770492, 0.7704918 ,\n",
       "        0.75409836, 0.7704918 , 0.7704918 , 0.78688525, 0.75409836,\n",
       "        0.78688525, 0.78688525, 0.75409836, 0.7704918 , 0.78688525,\n",
       "        0.80327869, 0.7704918 , 0.78688525, 0.78688525, 0.80327869,\n",
       "        0.78688525, 0.7704918 , 0.7704918 , 0.7704918 , 0.78688525,\n",
       "        0.78688525, 0.80327869, 0.80327869, 0.7704918 , 0.80327869,\n",
       "        0.72131148, 0.72131148, 0.70491803, 0.72131148, 0.75409836,\n",
       "        0.75409836, 0.72131148, 0.73770492, 0.72131148, 0.72131148,\n",
       "        0.72131148, 0.73770492, 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "        0.75409836, 0.78688525, 0.78688525, 0.78688525, 0.7704918 ,\n",
       "        0.78688525, 0.78688525, 0.83606557, 0.7704918 , 0.78688525,\n",
       "        0.78688525, 0.7704918 , 0.7704918 , 0.73770492, 0.73770492,\n",
       "        0.7704918 , 0.78688525, 0.78688525, 0.78688525, 0.80327869,\n",
       "        0.7704918 , 0.80327869, 0.80327869, 0.81967213, 0.78688525,\n",
       "        0.78688525, 0.78688525, 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "        0.7704918 , 0.75409836, 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "        0.75409836, 0.75409836, 0.75409836, 0.75409836, 0.7704918 ,\n",
       "        0.75409836, 0.78688525, 0.78688525, 0.7704918 , 0.7704918 ,\n",
       "        0.73770492, 0.73770492, 0.67213115, 0.73770492, 0.72131148,\n",
       "        0.70491803, 0.67213115, 0.73770492, 0.70491803, 0.70491803,\n",
       "        0.72131148, 0.78688525, 0.80327869, 0.80327869, 0.83606557,\n",
       "        0.78688525, 0.81967213, 0.81967213, 0.80327869, 0.81967213,\n",
       "        0.80327869, 0.78688525, 0.7704918 , 0.78688525, 0.80327869,\n",
       "        0.78688525, 0.78688525, 0.80327869, 0.75409836, 0.75409836,\n",
       "        0.73770492, 0.7704918 , 0.73770492, 0.73770492, 0.7704918 ,\n",
       "        0.75409836, 0.7704918 , 0.7704918 , 0.78688525, 0.75409836,\n",
       "        0.78688525, 0.78688525, 0.75409836, 0.7704918 , 0.78688525,\n",
       "        0.80327869, 0.7704918 , 0.78688525, 0.78688525, 0.80327869,\n",
       "        0.78688525, 0.7704918 , 0.7704918 , 0.7704918 , 0.78688525,\n",
       "        0.78688525, 0.80327869, 0.80327869, 0.7704918 , 0.80327869,\n",
       "        0.73770492, 0.73770492, 0.67213115, 0.73770492, 0.72131148,\n",
       "        0.70491803, 0.67213115, 0.73770492, 0.70491803, 0.70491803,\n",
       "        0.72131148, 0.78688525, 0.80327869, 0.80327869, 0.83606557,\n",
       "        0.78688525, 0.81967213, 0.81967213, 0.80327869, 0.81967213,\n",
       "        0.80327869, 0.78688525, 0.7704918 , 0.78688525, 0.80327869,\n",
       "        0.78688525, 0.78688525, 0.80327869, 0.75409836, 0.75409836,\n",
       "        0.73770492, 0.7704918 , 0.73770492, 0.73770492, 0.7704918 ,\n",
       "        0.75409836, 0.7704918 , 0.7704918 , 0.78688525, 0.75409836,\n",
       "        0.78688525, 0.78688525, 0.75409836, 0.7704918 , 0.78688525,\n",
       "        0.80327869, 0.7704918 , 0.78688525, 0.78688525, 0.80327869,\n",
       "        0.78688525, 0.7704918 , 0.7704918 , 0.7704918 , 0.78688525,\n",
       "        0.78688525, 0.80327869, 0.80327869, 0.7704918 , 0.80327869,\n",
       "        0.72131148, 0.72131148, 0.70491803, 0.72131148, 0.75409836,\n",
       "        0.75409836, 0.72131148, 0.73770492, 0.72131148, 0.72131148,\n",
       "        0.72131148, 0.73770492, 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "        0.75409836, 0.78688525, 0.78688525, 0.78688525, 0.7704918 ,\n",
       "        0.78688525, 0.78688525, 0.83606557, 0.7704918 , 0.78688525,\n",
       "        0.78688525, 0.7704918 , 0.7704918 , 0.73770492, 0.73770492,\n",
       "        0.7704918 , 0.78688525, 0.78688525, 0.78688525, 0.80327869,\n",
       "        0.7704918 , 0.80327869, 0.80327869, 0.81967213, 0.78688525,\n",
       "        0.78688525, 0.78688525, 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "        0.7704918 , 0.75409836, 0.7704918 , 0.7704918 , 0.7704918 ,\n",
       "        0.75409836, 0.75409836, 0.75409836, 0.75409836, 0.7704918 ,\n",
       "        0.75409836, 0.78688525, 0.78688525, 0.7704918 , 0.7704918 ,\n",
       "        0.73770492, 0.73770492, 0.67213115, 0.73770492, 0.72131148,\n",
       "        0.70491803, 0.67213115, 0.73770492, 0.70491803, 0.70491803,\n",
       "        0.72131148, 0.78688525, 0.80327869, 0.80327869, 0.83606557,\n",
       "        0.78688525, 0.81967213, 0.81967213, 0.80327869, 0.81967213,\n",
       "        0.80327869, 0.78688525, 0.7704918 , 0.78688525, 0.80327869,\n",
       "        0.78688525, 0.78688525, 0.80327869, 0.75409836, 0.75409836,\n",
       "        0.73770492, 0.7704918 , 0.73770492, 0.73770492, 0.7704918 ,\n",
       "        0.75409836, 0.7704918 , 0.7704918 , 0.78688525, 0.75409836,\n",
       "        0.78688525, 0.78688525, 0.75409836, 0.7704918 , 0.78688525,\n",
       "        0.80327869, 0.7704918 , 0.78688525, 0.78688525, 0.80327869,\n",
       "        0.78688525, 0.7704918 , 0.7704918 , 0.7704918 , 0.78688525,\n",
       "        0.78688525, 0.80327869, 0.80327869, 0.7704918 , 0.80327869]),\n",
       " 'split8_test_score': array([0.70491803, 0.70491803, 0.75409836, 0.70491803, 0.78688525,\n",
       "        0.7704918 , 0.73770492, 0.78688525, 0.72131148, 0.70491803,\n",
       "        0.68852459, 0.75409836, 0.73770492, 0.73770492, 0.73770492,\n",
       "        0.75409836, 0.73770492, 0.73770492, 0.72131148, 0.7704918 ,\n",
       "        0.73770492, 0.73770492, 0.73770492, 0.75409836, 0.75409836,\n",
       "        0.75409836, 0.73770492, 0.75409836, 0.78688525, 0.7704918 ,\n",
       "        0.78688525, 0.7704918 , 0.80327869, 0.7704918 , 0.78688525,\n",
       "        0.78688525, 0.80327869, 0.7704918 , 0.7704918 , 0.78688525,\n",
       "        0.7704918 , 0.7704918 , 0.7704918 , 0.78688525, 0.78688525,\n",
       "        0.7704918 , 0.75409836, 0.7704918 , 0.73770492, 0.75409836,\n",
       "        0.75409836, 0.78688525, 0.7704918 , 0.75409836, 0.75409836,\n",
       "        0.7704918 , 0.75409836, 0.7704918 , 0.75409836, 0.7704918 ,\n",
       "        0.73770492, 0.73770492, 0.73770492, 0.73770492, 0.75409836,\n",
       "        0.73770492, 0.72131148, 0.7704918 , 0.80327869, 0.78688525,\n",
       "        0.7704918 , 0.7704918 , 0.78688525, 0.7704918 , 0.73770492,\n",
       "        0.78688525, 0.7704918 , 0.75409836, 0.73770492, 0.7704918 ,\n",
       "        0.7704918 , 0.7704918 , 0.75409836, 0.78688525, 0.7704918 ,\n",
       "        0.7704918 , 0.73770492, 0.78688525, 0.7704918 , 0.78688525,\n",
       "        0.75409836, 0.75409836, 0.75409836, 0.7704918 , 0.7704918 ,\n",
       "        0.7704918 , 0.78688525, 0.78688525, 0.80327869, 0.80327869,\n",
       "        0.80327869, 0.78688525, 0.7704918 , 0.80327869, 0.78688525,\n",
       "        0.81967213, 0.7704918 , 0.81967213, 0.78688525, 0.80327869,\n",
       "        0.7704918 , 0.78688525, 0.7704918 , 0.81967213, 0.73770492,\n",
       "        0.7704918 , 0.73770492, 0.7704918 , 0.73770492, 0.75409836,\n",
       "        0.70491803, 0.70491803, 0.75409836, 0.70491803, 0.78688525,\n",
       "        0.7704918 , 0.73770492, 0.78688525, 0.72131148, 0.70491803,\n",
       "        0.68852459, 0.75409836, 0.73770492, 0.73770492, 0.73770492,\n",
       "        0.75409836, 0.73770492, 0.73770492, 0.72131148, 0.7704918 ,\n",
       "        0.73770492, 0.73770492, 0.73770492, 0.75409836, 0.75409836,\n",
       "        0.75409836, 0.73770492, 0.75409836, 0.78688525, 0.7704918 ,\n",
       "        0.78688525, 0.7704918 , 0.80327869, 0.7704918 , 0.78688525,\n",
       "        0.78688525, 0.80327869, 0.7704918 , 0.7704918 , 0.78688525,\n",
       "        0.7704918 , 0.7704918 , 0.7704918 , 0.78688525, 0.78688525,\n",
       "        0.7704918 , 0.75409836, 0.7704918 , 0.73770492, 0.75409836,\n",
       "        0.75409836, 0.78688525, 0.7704918 , 0.75409836, 0.75409836,\n",
       "        0.7704918 , 0.75409836, 0.7704918 , 0.75409836, 0.7704918 ,\n",
       "        0.70491803, 0.70491803, 0.75409836, 0.70491803, 0.78688525,\n",
       "        0.7704918 , 0.73770492, 0.78688525, 0.72131148, 0.70491803,\n",
       "        0.68852459, 0.75409836, 0.73770492, 0.73770492, 0.73770492,\n",
       "        0.75409836, 0.73770492, 0.73770492, 0.72131148, 0.7704918 ,\n",
       "        0.73770492, 0.73770492, 0.73770492, 0.75409836, 0.75409836,\n",
       "        0.75409836, 0.73770492, 0.75409836, 0.78688525, 0.7704918 ,\n",
       "        0.78688525, 0.7704918 , 0.80327869, 0.7704918 , 0.78688525,\n",
       "        0.78688525, 0.80327869, 0.7704918 , 0.7704918 , 0.78688525,\n",
       "        0.7704918 , 0.7704918 , 0.7704918 , 0.78688525, 0.78688525,\n",
       "        0.7704918 , 0.75409836, 0.7704918 , 0.73770492, 0.75409836,\n",
       "        0.75409836, 0.78688525, 0.7704918 , 0.75409836, 0.75409836,\n",
       "        0.7704918 , 0.75409836, 0.7704918 , 0.75409836, 0.7704918 ,\n",
       "        0.73770492, 0.73770492, 0.73770492, 0.73770492, 0.75409836,\n",
       "        0.73770492, 0.72131148, 0.7704918 , 0.80327869, 0.78688525,\n",
       "        0.7704918 , 0.7704918 , 0.78688525, 0.7704918 , 0.73770492,\n",
       "        0.78688525, 0.7704918 , 0.75409836, 0.73770492, 0.7704918 ,\n",
       "        0.7704918 , 0.7704918 , 0.75409836, 0.78688525, 0.7704918 ,\n",
       "        0.7704918 , 0.73770492, 0.78688525, 0.7704918 , 0.78688525,\n",
       "        0.75409836, 0.75409836, 0.75409836, 0.7704918 , 0.7704918 ,\n",
       "        0.7704918 , 0.78688525, 0.78688525, 0.80327869, 0.80327869,\n",
       "        0.80327869, 0.78688525, 0.7704918 , 0.80327869, 0.78688525,\n",
       "        0.81967213, 0.7704918 , 0.81967213, 0.78688525, 0.80327869,\n",
       "        0.7704918 , 0.78688525, 0.7704918 , 0.81967213, 0.73770492,\n",
       "        0.7704918 , 0.73770492, 0.7704918 , 0.73770492, 0.75409836,\n",
       "        0.70491803, 0.70491803, 0.75409836, 0.70491803, 0.78688525,\n",
       "        0.7704918 , 0.73770492, 0.78688525, 0.72131148, 0.70491803,\n",
       "        0.68852459, 0.75409836, 0.73770492, 0.73770492, 0.73770492,\n",
       "        0.75409836, 0.73770492, 0.73770492, 0.72131148, 0.7704918 ,\n",
       "        0.73770492, 0.73770492, 0.73770492, 0.75409836, 0.75409836,\n",
       "        0.75409836, 0.73770492, 0.75409836, 0.78688525, 0.7704918 ,\n",
       "        0.78688525, 0.7704918 , 0.80327869, 0.7704918 , 0.78688525,\n",
       "        0.78688525, 0.80327869, 0.7704918 , 0.7704918 , 0.78688525,\n",
       "        0.7704918 , 0.7704918 , 0.7704918 , 0.78688525, 0.78688525,\n",
       "        0.7704918 , 0.75409836, 0.7704918 , 0.73770492, 0.75409836,\n",
       "        0.75409836, 0.78688525, 0.7704918 , 0.75409836, 0.75409836,\n",
       "        0.7704918 , 0.75409836, 0.7704918 , 0.75409836, 0.7704918 ,\n",
       "        0.70491803, 0.70491803, 0.75409836, 0.70491803, 0.78688525,\n",
       "        0.7704918 , 0.73770492, 0.78688525, 0.72131148, 0.70491803,\n",
       "        0.68852459, 0.75409836, 0.73770492, 0.73770492, 0.73770492,\n",
       "        0.75409836, 0.73770492, 0.73770492, 0.72131148, 0.7704918 ,\n",
       "        0.73770492, 0.73770492, 0.73770492, 0.75409836, 0.75409836,\n",
       "        0.75409836, 0.73770492, 0.75409836, 0.78688525, 0.7704918 ,\n",
       "        0.78688525, 0.7704918 , 0.80327869, 0.7704918 , 0.78688525,\n",
       "        0.78688525, 0.80327869, 0.7704918 , 0.7704918 , 0.78688525,\n",
       "        0.7704918 , 0.7704918 , 0.7704918 , 0.78688525, 0.78688525,\n",
       "        0.7704918 , 0.75409836, 0.7704918 , 0.73770492, 0.75409836,\n",
       "        0.75409836, 0.78688525, 0.7704918 , 0.75409836, 0.75409836,\n",
       "        0.7704918 , 0.75409836, 0.7704918 , 0.75409836, 0.7704918 ,\n",
       "        0.73770492, 0.73770492, 0.73770492, 0.73770492, 0.75409836,\n",
       "        0.73770492, 0.72131148, 0.7704918 , 0.80327869, 0.78688525,\n",
       "        0.7704918 , 0.7704918 , 0.78688525, 0.7704918 , 0.73770492,\n",
       "        0.78688525, 0.7704918 , 0.75409836, 0.73770492, 0.7704918 ,\n",
       "        0.7704918 , 0.7704918 , 0.75409836, 0.78688525, 0.7704918 ,\n",
       "        0.7704918 , 0.73770492, 0.78688525, 0.7704918 , 0.78688525,\n",
       "        0.75409836, 0.75409836, 0.75409836, 0.7704918 , 0.7704918 ,\n",
       "        0.7704918 , 0.78688525, 0.78688525, 0.80327869, 0.80327869,\n",
       "        0.80327869, 0.78688525, 0.7704918 , 0.80327869, 0.78688525,\n",
       "        0.81967213, 0.7704918 , 0.81967213, 0.78688525, 0.80327869,\n",
       "        0.7704918 , 0.78688525, 0.7704918 , 0.81967213, 0.73770492,\n",
       "        0.7704918 , 0.73770492, 0.7704918 , 0.73770492, 0.75409836,\n",
       "        0.70491803, 0.70491803, 0.75409836, 0.70491803, 0.78688525,\n",
       "        0.7704918 , 0.73770492, 0.78688525, 0.72131148, 0.70491803,\n",
       "        0.68852459, 0.75409836, 0.73770492, 0.73770492, 0.73770492,\n",
       "        0.75409836, 0.73770492, 0.73770492, 0.72131148, 0.7704918 ,\n",
       "        0.73770492, 0.73770492, 0.73770492, 0.75409836, 0.75409836,\n",
       "        0.75409836, 0.73770492, 0.75409836, 0.78688525, 0.7704918 ,\n",
       "        0.78688525, 0.7704918 , 0.80327869, 0.7704918 , 0.78688525,\n",
       "        0.78688525, 0.80327869, 0.7704918 , 0.7704918 , 0.78688525,\n",
       "        0.7704918 , 0.7704918 , 0.7704918 , 0.78688525, 0.78688525,\n",
       "        0.7704918 , 0.75409836, 0.7704918 , 0.73770492, 0.75409836,\n",
       "        0.75409836, 0.78688525, 0.7704918 , 0.75409836, 0.75409836,\n",
       "        0.7704918 , 0.75409836, 0.7704918 , 0.75409836, 0.7704918 ,\n",
       "        0.70491803, 0.70491803, 0.75409836, 0.70491803, 0.78688525,\n",
       "        0.7704918 , 0.73770492, 0.78688525, 0.72131148, 0.70491803,\n",
       "        0.68852459, 0.75409836, 0.73770492, 0.73770492, 0.73770492,\n",
       "        0.75409836, 0.73770492, 0.73770492, 0.72131148, 0.7704918 ,\n",
       "        0.73770492, 0.73770492, 0.73770492, 0.75409836, 0.75409836,\n",
       "        0.75409836, 0.73770492, 0.75409836, 0.78688525, 0.7704918 ,\n",
       "        0.78688525, 0.7704918 , 0.80327869, 0.7704918 , 0.78688525,\n",
       "        0.78688525, 0.80327869, 0.7704918 , 0.7704918 , 0.78688525,\n",
       "        0.7704918 , 0.7704918 , 0.7704918 , 0.78688525, 0.78688525,\n",
       "        0.7704918 , 0.75409836, 0.7704918 , 0.73770492, 0.75409836,\n",
       "        0.75409836, 0.78688525, 0.7704918 , 0.75409836, 0.75409836,\n",
       "        0.7704918 , 0.75409836, 0.7704918 , 0.75409836, 0.7704918 ,\n",
       "        0.73770492, 0.73770492, 0.73770492, 0.73770492, 0.75409836,\n",
       "        0.73770492, 0.72131148, 0.7704918 , 0.80327869, 0.78688525,\n",
       "        0.7704918 , 0.7704918 , 0.78688525, 0.7704918 , 0.73770492,\n",
       "        0.78688525, 0.7704918 , 0.75409836, 0.73770492, 0.7704918 ,\n",
       "        0.7704918 , 0.7704918 , 0.75409836, 0.78688525, 0.7704918 ,\n",
       "        0.7704918 , 0.73770492, 0.78688525, 0.7704918 , 0.78688525,\n",
       "        0.75409836, 0.75409836, 0.75409836, 0.7704918 , 0.7704918 ,\n",
       "        0.7704918 , 0.78688525, 0.78688525, 0.80327869, 0.80327869,\n",
       "        0.80327869, 0.78688525, 0.7704918 , 0.80327869, 0.78688525,\n",
       "        0.81967213, 0.7704918 , 0.81967213, 0.78688525, 0.80327869,\n",
       "        0.7704918 , 0.78688525, 0.7704918 , 0.81967213, 0.73770492,\n",
       "        0.7704918 , 0.73770492, 0.7704918 , 0.73770492, 0.75409836,\n",
       "        0.70491803, 0.70491803, 0.75409836, 0.70491803, 0.78688525,\n",
       "        0.7704918 , 0.73770492, 0.78688525, 0.72131148, 0.70491803,\n",
       "        0.68852459, 0.75409836, 0.73770492, 0.73770492, 0.73770492,\n",
       "        0.75409836, 0.73770492, 0.73770492, 0.72131148, 0.7704918 ,\n",
       "        0.73770492, 0.73770492, 0.73770492, 0.75409836, 0.75409836,\n",
       "        0.75409836, 0.73770492, 0.75409836, 0.78688525, 0.7704918 ,\n",
       "        0.78688525, 0.7704918 , 0.80327869, 0.7704918 , 0.78688525,\n",
       "        0.78688525, 0.80327869, 0.7704918 , 0.7704918 , 0.78688525,\n",
       "        0.7704918 , 0.7704918 , 0.7704918 , 0.78688525, 0.78688525,\n",
       "        0.7704918 , 0.75409836, 0.7704918 , 0.73770492, 0.75409836,\n",
       "        0.75409836, 0.78688525, 0.7704918 , 0.75409836, 0.75409836,\n",
       "        0.7704918 , 0.75409836, 0.7704918 , 0.75409836, 0.7704918 ]),\n",
       " 'split9_test_score': array([0.67213115, 0.67213115, 0.67213115, 0.67213115, 0.68852459,\n",
       "        0.68852459, 0.72131148, 0.67213115, 0.7704918 , 0.7704918 ,\n",
       "        0.73770492, 0.72131148, 0.72131148, 0.72131148, 0.67213115,\n",
       "        0.70491803, 0.67213115, 0.67213115, 0.70491803, 0.70491803,\n",
       "        0.73770492, 0.73770492, 0.68852459, 0.68852459, 0.68852459,\n",
       "        0.68852459, 0.67213115, 0.67213115, 0.70491803, 0.70491803,\n",
       "        0.70491803, 0.72131148, 0.72131148, 0.72131148, 0.72131148,\n",
       "        0.73770492, 0.73770492, 0.73770492, 0.75409836, 0.73770492,\n",
       "        0.75409836, 0.73770492, 0.73770492, 0.73770492, 0.72131148,\n",
       "        0.70491803, 0.72131148, 0.72131148, 0.75409836, 0.73770492,\n",
       "        0.73770492, 0.73770492, 0.75409836, 0.72131148, 0.73770492,\n",
       "        0.73770492, 0.70491803, 0.70491803, 0.73770492, 0.73770492,\n",
       "        0.68852459, 0.68852459, 0.63934426, 0.68852459, 0.6557377 ,\n",
       "        0.6557377 , 0.68852459, 0.67213115, 0.70491803, 0.70491803,\n",
       "        0.68852459, 0.68852459, 0.67213115, 0.67213115, 0.67213115,\n",
       "        0.67213115, 0.68852459, 0.67213115, 0.6557377 , 0.67213115,\n",
       "        0.70491803, 0.70491803, 0.6557377 , 0.67213115, 0.67213115,\n",
       "        0.68852459, 0.63934426, 0.67213115, 0.67213115, 0.68852459,\n",
       "        0.67213115, 0.68852459, 0.67213115, 0.67213115, 0.68852459,\n",
       "        0.67213115, 0.68852459, 0.67213115, 0.68852459, 0.67213115,\n",
       "        0.67213115, 0.67213115, 0.67213115, 0.67213115, 0.67213115,\n",
       "        0.6557377 , 0.68852459, 0.63934426, 0.70491803, 0.63934426,\n",
       "        0.70491803, 0.67213115, 0.70491803, 0.63934426, 0.70491803,\n",
       "        0.6557377 , 0.68852459, 0.67213115, 0.68852459, 0.68852459,\n",
       "        0.67213115, 0.67213115, 0.67213115, 0.67213115, 0.68852459,\n",
       "        0.68852459, 0.72131148, 0.67213115, 0.7704918 , 0.7704918 ,\n",
       "        0.73770492, 0.72131148, 0.72131148, 0.72131148, 0.67213115,\n",
       "        0.70491803, 0.67213115, 0.67213115, 0.70491803, 0.70491803,\n",
       "        0.73770492, 0.73770492, 0.68852459, 0.68852459, 0.68852459,\n",
       "        0.68852459, 0.67213115, 0.67213115, 0.70491803, 0.70491803,\n",
       "        0.70491803, 0.72131148, 0.72131148, 0.72131148, 0.72131148,\n",
       "        0.73770492, 0.73770492, 0.73770492, 0.75409836, 0.73770492,\n",
       "        0.75409836, 0.73770492, 0.73770492, 0.73770492, 0.72131148,\n",
       "        0.70491803, 0.72131148, 0.72131148, 0.75409836, 0.73770492,\n",
       "        0.73770492, 0.73770492, 0.75409836, 0.72131148, 0.73770492,\n",
       "        0.73770492, 0.70491803, 0.70491803, 0.73770492, 0.73770492,\n",
       "        0.67213115, 0.67213115, 0.67213115, 0.67213115, 0.68852459,\n",
       "        0.68852459, 0.72131148, 0.67213115, 0.7704918 , 0.7704918 ,\n",
       "        0.73770492, 0.72131148, 0.72131148, 0.72131148, 0.67213115,\n",
       "        0.70491803, 0.67213115, 0.67213115, 0.70491803, 0.70491803,\n",
       "        0.73770492, 0.73770492, 0.68852459, 0.68852459, 0.68852459,\n",
       "        0.68852459, 0.67213115, 0.67213115, 0.70491803, 0.70491803,\n",
       "        0.70491803, 0.72131148, 0.72131148, 0.72131148, 0.72131148,\n",
       "        0.73770492, 0.73770492, 0.73770492, 0.75409836, 0.73770492,\n",
       "        0.75409836, 0.73770492, 0.73770492, 0.73770492, 0.72131148,\n",
       "        0.70491803, 0.72131148, 0.72131148, 0.75409836, 0.73770492,\n",
       "        0.73770492, 0.73770492, 0.75409836, 0.72131148, 0.73770492,\n",
       "        0.73770492, 0.70491803, 0.70491803, 0.73770492, 0.73770492,\n",
       "        0.68852459, 0.68852459, 0.63934426, 0.68852459, 0.6557377 ,\n",
       "        0.6557377 , 0.68852459, 0.67213115, 0.70491803, 0.70491803,\n",
       "        0.68852459, 0.68852459, 0.67213115, 0.67213115, 0.67213115,\n",
       "        0.67213115, 0.68852459, 0.67213115, 0.6557377 , 0.67213115,\n",
       "        0.70491803, 0.70491803, 0.6557377 , 0.67213115, 0.67213115,\n",
       "        0.68852459, 0.63934426, 0.67213115, 0.67213115, 0.68852459,\n",
       "        0.67213115, 0.68852459, 0.67213115, 0.67213115, 0.68852459,\n",
       "        0.67213115, 0.68852459, 0.67213115, 0.68852459, 0.67213115,\n",
       "        0.67213115, 0.67213115, 0.67213115, 0.67213115, 0.67213115,\n",
       "        0.6557377 , 0.68852459, 0.63934426, 0.70491803, 0.63934426,\n",
       "        0.70491803, 0.67213115, 0.70491803, 0.63934426, 0.70491803,\n",
       "        0.6557377 , 0.68852459, 0.67213115, 0.68852459, 0.68852459,\n",
       "        0.67213115, 0.67213115, 0.67213115, 0.67213115, 0.68852459,\n",
       "        0.68852459, 0.72131148, 0.67213115, 0.7704918 , 0.7704918 ,\n",
       "        0.73770492, 0.72131148, 0.72131148, 0.72131148, 0.67213115,\n",
       "        0.70491803, 0.67213115, 0.67213115, 0.70491803, 0.70491803,\n",
       "        0.73770492, 0.73770492, 0.68852459, 0.68852459, 0.68852459,\n",
       "        0.68852459, 0.67213115, 0.67213115, 0.70491803, 0.70491803,\n",
       "        0.70491803, 0.72131148, 0.72131148, 0.72131148, 0.72131148,\n",
       "        0.73770492, 0.73770492, 0.73770492, 0.75409836, 0.73770492,\n",
       "        0.75409836, 0.73770492, 0.73770492, 0.73770492, 0.72131148,\n",
       "        0.70491803, 0.72131148, 0.72131148, 0.75409836, 0.73770492,\n",
       "        0.73770492, 0.73770492, 0.75409836, 0.72131148, 0.73770492,\n",
       "        0.73770492, 0.70491803, 0.70491803, 0.73770492, 0.73770492,\n",
       "        0.67213115, 0.67213115, 0.67213115, 0.67213115, 0.68852459,\n",
       "        0.68852459, 0.72131148, 0.67213115, 0.7704918 , 0.7704918 ,\n",
       "        0.73770492, 0.72131148, 0.72131148, 0.72131148, 0.67213115,\n",
       "        0.70491803, 0.67213115, 0.67213115, 0.70491803, 0.70491803,\n",
       "        0.73770492, 0.73770492, 0.68852459, 0.68852459, 0.68852459,\n",
       "        0.68852459, 0.67213115, 0.67213115, 0.70491803, 0.70491803,\n",
       "        0.70491803, 0.72131148, 0.72131148, 0.72131148, 0.72131148,\n",
       "        0.73770492, 0.73770492, 0.73770492, 0.75409836, 0.73770492,\n",
       "        0.75409836, 0.73770492, 0.73770492, 0.73770492, 0.72131148,\n",
       "        0.70491803, 0.72131148, 0.72131148, 0.75409836, 0.73770492,\n",
       "        0.73770492, 0.73770492, 0.75409836, 0.72131148, 0.73770492,\n",
       "        0.73770492, 0.70491803, 0.70491803, 0.73770492, 0.73770492,\n",
       "        0.68852459, 0.68852459, 0.63934426, 0.68852459, 0.6557377 ,\n",
       "        0.6557377 , 0.68852459, 0.67213115, 0.70491803, 0.70491803,\n",
       "        0.68852459, 0.68852459, 0.67213115, 0.67213115, 0.67213115,\n",
       "        0.67213115, 0.68852459, 0.67213115, 0.6557377 , 0.67213115,\n",
       "        0.70491803, 0.70491803, 0.6557377 , 0.67213115, 0.67213115,\n",
       "        0.68852459, 0.63934426, 0.67213115, 0.67213115, 0.68852459,\n",
       "        0.67213115, 0.68852459, 0.67213115, 0.67213115, 0.68852459,\n",
       "        0.67213115, 0.68852459, 0.67213115, 0.68852459, 0.67213115,\n",
       "        0.67213115, 0.67213115, 0.67213115, 0.67213115, 0.67213115,\n",
       "        0.6557377 , 0.68852459, 0.63934426, 0.70491803, 0.63934426,\n",
       "        0.70491803, 0.67213115, 0.70491803, 0.63934426, 0.70491803,\n",
       "        0.6557377 , 0.68852459, 0.67213115, 0.68852459, 0.68852459,\n",
       "        0.67213115, 0.67213115, 0.67213115, 0.67213115, 0.68852459,\n",
       "        0.68852459, 0.72131148, 0.67213115, 0.7704918 , 0.7704918 ,\n",
       "        0.73770492, 0.72131148, 0.72131148, 0.72131148, 0.67213115,\n",
       "        0.70491803, 0.67213115, 0.67213115, 0.70491803, 0.70491803,\n",
       "        0.73770492, 0.73770492, 0.68852459, 0.68852459, 0.68852459,\n",
       "        0.68852459, 0.67213115, 0.67213115, 0.70491803, 0.70491803,\n",
       "        0.70491803, 0.72131148, 0.72131148, 0.72131148, 0.72131148,\n",
       "        0.73770492, 0.73770492, 0.73770492, 0.75409836, 0.73770492,\n",
       "        0.75409836, 0.73770492, 0.73770492, 0.73770492, 0.72131148,\n",
       "        0.70491803, 0.72131148, 0.72131148, 0.75409836, 0.73770492,\n",
       "        0.73770492, 0.73770492, 0.75409836, 0.72131148, 0.73770492,\n",
       "        0.73770492, 0.70491803, 0.70491803, 0.73770492, 0.73770492,\n",
       "        0.67213115, 0.67213115, 0.67213115, 0.67213115, 0.68852459,\n",
       "        0.68852459, 0.72131148, 0.67213115, 0.7704918 , 0.7704918 ,\n",
       "        0.73770492, 0.72131148, 0.72131148, 0.72131148, 0.67213115,\n",
       "        0.70491803, 0.67213115, 0.67213115, 0.70491803, 0.70491803,\n",
       "        0.73770492, 0.73770492, 0.68852459, 0.68852459, 0.68852459,\n",
       "        0.68852459, 0.67213115, 0.67213115, 0.70491803, 0.70491803,\n",
       "        0.70491803, 0.72131148, 0.72131148, 0.72131148, 0.72131148,\n",
       "        0.73770492, 0.73770492, 0.73770492, 0.75409836, 0.73770492,\n",
       "        0.75409836, 0.73770492, 0.73770492, 0.73770492, 0.72131148,\n",
       "        0.70491803, 0.72131148, 0.72131148, 0.75409836, 0.73770492,\n",
       "        0.73770492, 0.73770492, 0.75409836, 0.72131148, 0.73770492,\n",
       "        0.73770492, 0.70491803, 0.70491803, 0.73770492, 0.73770492,\n",
       "        0.68852459, 0.68852459, 0.63934426, 0.68852459, 0.6557377 ,\n",
       "        0.6557377 , 0.68852459, 0.67213115, 0.70491803, 0.70491803,\n",
       "        0.68852459, 0.68852459, 0.67213115, 0.67213115, 0.67213115,\n",
       "        0.67213115, 0.68852459, 0.67213115, 0.6557377 , 0.67213115,\n",
       "        0.70491803, 0.70491803, 0.6557377 , 0.67213115, 0.67213115,\n",
       "        0.68852459, 0.63934426, 0.67213115, 0.67213115, 0.68852459,\n",
       "        0.67213115, 0.68852459, 0.67213115, 0.67213115, 0.68852459,\n",
       "        0.67213115, 0.68852459, 0.67213115, 0.68852459, 0.67213115,\n",
       "        0.67213115, 0.67213115, 0.67213115, 0.67213115, 0.67213115,\n",
       "        0.6557377 , 0.68852459, 0.63934426, 0.70491803, 0.63934426,\n",
       "        0.70491803, 0.67213115, 0.70491803, 0.63934426, 0.70491803,\n",
       "        0.6557377 , 0.68852459, 0.67213115, 0.68852459, 0.68852459,\n",
       "        0.67213115, 0.67213115, 0.67213115, 0.67213115, 0.68852459,\n",
       "        0.68852459, 0.72131148, 0.67213115, 0.7704918 , 0.7704918 ,\n",
       "        0.73770492, 0.72131148, 0.72131148, 0.72131148, 0.67213115,\n",
       "        0.70491803, 0.67213115, 0.67213115, 0.70491803, 0.70491803,\n",
       "        0.73770492, 0.73770492, 0.68852459, 0.68852459, 0.68852459,\n",
       "        0.68852459, 0.67213115, 0.67213115, 0.70491803, 0.70491803,\n",
       "        0.70491803, 0.72131148, 0.72131148, 0.72131148, 0.72131148,\n",
       "        0.73770492, 0.73770492, 0.73770492, 0.75409836, 0.73770492,\n",
       "        0.75409836, 0.73770492, 0.73770492, 0.73770492, 0.72131148,\n",
       "        0.70491803, 0.72131148, 0.72131148, 0.75409836, 0.73770492,\n",
       "        0.73770492, 0.73770492, 0.75409836, 0.72131148, 0.73770492,\n",
       "        0.73770492, 0.70491803, 0.70491803, 0.73770492, 0.73770492]),\n",
       " 'mean_test_score': array([0.68564252, 0.68564252, 0.68239027, 0.68564252, 0.70351666,\n",
       "        0.69865151, 0.70676891, 0.70676891, 0.71816499, 0.71816499,\n",
       "        0.71663141, 0.72805394, 0.72472237, 0.72633527, 0.73294553,\n",
       "        0.73120042, 0.72800106, 0.71983078, 0.73286621, 0.74106293,\n",
       "        0.73297197, 0.73133263, 0.73289265, 0.73291909, 0.74590164,\n",
       "        0.73778424, 0.73939714, 0.74431518, 0.75407192, 0.75243258,\n",
       "        0.74101005, 0.75571126, 0.75563194, 0.7474881 , 0.749101  ,\n",
       "        0.75568482, 0.75563194, 0.74912745, 0.749101  , 0.75727129,\n",
       "        0.76047065, 0.75563194, 0.75068747, 0.75724484, 0.75401904,\n",
       "        0.7539926 , 0.74754098, 0.75240613, 0.75407192, 0.75893707,\n",
       "        0.7606293 , 0.75896351, 0.76060286, 0.75565838, 0.75893707,\n",
       "        0.75565838, 0.75729773, 0.75732417, 0.75893707, 0.75732417,\n",
       "        0.68088313, 0.68088313, 0.68252247, 0.68088313, 0.69056055,\n",
       "        0.6873083 , 0.69534638, 0.69053411, 0.7132734 , 0.71002115,\n",
       "        0.72459016, 0.71163406, 0.72464305, 0.72136436, 0.71969857,\n",
       "        0.7311211 , 0.74093072, 0.73278689, 0.73283977, 0.72956108,\n",
       "        0.73773136, 0.73773136, 0.73617134, 0.7361449 , 0.74743522,\n",
       "        0.7393707 , 0.73603913, 0.74095717, 0.7473559 , 0.73767848,\n",
       "        0.74254363, 0.74582232, 0.74090428, 0.73767848, 0.73289265,\n",
       "        0.73929138, 0.74095717, 0.74095717, 0.74420941, 0.74090428,\n",
       "        0.73770492, 0.73445267, 0.73770492, 0.74090428, 0.74095717,\n",
       "        0.73770492, 0.73445267, 0.74093072, 0.75237969, 0.74743522,\n",
       "        0.74418297, 0.74740878, 0.75068747, 0.74904812, 0.74420941,\n",
       "        0.74574299, 0.74259651, 0.74746166, 0.73606557, 0.74579588,\n",
       "        0.68564252, 0.68564252, 0.68239027, 0.68564252, 0.70351666,\n",
       "        0.69865151, 0.70676891, 0.70676891, 0.71816499, 0.71816499,\n",
       "        0.71663141, 0.72805394, 0.72472237, 0.72633527, 0.73294553,\n",
       "        0.73120042, 0.72800106, 0.71983078, 0.73286621, 0.74106293,\n",
       "        0.73297197, 0.73133263, 0.73289265, 0.73291909, 0.74590164,\n",
       "        0.73778424, 0.73939714, 0.74431518, 0.75407192, 0.75243258,\n",
       "        0.74101005, 0.75571126, 0.75563194, 0.7474881 , 0.749101  ,\n",
       "        0.75568482, 0.75563194, 0.74912745, 0.749101  , 0.75727129,\n",
       "        0.76047065, 0.75563194, 0.75068747, 0.75724484, 0.75401904,\n",
       "        0.7539926 , 0.74754098, 0.75240613, 0.75407192, 0.75893707,\n",
       "        0.7606293 , 0.75896351, 0.76060286, 0.75565838, 0.75893707,\n",
       "        0.75565838, 0.75729773, 0.75732417, 0.75893707, 0.75732417,\n",
       "        0.68564252, 0.68564252, 0.68239027, 0.68564252, 0.70351666,\n",
       "        0.69865151, 0.70676891, 0.70676891, 0.71816499, 0.71816499,\n",
       "        0.71663141, 0.72805394, 0.72472237, 0.72633527, 0.73294553,\n",
       "        0.73120042, 0.72800106, 0.71983078, 0.73286621, 0.74106293,\n",
       "        0.73297197, 0.73133263, 0.73289265, 0.73291909, 0.74590164,\n",
       "        0.73778424, 0.73939714, 0.74431518, 0.75407192, 0.75243258,\n",
       "        0.74101005, 0.75571126, 0.75563194, 0.7474881 , 0.749101  ,\n",
       "        0.75568482, 0.75563194, 0.74912745, 0.749101  , 0.75727129,\n",
       "        0.76047065, 0.75563194, 0.75068747, 0.75724484, 0.75401904,\n",
       "        0.7539926 , 0.74754098, 0.75240613, 0.75407192, 0.75893707,\n",
       "        0.7606293 , 0.75896351, 0.76060286, 0.75565838, 0.75893707,\n",
       "        0.75565838, 0.75729773, 0.75732417, 0.75893707, 0.75732417,\n",
       "        0.68088313, 0.68088313, 0.68252247, 0.68088313, 0.69056055,\n",
       "        0.6873083 , 0.69534638, 0.69053411, 0.7132734 , 0.71002115,\n",
       "        0.72459016, 0.71163406, 0.72464305, 0.72136436, 0.71969857,\n",
       "        0.7311211 , 0.74093072, 0.73278689, 0.73283977, 0.72956108,\n",
       "        0.73773136, 0.73773136, 0.73617134, 0.7361449 , 0.74743522,\n",
       "        0.7393707 , 0.73603913, 0.74095717, 0.7473559 , 0.73767848,\n",
       "        0.74254363, 0.74582232, 0.74090428, 0.73767848, 0.73289265,\n",
       "        0.73929138, 0.74095717, 0.74095717, 0.74420941, 0.74090428,\n",
       "        0.73770492, 0.73445267, 0.73770492, 0.74090428, 0.74095717,\n",
       "        0.73770492, 0.73445267, 0.74093072, 0.75237969, 0.74743522,\n",
       "        0.74418297, 0.74740878, 0.75068747, 0.74904812, 0.74420941,\n",
       "        0.74574299, 0.74259651, 0.74746166, 0.73606557, 0.74579588,\n",
       "        0.68564252, 0.68564252, 0.68239027, 0.68564252, 0.70351666,\n",
       "        0.69865151, 0.70676891, 0.70676891, 0.71816499, 0.71816499,\n",
       "        0.71663141, 0.72805394, 0.72472237, 0.72633527, 0.73294553,\n",
       "        0.73120042, 0.72800106, 0.71983078, 0.73286621, 0.74106293,\n",
       "        0.73297197, 0.73133263, 0.73289265, 0.73291909, 0.74590164,\n",
       "        0.73778424, 0.73939714, 0.74431518, 0.75407192, 0.75243258,\n",
       "        0.74101005, 0.75571126, 0.75563194, 0.7474881 , 0.749101  ,\n",
       "        0.75568482, 0.75563194, 0.74912745, 0.749101  , 0.75727129,\n",
       "        0.76047065, 0.75563194, 0.75068747, 0.75724484, 0.75401904,\n",
       "        0.7539926 , 0.74754098, 0.75240613, 0.75407192, 0.75893707,\n",
       "        0.7606293 , 0.75896351, 0.76060286, 0.75565838, 0.75893707,\n",
       "        0.75565838, 0.75729773, 0.75732417, 0.75893707, 0.75732417,\n",
       "        0.68564252, 0.68564252, 0.68239027, 0.68564252, 0.70351666,\n",
       "        0.69865151, 0.70676891, 0.70676891, 0.71816499, 0.71816499,\n",
       "        0.71663141, 0.72805394, 0.72472237, 0.72633527, 0.73294553,\n",
       "        0.73120042, 0.72800106, 0.71983078, 0.73286621, 0.74106293,\n",
       "        0.73297197, 0.73133263, 0.73289265, 0.73291909, 0.74590164,\n",
       "        0.73778424, 0.73939714, 0.74431518, 0.75407192, 0.75243258,\n",
       "        0.74101005, 0.75571126, 0.75563194, 0.7474881 , 0.749101  ,\n",
       "        0.75568482, 0.75563194, 0.74912745, 0.749101  , 0.75727129,\n",
       "        0.76047065, 0.75563194, 0.75068747, 0.75724484, 0.75401904,\n",
       "        0.7539926 , 0.74754098, 0.75240613, 0.75407192, 0.75893707,\n",
       "        0.7606293 , 0.75896351, 0.76060286, 0.75565838, 0.75893707,\n",
       "        0.75565838, 0.75729773, 0.75732417, 0.75893707, 0.75732417,\n",
       "        0.68088313, 0.68088313, 0.68252247, 0.68088313, 0.69056055,\n",
       "        0.6873083 , 0.69534638, 0.69053411, 0.7132734 , 0.71002115,\n",
       "        0.72459016, 0.71163406, 0.72464305, 0.72136436, 0.71969857,\n",
       "        0.7311211 , 0.74093072, 0.73278689, 0.73283977, 0.72956108,\n",
       "        0.73773136, 0.73773136, 0.73617134, 0.7361449 , 0.74743522,\n",
       "        0.7393707 , 0.73603913, 0.74095717, 0.7473559 , 0.73767848,\n",
       "        0.74254363, 0.74582232, 0.74090428, 0.73767848, 0.73289265,\n",
       "        0.73929138, 0.74095717, 0.74095717, 0.74420941, 0.74090428,\n",
       "        0.73770492, 0.73445267, 0.73770492, 0.74090428, 0.74095717,\n",
       "        0.73770492, 0.73445267, 0.74093072, 0.75237969, 0.74743522,\n",
       "        0.74418297, 0.74740878, 0.75068747, 0.74904812, 0.74420941,\n",
       "        0.74574299, 0.74259651, 0.74746166, 0.73606557, 0.74579588,\n",
       "        0.68564252, 0.68564252, 0.68239027, 0.68564252, 0.70351666,\n",
       "        0.69865151, 0.70676891, 0.70676891, 0.71816499, 0.71816499,\n",
       "        0.71663141, 0.72805394, 0.72472237, 0.72633527, 0.73294553,\n",
       "        0.73120042, 0.72800106, 0.71983078, 0.73286621, 0.74106293,\n",
       "        0.73297197, 0.73133263, 0.73289265, 0.73291909, 0.74590164,\n",
       "        0.73778424, 0.73939714, 0.74431518, 0.75407192, 0.75243258,\n",
       "        0.74101005, 0.75571126, 0.75563194, 0.7474881 , 0.749101  ,\n",
       "        0.75568482, 0.75563194, 0.74912745, 0.749101  , 0.75727129,\n",
       "        0.76047065, 0.75563194, 0.75068747, 0.75724484, 0.75401904,\n",
       "        0.7539926 , 0.74754098, 0.75240613, 0.75407192, 0.75893707,\n",
       "        0.7606293 , 0.75896351, 0.76060286, 0.75565838, 0.75893707,\n",
       "        0.75565838, 0.75729773, 0.75732417, 0.75893707, 0.75732417,\n",
       "        0.68564252, 0.68564252, 0.68239027, 0.68564252, 0.70351666,\n",
       "        0.69865151, 0.70676891, 0.70676891, 0.71816499, 0.71816499,\n",
       "        0.71663141, 0.72805394, 0.72472237, 0.72633527, 0.73294553,\n",
       "        0.73120042, 0.72800106, 0.71983078, 0.73286621, 0.74106293,\n",
       "        0.73297197, 0.73133263, 0.73289265, 0.73291909, 0.74590164,\n",
       "        0.73778424, 0.73939714, 0.74431518, 0.75407192, 0.75243258,\n",
       "        0.74101005, 0.75571126, 0.75563194, 0.7474881 , 0.749101  ,\n",
       "        0.75568482, 0.75563194, 0.74912745, 0.749101  , 0.75727129,\n",
       "        0.76047065, 0.75563194, 0.75068747, 0.75724484, 0.75401904,\n",
       "        0.7539926 , 0.74754098, 0.75240613, 0.75407192, 0.75893707,\n",
       "        0.7606293 , 0.75896351, 0.76060286, 0.75565838, 0.75893707,\n",
       "        0.75565838, 0.75729773, 0.75732417, 0.75893707, 0.75732417,\n",
       "        0.68088313, 0.68088313, 0.68252247, 0.68088313, 0.69056055,\n",
       "        0.6873083 , 0.69534638, 0.69053411, 0.7132734 , 0.71002115,\n",
       "        0.72459016, 0.71163406, 0.72464305, 0.72136436, 0.71969857,\n",
       "        0.7311211 , 0.74093072, 0.73278689, 0.73283977, 0.72956108,\n",
       "        0.73773136, 0.73773136, 0.73617134, 0.7361449 , 0.74743522,\n",
       "        0.7393707 , 0.73603913, 0.74095717, 0.7473559 , 0.73767848,\n",
       "        0.74254363, 0.74582232, 0.74090428, 0.73767848, 0.73289265,\n",
       "        0.73929138, 0.74095717, 0.74095717, 0.74420941, 0.74090428,\n",
       "        0.73770492, 0.73445267, 0.73770492, 0.74090428, 0.74095717,\n",
       "        0.73770492, 0.73445267, 0.74093072, 0.75237969, 0.74743522,\n",
       "        0.74418297, 0.74740878, 0.75068747, 0.74904812, 0.74420941,\n",
       "        0.74574299, 0.74259651, 0.74746166, 0.73606557, 0.74579588,\n",
       "        0.68564252, 0.68564252, 0.68239027, 0.68564252, 0.70351666,\n",
       "        0.69865151, 0.70676891, 0.70676891, 0.71816499, 0.71816499,\n",
       "        0.71663141, 0.72805394, 0.72472237, 0.72633527, 0.73294553,\n",
       "        0.73120042, 0.72800106, 0.71983078, 0.73286621, 0.74106293,\n",
       "        0.73297197, 0.73133263, 0.73289265, 0.73291909, 0.74590164,\n",
       "        0.73778424, 0.73939714, 0.74431518, 0.75407192, 0.75243258,\n",
       "        0.74101005, 0.75571126, 0.75563194, 0.7474881 , 0.749101  ,\n",
       "        0.75568482, 0.75563194, 0.74912745, 0.749101  , 0.75727129,\n",
       "        0.76047065, 0.75563194, 0.75068747, 0.75724484, 0.75401904,\n",
       "        0.7539926 , 0.74754098, 0.75240613, 0.75407192, 0.75893707,\n",
       "        0.7606293 , 0.75896351, 0.76060286, 0.75565838, 0.75893707,\n",
       "        0.75565838, 0.75729773, 0.75732417, 0.75893707, 0.75732417]),\n",
       " 'std_test_score': array([0.06473557, 0.06473557, 0.05110168, 0.06473557, 0.05704246,\n",
       "        0.05280031, 0.0446553 , 0.0594466 , 0.04466242, 0.04287941,\n",
       "        0.04029826, 0.04170435, 0.04878073, 0.0566959 , 0.0568    ,\n",
       "        0.04831483, 0.05011118, 0.0581085 , 0.04802788, 0.05160448,\n",
       "        0.05117641, 0.04695298, 0.05682385, 0.05096299, 0.06596241,\n",
       "        0.05964116, 0.06790923, 0.06874476, 0.06935766, 0.06644481,\n",
       "        0.05715268, 0.06644611, 0.06073165, 0.05869684, 0.06472671,\n",
       "        0.06452534, 0.06033029, 0.05629107, 0.06417632, 0.06879072,\n",
       "        0.06877897, 0.0662739 , 0.05868522, 0.06779953, 0.06311072,\n",
       "        0.06568064, 0.05512735, 0.06021364, 0.04395586, 0.0519936 ,\n",
       "        0.06251279, 0.05495923, 0.04812751, 0.05560537, 0.04586389,\n",
       "        0.05529129, 0.05290421, 0.05026535, 0.0470395 , 0.04969323,\n",
       "        0.04470028, 0.04470028, 0.05327394, 0.04470028, 0.05922061,\n",
       "        0.05726608, 0.0476596 , 0.05935093, 0.06368945, 0.06436468,\n",
       "        0.04494855, 0.0667968 , 0.05636435, 0.05923522, 0.05073544,\n",
       "        0.06554609, 0.06486141, 0.06441562, 0.06207939, 0.06208565,\n",
       "        0.0641883 , 0.06128567, 0.06934318, 0.06663167, 0.07535109,\n",
       "        0.06811768, 0.07544523, 0.07612145, 0.07834129, 0.07379707,\n",
       "        0.06408775, 0.06862761, 0.06118086, 0.06157781, 0.06054602,\n",
       "        0.0569313 , 0.06918817, 0.06446529, 0.06797478, 0.06857099,\n",
       "        0.06400293, 0.06084347, 0.06503925, 0.06698496, 0.06252856,\n",
       "        0.06680044, 0.05064187, 0.0688553 , 0.05252261, 0.06730309,\n",
       "        0.05386737, 0.05663816, 0.05103537, 0.065795  , 0.04585812,\n",
       "        0.06002525, 0.05514135, 0.06061038, 0.04584952, 0.05749904,\n",
       "        0.06473557, 0.06473557, 0.05110168, 0.06473557, 0.05704246,\n",
       "        0.05280031, 0.0446553 , 0.0594466 , 0.04466242, 0.04287941,\n",
       "        0.04029826, 0.04170435, 0.04878073, 0.0566959 , 0.0568    ,\n",
       "        0.04831483, 0.05011118, 0.0581085 , 0.04802788, 0.05160448,\n",
       "        0.05117641, 0.04695298, 0.05682385, 0.05096299, 0.06596241,\n",
       "        0.05964116, 0.06790923, 0.06874476, 0.06935766, 0.06644481,\n",
       "        0.05715268, 0.06644611, 0.06073165, 0.05869684, 0.06472671,\n",
       "        0.06452534, 0.06033029, 0.05629107, 0.06417632, 0.06879072,\n",
       "        0.06877897, 0.0662739 , 0.05868522, 0.06779953, 0.06311072,\n",
       "        0.06568064, 0.05512735, 0.06021364, 0.04395586, 0.0519936 ,\n",
       "        0.06251279, 0.05495923, 0.04812751, 0.05560537, 0.04586389,\n",
       "        0.05529129, 0.05290421, 0.05026535, 0.0470395 , 0.04969323,\n",
       "        0.06473557, 0.06473557, 0.05110168, 0.06473557, 0.05704246,\n",
       "        0.05280031, 0.0446553 , 0.0594466 , 0.04466242, 0.04287941,\n",
       "        0.04029826, 0.04170435, 0.04878073, 0.0566959 , 0.0568    ,\n",
       "        0.04831483, 0.05011118, 0.0581085 , 0.04802788, 0.05160448,\n",
       "        0.05117641, 0.04695298, 0.05682385, 0.05096299, 0.06596241,\n",
       "        0.05964116, 0.06790923, 0.06874476, 0.06935766, 0.06644481,\n",
       "        0.05715268, 0.06644611, 0.06073165, 0.05869684, 0.06472671,\n",
       "        0.06452534, 0.06033029, 0.05629107, 0.06417632, 0.06879072,\n",
       "        0.06877897, 0.0662739 , 0.05868522, 0.06779953, 0.06311072,\n",
       "        0.06568064, 0.05512735, 0.06021364, 0.04395586, 0.0519936 ,\n",
       "        0.06251279, 0.05495923, 0.04812751, 0.05560537, 0.04586389,\n",
       "        0.05529129, 0.05290421, 0.05026535, 0.0470395 , 0.04969323,\n",
       "        0.04470028, 0.04470028, 0.05327394, 0.04470028, 0.05922061,\n",
       "        0.05726608, 0.0476596 , 0.05935093, 0.06368945, 0.06436468,\n",
       "        0.04494855, 0.0667968 , 0.05636435, 0.05923522, 0.05073544,\n",
       "        0.06554609, 0.06486141, 0.06441562, 0.06207939, 0.06208565,\n",
       "        0.0641883 , 0.06128567, 0.06934318, 0.06663167, 0.07535109,\n",
       "        0.06811768, 0.07544523, 0.07612145, 0.07834129, 0.07379707,\n",
       "        0.06408775, 0.06862761, 0.06118086, 0.06157781, 0.06054602,\n",
       "        0.0569313 , 0.06918817, 0.06446529, 0.06797478, 0.06857099,\n",
       "        0.06400293, 0.06084347, 0.06503925, 0.06698496, 0.06252856,\n",
       "        0.06680044, 0.05064187, 0.0688553 , 0.05252261, 0.06730309,\n",
       "        0.05386737, 0.05663816, 0.05103537, 0.065795  , 0.04585812,\n",
       "        0.06002525, 0.05514135, 0.06061038, 0.04584952, 0.05749904,\n",
       "        0.06473557, 0.06473557, 0.05110168, 0.06473557, 0.05704246,\n",
       "        0.05280031, 0.0446553 , 0.0594466 , 0.04466242, 0.04287941,\n",
       "        0.04029826, 0.04170435, 0.04878073, 0.0566959 , 0.0568    ,\n",
       "        0.04831483, 0.05011118, 0.0581085 , 0.04802788, 0.05160448,\n",
       "        0.05117641, 0.04695298, 0.05682385, 0.05096299, 0.06596241,\n",
       "        0.05964116, 0.06790923, 0.06874476, 0.06935766, 0.06644481,\n",
       "        0.05715268, 0.06644611, 0.06073165, 0.05869684, 0.06472671,\n",
       "        0.06452534, 0.06033029, 0.05629107, 0.06417632, 0.06879072,\n",
       "        0.06877897, 0.0662739 , 0.05868522, 0.06779953, 0.06311072,\n",
       "        0.06568064, 0.05512735, 0.06021364, 0.04395586, 0.0519936 ,\n",
       "        0.06251279, 0.05495923, 0.04812751, 0.05560537, 0.04586389,\n",
       "        0.05529129, 0.05290421, 0.05026535, 0.0470395 , 0.04969323,\n",
       "        0.06473557, 0.06473557, 0.05110168, 0.06473557, 0.05704246,\n",
       "        0.05280031, 0.0446553 , 0.0594466 , 0.04466242, 0.04287941,\n",
       "        0.04029826, 0.04170435, 0.04878073, 0.0566959 , 0.0568    ,\n",
       "        0.04831483, 0.05011118, 0.0581085 , 0.04802788, 0.05160448,\n",
       "        0.05117641, 0.04695298, 0.05682385, 0.05096299, 0.06596241,\n",
       "        0.05964116, 0.06790923, 0.06874476, 0.06935766, 0.06644481,\n",
       "        0.05715268, 0.06644611, 0.06073165, 0.05869684, 0.06472671,\n",
       "        0.06452534, 0.06033029, 0.05629107, 0.06417632, 0.06879072,\n",
       "        0.06877897, 0.0662739 , 0.05868522, 0.06779953, 0.06311072,\n",
       "        0.06568064, 0.05512735, 0.06021364, 0.04395586, 0.0519936 ,\n",
       "        0.06251279, 0.05495923, 0.04812751, 0.05560537, 0.04586389,\n",
       "        0.05529129, 0.05290421, 0.05026535, 0.0470395 , 0.04969323,\n",
       "        0.04470028, 0.04470028, 0.05327394, 0.04470028, 0.05922061,\n",
       "        0.05726608, 0.0476596 , 0.05935093, 0.06368945, 0.06436468,\n",
       "        0.04494855, 0.0667968 , 0.05636435, 0.05923522, 0.05073544,\n",
       "        0.06554609, 0.06486141, 0.06441562, 0.06207939, 0.06208565,\n",
       "        0.0641883 , 0.06128567, 0.06934318, 0.06663167, 0.07535109,\n",
       "        0.06811768, 0.07544523, 0.07612145, 0.07834129, 0.07379707,\n",
       "        0.06408775, 0.06862761, 0.06118086, 0.06157781, 0.06054602,\n",
       "        0.0569313 , 0.06918817, 0.06446529, 0.06797478, 0.06857099,\n",
       "        0.06400293, 0.06084347, 0.06503925, 0.06698496, 0.06252856,\n",
       "        0.06680044, 0.05064187, 0.0688553 , 0.05252261, 0.06730309,\n",
       "        0.05386737, 0.05663816, 0.05103537, 0.065795  , 0.04585812,\n",
       "        0.06002525, 0.05514135, 0.06061038, 0.04584952, 0.05749904,\n",
       "        0.06473557, 0.06473557, 0.05110168, 0.06473557, 0.05704246,\n",
       "        0.05280031, 0.0446553 , 0.0594466 , 0.04466242, 0.04287941,\n",
       "        0.04029826, 0.04170435, 0.04878073, 0.0566959 , 0.0568    ,\n",
       "        0.04831483, 0.05011118, 0.0581085 , 0.04802788, 0.05160448,\n",
       "        0.05117641, 0.04695298, 0.05682385, 0.05096299, 0.06596241,\n",
       "        0.05964116, 0.06790923, 0.06874476, 0.06935766, 0.06644481,\n",
       "        0.05715268, 0.06644611, 0.06073165, 0.05869684, 0.06472671,\n",
       "        0.06452534, 0.06033029, 0.05629107, 0.06417632, 0.06879072,\n",
       "        0.06877897, 0.0662739 , 0.05868522, 0.06779953, 0.06311072,\n",
       "        0.06568064, 0.05512735, 0.06021364, 0.04395586, 0.0519936 ,\n",
       "        0.06251279, 0.05495923, 0.04812751, 0.05560537, 0.04586389,\n",
       "        0.05529129, 0.05290421, 0.05026535, 0.0470395 , 0.04969323,\n",
       "        0.06473557, 0.06473557, 0.05110168, 0.06473557, 0.05704246,\n",
       "        0.05280031, 0.0446553 , 0.0594466 , 0.04466242, 0.04287941,\n",
       "        0.04029826, 0.04170435, 0.04878073, 0.0566959 , 0.0568    ,\n",
       "        0.04831483, 0.05011118, 0.0581085 , 0.04802788, 0.05160448,\n",
       "        0.05117641, 0.04695298, 0.05682385, 0.05096299, 0.06596241,\n",
       "        0.05964116, 0.06790923, 0.06874476, 0.06935766, 0.06644481,\n",
       "        0.05715268, 0.06644611, 0.06073165, 0.05869684, 0.06472671,\n",
       "        0.06452534, 0.06033029, 0.05629107, 0.06417632, 0.06879072,\n",
       "        0.06877897, 0.0662739 , 0.05868522, 0.06779953, 0.06311072,\n",
       "        0.06568064, 0.05512735, 0.06021364, 0.04395586, 0.0519936 ,\n",
       "        0.06251279, 0.05495923, 0.04812751, 0.05560537, 0.04586389,\n",
       "        0.05529129, 0.05290421, 0.05026535, 0.0470395 , 0.04969323,\n",
       "        0.04470028, 0.04470028, 0.05327394, 0.04470028, 0.05922061,\n",
       "        0.05726608, 0.0476596 , 0.05935093, 0.06368945, 0.06436468,\n",
       "        0.04494855, 0.0667968 , 0.05636435, 0.05923522, 0.05073544,\n",
       "        0.06554609, 0.06486141, 0.06441562, 0.06207939, 0.06208565,\n",
       "        0.0641883 , 0.06128567, 0.06934318, 0.06663167, 0.07535109,\n",
       "        0.06811768, 0.07544523, 0.07612145, 0.07834129, 0.07379707,\n",
       "        0.06408775, 0.06862761, 0.06118086, 0.06157781, 0.06054602,\n",
       "        0.0569313 , 0.06918817, 0.06446529, 0.06797478, 0.06857099,\n",
       "        0.06400293, 0.06084347, 0.06503925, 0.06698496, 0.06252856,\n",
       "        0.06680044, 0.05064187, 0.0688553 , 0.05252261, 0.06730309,\n",
       "        0.05386737, 0.05663816, 0.05103537, 0.065795  , 0.04585812,\n",
       "        0.06002525, 0.05514135, 0.06061038, 0.04584952, 0.05749904,\n",
       "        0.06473557, 0.06473557, 0.05110168, 0.06473557, 0.05704246,\n",
       "        0.05280031, 0.0446553 , 0.0594466 , 0.04466242, 0.04287941,\n",
       "        0.04029826, 0.04170435, 0.04878073, 0.0566959 , 0.0568    ,\n",
       "        0.04831483, 0.05011118, 0.0581085 , 0.04802788, 0.05160448,\n",
       "        0.05117641, 0.04695298, 0.05682385, 0.05096299, 0.06596241,\n",
       "        0.05964116, 0.06790923, 0.06874476, 0.06935766, 0.06644481,\n",
       "        0.05715268, 0.06644611, 0.06073165, 0.05869684, 0.06472671,\n",
       "        0.06452534, 0.06033029, 0.05629107, 0.06417632, 0.06879072,\n",
       "        0.06877897, 0.0662739 , 0.05868522, 0.06779953, 0.06311072,\n",
       "        0.06568064, 0.05512735, 0.06021364, 0.04395586, 0.0519936 ,\n",
       "        0.06251279, 0.05495923, 0.04812751, 0.05560537, 0.04586389,\n",
       "        0.05529129, 0.05290421, 0.05026535, 0.0470395 , 0.04969323]),\n",
       " 'rank_test_score': array([673, 673, 701, 673, 641, 649, 625, 625, 589, 589, 605, 533, 557,\n",
       "        549, 465, 517, 541, 577, 493, 329, 457, 509, 481, 473, 281, 397,\n",
       "        381, 301, 153, 185, 337,  97, 129, 253, 233, 105, 145, 217, 225,\n",
       "         81,  17, 129, 205,  89, 169, 177, 245, 193, 153,  33,   1,  25,\n",
       "          9, 121,  33, 113,  73,  57,  33,  65, 709, 709, 697, 709, 661,\n",
       "        669, 657, 665, 613, 621, 569, 617, 565, 573, 585, 525, 361, 505,\n",
       "        501, 529, 405, 405, 433, 437, 265, 389, 445, 349, 277, 425, 325,\n",
       "        289, 377, 425, 481, 393, 345, 349, 309, 369, 413, 453, 413, 369,\n",
       "        349, 413, 449, 361, 201, 265, 317, 273, 205, 241, 313, 297, 321,\n",
       "        261, 441, 293, 673, 673, 701, 673, 641, 649, 625, 625, 589, 589,\n",
       "        605, 533, 557, 549, 465, 517, 541, 577, 493, 329, 457, 509, 481,\n",
       "        473, 281, 397, 381, 301, 153, 185, 337,  97, 129, 253, 233, 105,\n",
       "        145, 217, 225,  81,  17, 129, 205,  89, 169, 177, 245, 193, 153,\n",
       "         33,   1,  25,   9, 121,  33, 113,  73,  57,  33,  65, 673, 673,\n",
       "        701, 673, 641, 649, 625, 625, 589, 589, 605, 533, 557, 549, 465,\n",
       "        517, 541, 577, 493, 329, 457, 509, 481, 473, 281, 397, 381, 301,\n",
       "        153, 185, 337,  97, 129, 253, 233, 105, 145, 217, 225,  81,  17,\n",
       "        129, 205,  89, 169, 177, 245, 193, 153,  33,   1,  25,   9, 121,\n",
       "         33, 113,  73,  57,  33,  65, 709, 709, 697, 709, 661, 669, 657,\n",
       "        665, 613, 621, 569, 617, 565, 573, 585, 525, 361, 505, 501, 529,\n",
       "        405, 405, 433, 437, 265, 389, 445, 349, 277, 425, 325, 289, 377,\n",
       "        425, 481, 393, 345, 349, 309, 369, 413, 453, 413, 369, 349, 413,\n",
       "        449, 361, 201, 265, 317, 273, 205, 241, 313, 297, 321, 261, 441,\n",
       "        293, 673, 673, 701, 673, 641, 649, 625, 625, 589, 589, 605, 533,\n",
       "        557, 549, 465, 517, 541, 577, 493, 329, 457, 509, 481, 473, 281,\n",
       "        397, 381, 301, 153, 185, 337,  97, 129, 253, 233, 105, 145, 217,\n",
       "        225,  81,  17, 129, 205,  89, 169, 177, 245, 193, 153,  33,   1,\n",
       "         25,   9, 121,  33, 113,  73,  57,  33,  65, 673, 673, 701, 673,\n",
       "        641, 649, 625, 625, 589, 589, 605, 533, 557, 549, 465, 517, 541,\n",
       "        577, 493, 329, 457, 509, 481, 473, 281, 397, 381, 301, 153, 185,\n",
       "        337,  97, 129, 253, 233, 105, 145, 217, 225,  81,  17, 129, 205,\n",
       "         89, 169, 177, 245, 193, 153,  33,   1,  25,   9, 121,  33, 113,\n",
       "         73,  57,  33,  65, 709, 709, 697, 709, 661, 669, 657, 665, 613,\n",
       "        621, 569, 617, 565, 573, 585, 525, 361, 505, 501, 529, 405, 405,\n",
       "        433, 437, 265, 389, 445, 349, 277, 425, 325, 289, 377, 425, 481,\n",
       "        393, 345, 349, 309, 369, 413, 453, 413, 369, 349, 413, 449, 361,\n",
       "        201, 265, 317, 273, 205, 241, 313, 297, 321, 261, 441, 293, 673,\n",
       "        673, 701, 673, 641, 649, 625, 625, 589, 589, 605, 533, 557, 549,\n",
       "        465, 517, 541, 577, 493, 329, 457, 509, 481, 473, 281, 397, 381,\n",
       "        301, 153, 185, 337,  97, 129, 253, 233, 105, 145, 217, 225,  81,\n",
       "         17, 129, 205,  89, 169, 177, 245, 193, 153,  33,   1,  25,   9,\n",
       "        121,  33, 113,  73,  57,  33,  65, 673, 673, 701, 673, 641, 649,\n",
       "        625, 625, 589, 589, 605, 533, 557, 549, 465, 517, 541, 577, 493,\n",
       "        329, 457, 509, 481, 473, 281, 397, 381, 301, 153, 185, 337,  97,\n",
       "        129, 253, 233, 105, 145, 217, 225,  81,  17, 129, 205,  89, 169,\n",
       "        177, 245, 193, 153,  33,   1,  25,   9, 121,  33, 113,  73,  57,\n",
       "         33,  65, 709, 709, 697, 709, 661, 669, 657, 665, 613, 621, 569,\n",
       "        617, 565, 573, 585, 525, 361, 505, 501, 529, 405, 405, 433, 437,\n",
       "        265, 389, 445, 349, 277, 425, 325, 289, 377, 425, 481, 393, 345,\n",
       "        349, 309, 369, 413, 453, 413, 369, 349, 413, 449, 361, 201, 265,\n",
       "        317, 273, 205, 241, 313, 297, 321, 261, 441, 293, 673, 673, 701,\n",
       "        673, 641, 649, 625, 625, 589, 589, 605, 533, 557, 549, 465, 517,\n",
       "        541, 577, 493, 329, 457, 509, 481, 473, 281, 397, 381, 301, 153,\n",
       "        185, 337,  97, 129, 253, 233, 105, 145, 217, 225,  81,  17, 129,\n",
       "        205,  89, 169, 177, 245, 193, 153,  33,   1,  25,   9, 121,  33,\n",
       "        113,  73,  57,  33,  65])}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TO DO:\n",
    "param_grid = {'n_neighbors': np.arange(1, 31),\n",
    "              'weights' : ['uniform', 'distance'],\n",
    "              'metric' : ['euclidean', 'manhattan', 'minkowski'],\n",
    "              'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'],\n",
    "             }\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid, cv=10, scoring='accuracy')\n",
    "# fit the grid with data\n",
    "grid.fit(X_train, y_train)\n",
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7606292966684294\n",
      "KNeighborsClassifier(metric='euclidean', n_neighbors=26)\n",
      "{'algorithm': 'auto', 'leaf_size': 30, 'metric': 'euclidean', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 26, 'p': 2, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "# examine the best parameter\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(metric='euclidean', n_neighbors=26).fit(X_train, y_train)\n",
    "yhat_test = knn.predict(X_test)\n",
    "yhat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_train = knn.predict(X_train)\n",
    "yhat_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QLvhv6JrM1lA"
   },
   "source": [
    "# Additional Question: \n",
    "### Interpret and explain the parameters you have chosen to fine tune in KNN algorithm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QLvhv6JrM1lA"
   },
   "source": [
    "+ n_neighbor (Number of neighbors) : take a range from 1 to 31\n",
    "\n",
    "+ weights (Weight function used in prediction): 'uniform' or 'distance'\n",
    "\n",
    "+ metrics (The distance metric to use for the tree): 'euclidean', 'manhattan', 'minkowski'\n",
    "\n",
    "+ algorithm (Algorithm used to compute the nearest neighbors) : 'auto', 'ball_tree', 'kd_tree', 'brute'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qaJt1GeEM1lA"
   },
   "source": [
    "### TO DO:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GsPgXPEpM1lB"
   },
   "source": [
    "### 12. Run the prediction on KNN models on training data and test data, then calculate the f1 score and Jaccard similarity score and save it to f1_scores dict and jaccard_scores dict.  \n",
    "**Requirement**: F1 score on test data must be higher than **0.6**, Jaccard similarity score must be higher than **0.75**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "GxclqWk1M1lB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of train set: 0.7899022801302932\n",
      "Accuracy score of test set: 0.7727272727272727\n",
      "Jaccard score of train set: 0.7435387673956262\n",
      "Jaccard score of test set: 0.7244094488188977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.93      0.85       403\n",
      "           1       0.79      0.53      0.63       211\n",
      "\n",
      "    accuracy                           0.79       614\n",
      "   macro avg       0.79      0.73      0.74       614\n",
      "weighted avg       0.79      0.79      0.78       614\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.95      0.84        97\n",
      "           1       0.84      0.47      0.61        57\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.80      0.71      0.72       154\n",
      "weighted avg       0.79      0.77      0.75       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TO DO:\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Accuracy score of train set:\", accuracy_score(y_train, yhat_train))\n",
    "print(\"Accuracy score of test set:\", accuracy_score(y_test, yhat_test))\n",
    "\n",
    "print(\"Jaccard score of train set:\", jaccard_score(y_train, yhat_train, pos_label = 0))\n",
    "print(\"Jaccard score of test set:\", jaccard_score(y_test, yhat_test, pos_label = 0))\n",
    "\n",
    "print (classification_report(y_train, yhat_train))\n",
    "print (classification_report(y_test, yhat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores['test']['KNN'] = accuracy_score(y_test, yhat_test)\n",
    "f1_scores['train']['KNN'] = accuracy_score(y_train, yhat_train)\n",
    "jaccard_scores['test']['KNN'] = jaccard_score(y_test, yhat_test, pos_label = 0)\n",
    "jaccard_scores['train']['KNN'] = jaccard_score(y_train, yhat_train, pos_label = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': {'KNN': 0.7899022801302932, 'DT': 0, 'SVM': 0, 'LR': 0, 'EN_HARD': 0, 'EN_SOFT': 0}, 'test': {'KNN': 0.7727272727272727, 'DT': 0, 'SVM': 0, 'LR': 0, 'EN_HARD': 0, 'EN_SOFT': 0}}\n",
      "{'train': {'KNN': 0.7435387673956262, 'DT': 0, 'SVM': 0, 'LR': 0, 'EN_HARD': 0, 'EN_SOFT': 0}, 'test': {'KNN': 0.7244094488188977, 'DT': 0, 'SVM': 0, 'LR': 0, 'EN_HARD': 0, 'EN_SOFT': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(f1_scores)\n",
    "print(jaccard_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXIl2GGLM1lE"
   },
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kW11u1k6M1lF"
   },
   "source": [
    "### 13, 14. Perform task 11 and 12 on the DT model.\n",
    "\n",
    "Hint: Using GridSearchCV in sklearn.model_selection.\n",
    "\n",
    "**Warning**: You should not use the test data for finding the best parameters.\n",
    "\n",
    "**Requirement**: F1 score on test data has to higher than **0.6**, the Jaccard similarity score must be higher than **0.73**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "CnE8pvjvM1lG"
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "RPdHH2HiM1lI",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00091963, 0.00041201, 0.00079808, ..., 0.00059888, 0.00050714,\n",
       "        0.00059848]),\n",
       " 'std_fit_time': array([0.00031362, 0.00047912, 0.00039904, ..., 0.00048899, 0.00050764,\n",
       "        0.00048866]),\n",
       " 'mean_score_time': array([0.00029962, 0.00029924, 0.0001992 , ..., 0.00019944, 0.00039892,\n",
       "        0.00029919]),\n",
       " 'std_score_time': array([0.00045768, 0.0004571 , 0.0003984 , ..., 0.00039887, 0.00048858,\n",
       "        0.00045702]),\n",
       " 'param_criterion': masked_array(data=['gini', 'gini', 'gini', ..., 'entropy', 'entropy',\n",
       "                    'entropy'],\n",
       "              mask=[False, False, False, ..., False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_depth': masked_array(data=[1, 1, 1, ..., 30, 30, 30],\n",
       "              mask=[False, False, False, ..., False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[0.1, 0.1, 0.1, ..., 0.5, 0.5, 0.5],\n",
       "              mask=[False, False, False, ..., False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[0.1, 0.1, 0.2, ..., 0.9, 1.0, 1.0],\n",
       "              mask=[False, False, False, ..., False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_splitter': masked_array(data=['best', 'random', 'best', ..., 'random', 'best',\n",
       "                    'random'],\n",
       "              mask=[False, False, False, ..., False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 1,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 2,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 3,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 4,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 5,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 6,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 7,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 8,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 9,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.1,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.2,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.30000000000000004,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.4,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.1,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.2,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.30000000000000004,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.4,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.5,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.6,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.7000000000000001,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.8,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 0.9,\n",
       "   'splitter': 'random'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'best'},\n",
       "  {'criterion': 'gini',\n",
       "   'max_depth': 10,\n",
       "   'min_samples_leaf': 0.5,\n",
       "   'min_samples_split': 1.0,\n",
       "   'splitter': 'random'},\n",
       "  ...],\n",
       " 'split0_test_score': array([0.66129032, 0.75806452, 0.66129032, ..., 0.66129032, 0.66129032,\n",
       "        0.66129032]),\n",
       " 'split1_test_score': array([0.75806452, 0.72580645, 0.75806452, ..., 0.66129032, 0.66129032,\n",
       "        0.66129032]),\n",
       " 'split2_test_score': array([0.69354839, 0.66129032, 0.69354839, ..., 0.66129032, 0.66129032,\n",
       "        0.66129032]),\n",
       " 'split3_test_score': array([0.72580645, 0.64516129, 0.72580645, ..., 0.64516129, 0.66129032,\n",
       "        0.64516129]),\n",
       " 'split4_test_score': array([0.72131148, 0.6557377 , 0.72131148, ..., 0.6557377 , 0.6557377 ,\n",
       "        0.6557377 ]),\n",
       " 'split5_test_score': array([0.67213115, 0.6557377 , 0.67213115, ..., 0.6557377 , 0.6557377 ,\n",
       "        0.6557377 ]),\n",
       " 'split6_test_score': array([0.72131148, 0.70491803, 0.72131148, ..., 0.6557377 , 0.6557377 ,\n",
       "        0.6557377 ]),\n",
       " 'split7_test_score': array([0.75409836, 0.6557377 , 0.75409836, ..., 0.6557377 , 0.6557377 ,\n",
       "        0.6557377 ]),\n",
       " 'split8_test_score': array([0.67213115, 0.6557377 , 0.67213115, ..., 0.6557377 , 0.6557377 ,\n",
       "        0.6557377 ]),\n",
       " 'split9_test_score': array([0.73770492, 0.57377049, 0.73770492, ..., 0.6557377 , 0.6557377 ,\n",
       "        0.6557377 ]),\n",
       " 'mean_test_score': array([0.71173982, 0.66919619, 0.71173982, ..., 0.65634585, 0.65795875,\n",
       "        0.65634585]),\n",
       " 'std_test_score': array([0.03318025, 0.04780075, 0.03318025, ..., 0.00447947, 0.00272022,\n",
       "        0.00447947]),\n",
       " 'rank_test_score': array([ 728, 3213,  728, ..., 4731, 4089, 4731])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TO DO:\n",
    "param_grid = {'criterion':['gini','entropy'],\n",
    "              'splitter' : [\"best\", \"random\"],\n",
    "              'max_depth': np.arange(1, 31),\n",
    "              'min_samples_split' : np.linspace(0.1, 1.0, 10, endpoint=True),\n",
    "              'min_samples_leaf' : np.linspace(0.1, 0.5, 5, endpoint=True)    \n",
    "             }\n",
    "grid1 = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=10, scoring='accuracy')\n",
    "# fit the grid with data\n",
    "grid1.fit(X_train, y_train)\n",
    "grid1.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7653886832363829\n",
      "DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_leaf=0.1,\n",
      "                       min_samples_split=0.1)\n",
      "{'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'entropy', 'max_depth': 5, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 0.1, 'min_samples_split': 0.1, 'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "# examine the best parameter\n",
    "print(grid1.best_score_)\n",
    "print(grid1.best_estimator_)\n",
    "print(grid1.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_leaf=0.1,\n",
    "                       min_samples_split=0.1).fit(X_train, y_train)\n",
    "yhat_test1 = dtc.predict(X_test)\n",
    "yhat_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_train1 = dtc.predict(X_train)\n",
    "yhat_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of train set: 0.7785016286644951\n",
      "Accuracy score of test set: 0.7532467532467533\n",
      "Jaccard score of train set: 0.7075268817204301\n",
      "Jaccard score of test set: 0.6666666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83       403\n",
      "           1       0.67      0.71      0.69       211\n",
      "\n",
      "    accuracy                           0.78       614\n",
      "   macro avg       0.75      0.76      0.76       614\n",
      "weighted avg       0.78      0.78      0.78       614\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.78      0.80        97\n",
      "           1       0.66      0.70      0.68        57\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.74      0.74      0.74       154\n",
      "weighted avg       0.76      0.75      0.75       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TO DO:\n",
    "\n",
    "print(\"Accuracy score of train set:\", accuracy_score(y_train, yhat_train1))\n",
    "print(\"Accuracy score of test set:\", accuracy_score(y_test, yhat_test1))\n",
    "\n",
    "print(\"Jaccard score of train set:\", jaccard_score(y_train, yhat_train1, pos_label = 0))\n",
    "print(\"Jaccard score of test set:\", jaccard_score(y_test, yhat_test1, pos_label = 0))\n",
    "\n",
    "print (classification_report(y_train, yhat_train1))\n",
    "print (classification_report(y_test, yhat_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': {'KNN': 0.7899022801302932, 'DT': 0.7785016286644951, 'SVM': 0, 'LR': 0, 'EN_HARD': 0, 'EN_SOFT': 0}, 'test': {'KNN': 0.7727272727272727, 'DT': 0.7532467532467533, 'SVM': 0, 'LR': 0, 'EN_HARD': 0, 'EN_SOFT': 0}}\n",
      "{'train': {'KNN': 0.7435387673956262, 'DT': 0.7075268817204301, 'SVM': 0, 'LR': 0, 'EN_HARD': 0, 'EN_SOFT': 0}, 'test': {'KNN': 0.7244094488188977, 'DT': 0.6666666666666666, 'SVM': 0, 'LR': 0, 'EN_HARD': 0, 'EN_SOFT': 0}}\n"
     ]
    }
   ],
   "source": [
    "f1_scores['train']['DT'] = accuracy_score(y_train, yhat_train1)\n",
    "f1_scores['test']['DT'] = accuracy_score(y_test, yhat_test1)\n",
    "\n",
    "\n",
    "jaccard_scores['train']['DT'] = jaccard_score(y_train, yhat_train1, pos_label = 0)\n",
    "jaccard_scores['test']['DT'] = jaccard_score(y_test, yhat_test1, pos_label = 0)\n",
    "                                              \n",
    "print(f1_scores)\n",
    "print(jaccard_scores)                                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ZjQch2RM1lL"
   },
   "source": [
    "# Additional Question: \n",
    "### Interpret and explain the parameters you have chosen to fine tune in DT algorithm.\n",
    "Type your answer in the cell bellow as the markdown format.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QLvhv6JrM1lA"
   },
   "source": [
    "+ criterion (\"gini\", \"entropy\"): The function to measure the quality of a split. Supported criteria are \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
    "\n",
    "+ splitter (\"best\", \"random\"): The strategy used to choose the split at each node. Supported strategies are \"best\" to choose the best split and \"random\" to choose the best random split.\n",
    "\n",
    "+ max_depth (The maximum depth of the tree): take a range from 1 to 31\n",
    "\n",
    "+ min_samples_split (The minimum number of samples required to split an internal node): take 10% to 100% \n",
    "\n",
    "+ min_samples_leaf (The minimum number of samples required to be at a leaf node):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g4aBT64WM1lL"
   },
   "source": [
    "### TO DO:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nd4a59C6M1lQ"
   },
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sn_wfdWpM1lR"
   },
   "source": [
    "### 15, 16. Perform task 11 and 12 on SVM models.\n",
    "\n",
    "Hint: Using GridSearchCV in sklearn.model_selection.\n",
    "\n",
    "**Warning**: You should not use the test data for finding the best parameters.\n",
    "\n",
    "**Requirement**: F1 score on test data has to higher than **0.62**, Jaccard similarity score must be higher than **0.75**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.9691288 , 0.23323438, 0.12827759, 0.02835836, 0.5779187 ,\n",
       "        0.18609016, 0.02841742, 0.0066787 , 0.9284826 , 0.21564369,\n",
       "        0.11609795, 0.02547967, 0.52037115, 0.16629093, 0.02772853,\n",
       "        0.0056998 , 0.12875319, 0.02962239, 0.06552827, 0.01237574,\n",
       "        0.07421966, 0.02106905, 0.02815523, 0.00594492, 0.13316102,\n",
       "        0.02995498, 0.06126902, 0.01193151, 0.08148375, 0.02282741,\n",
       "        0.0300211 , 0.00594413, 0.04247837, 0.00915515, 0.052705  ,\n",
       "        0.00932949, 0.03664465, 0.00794036, 0.03738606, 0.00788522,\n",
       "        0.0401998 , 0.00918889, 0.05185947, 0.00881631, 0.03522511,\n",
       "        0.00756013, 0.03765662, 0.00783017, 0.02956412, 0.00602591,\n",
       "        0.05764604, 0.0095726 , 0.03118296, 0.00863895, 0.04530737,\n",
       "        0.00928841, 0.02903838, 0.00628562, 0.05604103, 0.00963063,\n",
       "        0.03264194, 0.00704155, 0.04352243, 0.00898457, 0.02843335,\n",
       "        0.00597131, 0.05466242, 0.00921187, 0.03131504, 0.00668488,\n",
       "        0.04728296, 0.00968828, 0.0309828 , 0.0067287 , 0.0587903 ,\n",
       "        0.00981305, 0.03375616, 0.00733802, 0.04760573, 0.01000066]),\n",
       " 'std_fit_time': array([0.09481292, 0.05690135, 0.00910489, 0.00167475, 0.10539142,\n",
       "        0.05513877, 0.00238329, 0.0006566 , 0.12043635, 0.05316753,\n",
       "        0.00650938, 0.00309968, 0.10204656, 0.04287306, 0.00100388,\n",
       "        0.00061946, 0.01108394, 0.00399248, 0.004559  , 0.00112696,\n",
       "        0.00807962, 0.0038859 , 0.00184969, 0.00062815, 0.01045413,\n",
       "        0.00431052, 0.00188808, 0.00052058, 0.01095751, 0.0058618 ,\n",
       "        0.00133254, 0.00049839, 0.00159104, 0.00058721, 0.00212575,\n",
       "        0.00062762, 0.00103845, 0.00025907, 0.00102687, 0.00029683,\n",
       "        0.00212262, 0.00056262, 0.00146314, 0.00044534, 0.00095868,\n",
       "        0.00050432, 0.0015292 , 0.00073405, 0.00072601, 0.00045537,\n",
       "        0.00160402, 0.00049589, 0.00123611, 0.0038557 , 0.00453829,\n",
       "        0.00038573, 0.00055065, 0.00039172, 0.00058133, 0.00040829,\n",
       "        0.00091051, 0.00044437, 0.00080824, 0.00039075, 0.00043558,\n",
       "        0.00017101, 0.00059345, 0.00043484, 0.00040925, 0.00039373,\n",
       "        0.00070593, 0.00060035, 0.00074114, 0.00046897, 0.00344104,\n",
       "        0.00062017, 0.00080927, 0.0005429 , 0.00138806, 0.00050659]),\n",
       " 'mean_score_time': array([0.00100489, 0.00090292, 0.00288701, 0.00237379, 0.00099952,\n",
       "        0.00091317, 0.00119517, 0.00100477, 0.00069661, 0.00100701,\n",
       "        0.00219295, 0.00209856, 0.0008873 , 0.00100191, 0.00092721,\n",
       "        0.00080125, 0.0007942 , 0.00072539, 0.0022315 , 0.00248475,\n",
       "        0.00090871, 0.00100248, 0.0007988 , 0.00056312, 0.000804  ,\n",
       "        0.00074396, 0.00237539, 0.00239308, 0.00109668, 0.00089946,\n",
       "        0.001091  , 0.00086288, 0.00080526, 0.00089822, 0.0024051 ,\n",
       "        0.00238085, 0.00108421, 0.00092516, 0.00102181, 0.00091743,\n",
       "        0.00070198, 0.00090208, 0.00269463, 0.00225236, 0.00101414,\n",
       "        0.00110579, 0.0011095 , 0.00090473, 0.00090363, 0.00069506,\n",
       "        0.00282986, 0.00279887, 0.00100019, 0.00139902, 0.00111015,\n",
       "        0.00112715, 0.00100026, 0.00090501, 0.00257411, 0.00256097,\n",
       "        0.00100174, 0.00080597, 0.00120692, 0.00110035, 0.00099847,\n",
       "        0.00100765, 0.00229394, 0.00281889, 0.00109196, 0.00099664,\n",
       "        0.0014966 , 0.00119786, 0.00110819, 0.00111501, 0.00298343,\n",
       "        0.00270987, 0.00109761, 0.00099053, 0.00120034, 0.00156763]),\n",
       " 'std_score_time': array([5.23237044e-05, 5.45231060e-04, 7.17642244e-04, 6.39817446e-04,\n",
       "        1.77316916e-05, 3.06051318e-04, 5.91222405e-04, 1.17456182e-05,\n",
       "        4.56057897e-04, 1.63061750e-05, 3.87826840e-04, 5.33855711e-04,\n",
       "        2.98391633e-04, 2.10673677e-05, 5.65061740e-04, 4.01084399e-04,\n",
       "        3.97423654e-04, 4.81660567e-04, 3.93389560e-04, 6.68055179e-04,\n",
       "        3.05364934e-04, 1.59384380e-05, 5.99392532e-04, 4.71455743e-04,\n",
       "        4.02252784e-04, 5.09260547e-04, 4.59716568e-04, 4.89094816e-04,\n",
       "        2.99401563e-04, 3.00108882e-04, 2.89142135e-04, 3.34455395e-04,\n",
       "        4.02852949e-04, 2.99406868e-04, 4.94985187e-04, 4.43953602e-04,\n",
       "        3.21675567e-04, 3.19361917e-04, 3.70049599e-05, 3.07001987e-04,\n",
       "        4.59641107e-04, 3.01644171e-04, 4.57555113e-04, 4.08733932e-04,\n",
       "        5.30669843e-05, 2.98178251e-04, 3.06619051e-04, 3.01944570e-04,\n",
       "        3.02281052e-04, 4.55444317e-04, 4.02564812e-04, 4.60022974e-04,\n",
       "        1.82381486e-05, 1.27652446e-03, 2.94493835e-04, 2.98582243e-04,\n",
       "        1.79385860e-05, 3.02010649e-04, 4.83925329e-04, 4.81899099e-04,\n",
       "        1.07231125e-05, 4.03275780e-04, 3.96467155e-04, 2.99676274e-04,\n",
       "        1.58182956e-05, 3.23125702e-05, 4.66530738e-04, 3.02606456e-04,\n",
       "        3.03186737e-04, 4.38848573e-04, 4.98391521e-04, 3.98995537e-04,\n",
       "        2.97395894e-04, 2.95519921e-04, 7.63423149e-04, 6.49723455e-04,\n",
       "        2.99239311e-04, 4.46753810e-04, 4.05613453e-04, 4.77006721e-04]),\n",
       " 'param_C': masked_array(data=[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 1.0, 1.0, 1.0, 1.0,\n",
       "                    1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
       "                    1.0, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "                    0.001, 0.001, 0.001, 0.001, 0.001],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_gamma': masked_array(data=['scale', 'scale', 'scale', 'scale', 'scale', 'scale',\n",
       "                    'scale', 'scale', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'scale', 'scale',\n",
       "                    'scale', 'scale', 'scale', 'scale', 'scale', 'scale',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'scale', 'scale', 'scale', 'scale', 'scale',\n",
       "                    'scale', 'scale', 'scale', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'scale',\n",
       "                    'scale', 'scale', 'scale', 'scale', 'scale', 'scale',\n",
       "                    'scale', 'auto', 'auto', 'auto', 'auto', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'scale', 'scale', 'scale',\n",
       "                    'scale', 'scale', 'scale', 'scale', 'scale', 'auto',\n",
       "                    'auto', 'auto', 'auto', 'auto', 'auto', 'auto', 'auto'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['linear', 'linear', 'rbf', 'rbf', 'poly', 'poly',\n",
       "                    'sigmoid', 'sigmoid', 'linear', 'linear', 'rbf', 'rbf',\n",
       "                    'poly', 'poly', 'sigmoid', 'sigmoid', 'linear',\n",
       "                    'linear', 'rbf', 'rbf', 'poly', 'poly', 'sigmoid',\n",
       "                    'sigmoid', 'linear', 'linear', 'rbf', 'rbf', 'poly',\n",
       "                    'poly', 'sigmoid', 'sigmoid', 'linear', 'linear',\n",
       "                    'rbf', 'rbf', 'poly', 'poly', 'sigmoid', 'sigmoid',\n",
       "                    'linear', 'linear', 'rbf', 'rbf', 'poly', 'poly',\n",
       "                    'sigmoid', 'sigmoid', 'linear', 'linear', 'rbf', 'rbf',\n",
       "                    'poly', 'poly', 'sigmoid', 'sigmoid', 'linear',\n",
       "                    'linear', 'rbf', 'rbf', 'poly', 'poly', 'sigmoid',\n",
       "                    'sigmoid', 'linear', 'linear', 'rbf', 'rbf', 'poly',\n",
       "                    'poly', 'sigmoid', 'sigmoid', 'linear', 'linear',\n",
       "                    'rbf', 'rbf', 'poly', 'poly', 'sigmoid', 'sigmoid'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_probability': masked_array(data=[True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False,\n",
       "                    True, False, True, False, True, False, True, False],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 100,\n",
       "   'gamma': 'scale',\n",
       "   'kernel': 'linear',\n",
       "   'probability': True},\n",
       "  {'C': 100, 'gamma': 'scale', 'kernel': 'linear', 'probability': False},\n",
       "  {'C': 100, 'gamma': 'scale', 'kernel': 'rbf', 'probability': True},\n",
       "  {'C': 100, 'gamma': 'scale', 'kernel': 'rbf', 'probability': False},\n",
       "  {'C': 100, 'gamma': 'scale', 'kernel': 'poly', 'probability': True},\n",
       "  {'C': 100, 'gamma': 'scale', 'kernel': 'poly', 'probability': False},\n",
       "  {'C': 100, 'gamma': 'scale', 'kernel': 'sigmoid', 'probability': True},\n",
       "  {'C': 100, 'gamma': 'scale', 'kernel': 'sigmoid', 'probability': False},\n",
       "  {'C': 100, 'gamma': 'auto', 'kernel': 'linear', 'probability': True},\n",
       "  {'C': 100, 'gamma': 'auto', 'kernel': 'linear', 'probability': False},\n",
       "  {'C': 100, 'gamma': 'auto', 'kernel': 'rbf', 'probability': True},\n",
       "  {'C': 100, 'gamma': 'auto', 'kernel': 'rbf', 'probability': False},\n",
       "  {'C': 100, 'gamma': 'auto', 'kernel': 'poly', 'probability': True},\n",
       "  {'C': 100, 'gamma': 'auto', 'kernel': 'poly', 'probability': False},\n",
       "  {'C': 100, 'gamma': 'auto', 'kernel': 'sigmoid', 'probability': True},\n",
       "  {'C': 100, 'gamma': 'auto', 'kernel': 'sigmoid', 'probability': False},\n",
       "  {'C': 10, 'gamma': 'scale', 'kernel': 'linear', 'probability': True},\n",
       "  {'C': 10, 'gamma': 'scale', 'kernel': 'linear', 'probability': False},\n",
       "  {'C': 10, 'gamma': 'scale', 'kernel': 'rbf', 'probability': True},\n",
       "  {'C': 10, 'gamma': 'scale', 'kernel': 'rbf', 'probability': False},\n",
       "  {'C': 10, 'gamma': 'scale', 'kernel': 'poly', 'probability': True},\n",
       "  {'C': 10, 'gamma': 'scale', 'kernel': 'poly', 'probability': False},\n",
       "  {'C': 10, 'gamma': 'scale', 'kernel': 'sigmoid', 'probability': True},\n",
       "  {'C': 10, 'gamma': 'scale', 'kernel': 'sigmoid', 'probability': False},\n",
       "  {'C': 10, 'gamma': 'auto', 'kernel': 'linear', 'probability': True},\n",
       "  {'C': 10, 'gamma': 'auto', 'kernel': 'linear', 'probability': False},\n",
       "  {'C': 10, 'gamma': 'auto', 'kernel': 'rbf', 'probability': True},\n",
       "  {'C': 10, 'gamma': 'auto', 'kernel': 'rbf', 'probability': False},\n",
       "  {'C': 10, 'gamma': 'auto', 'kernel': 'poly', 'probability': True},\n",
       "  {'C': 10, 'gamma': 'auto', 'kernel': 'poly', 'probability': False},\n",
       "  {'C': 10, 'gamma': 'auto', 'kernel': 'sigmoid', 'probability': True},\n",
       "  {'C': 10, 'gamma': 'auto', 'kernel': 'sigmoid', 'probability': False},\n",
       "  {'C': 1.0, 'gamma': 'scale', 'kernel': 'linear', 'probability': True},\n",
       "  {'C': 1.0, 'gamma': 'scale', 'kernel': 'linear', 'probability': False},\n",
       "  {'C': 1.0, 'gamma': 'scale', 'kernel': 'rbf', 'probability': True},\n",
       "  {'C': 1.0, 'gamma': 'scale', 'kernel': 'rbf', 'probability': False},\n",
       "  {'C': 1.0, 'gamma': 'scale', 'kernel': 'poly', 'probability': True},\n",
       "  {'C': 1.0, 'gamma': 'scale', 'kernel': 'poly', 'probability': False},\n",
       "  {'C': 1.0, 'gamma': 'scale', 'kernel': 'sigmoid', 'probability': True},\n",
       "  {'C': 1.0, 'gamma': 'scale', 'kernel': 'sigmoid', 'probability': False},\n",
       "  {'C': 1.0, 'gamma': 'auto', 'kernel': 'linear', 'probability': True},\n",
       "  {'C': 1.0, 'gamma': 'auto', 'kernel': 'linear', 'probability': False},\n",
       "  {'C': 1.0, 'gamma': 'auto', 'kernel': 'rbf', 'probability': True},\n",
       "  {'C': 1.0, 'gamma': 'auto', 'kernel': 'rbf', 'probability': False},\n",
       "  {'C': 1.0, 'gamma': 'auto', 'kernel': 'poly', 'probability': True},\n",
       "  {'C': 1.0, 'gamma': 'auto', 'kernel': 'poly', 'probability': False},\n",
       "  {'C': 1.0, 'gamma': 'auto', 'kernel': 'sigmoid', 'probability': True},\n",
       "  {'C': 1.0, 'gamma': 'auto', 'kernel': 'sigmoid', 'probability': False},\n",
       "  {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'probability': True},\n",
       "  {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear', 'probability': False},\n",
       "  {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf', 'probability': True},\n",
       "  {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf', 'probability': False},\n",
       "  {'C': 0.1, 'gamma': 'scale', 'kernel': 'poly', 'probability': True},\n",
       "  {'C': 0.1, 'gamma': 'scale', 'kernel': 'poly', 'probability': False},\n",
       "  {'C': 0.1, 'gamma': 'scale', 'kernel': 'sigmoid', 'probability': True},\n",
       "  {'C': 0.1, 'gamma': 'scale', 'kernel': 'sigmoid', 'probability': False},\n",
       "  {'C': 0.1, 'gamma': 'auto', 'kernel': 'linear', 'probability': True},\n",
       "  {'C': 0.1, 'gamma': 'auto', 'kernel': 'linear', 'probability': False},\n",
       "  {'C': 0.1, 'gamma': 'auto', 'kernel': 'rbf', 'probability': True},\n",
       "  {'C': 0.1, 'gamma': 'auto', 'kernel': 'rbf', 'probability': False},\n",
       "  {'C': 0.1, 'gamma': 'auto', 'kernel': 'poly', 'probability': True},\n",
       "  {'C': 0.1, 'gamma': 'auto', 'kernel': 'poly', 'probability': False},\n",
       "  {'C': 0.1, 'gamma': 'auto', 'kernel': 'sigmoid', 'probability': True},\n",
       "  {'C': 0.1, 'gamma': 'auto', 'kernel': 'sigmoid', 'probability': False},\n",
       "  {'C': 0.001, 'gamma': 'scale', 'kernel': 'linear', 'probability': True},\n",
       "  {'C': 0.001, 'gamma': 'scale', 'kernel': 'linear', 'probability': False},\n",
       "  {'C': 0.001, 'gamma': 'scale', 'kernel': 'rbf', 'probability': True},\n",
       "  {'C': 0.001, 'gamma': 'scale', 'kernel': 'rbf', 'probability': False},\n",
       "  {'C': 0.001, 'gamma': 'scale', 'kernel': 'poly', 'probability': True},\n",
       "  {'C': 0.001, 'gamma': 'scale', 'kernel': 'poly', 'probability': False},\n",
       "  {'C': 0.001, 'gamma': 'scale', 'kernel': 'sigmoid', 'probability': True},\n",
       "  {'C': 0.001, 'gamma': 'scale', 'kernel': 'sigmoid', 'probability': False},\n",
       "  {'C': 0.001, 'gamma': 'auto', 'kernel': 'linear', 'probability': True},\n",
       "  {'C': 0.001, 'gamma': 'auto', 'kernel': 'linear', 'probability': False},\n",
       "  {'C': 0.001, 'gamma': 'auto', 'kernel': 'rbf', 'probability': True},\n",
       "  {'C': 0.001, 'gamma': 'auto', 'kernel': 'rbf', 'probability': False},\n",
       "  {'C': 0.001, 'gamma': 'auto', 'kernel': 'poly', 'probability': True},\n",
       "  {'C': 0.001, 'gamma': 'auto', 'kernel': 'poly', 'probability': False},\n",
       "  {'C': 0.001, 'gamma': 'auto', 'kernel': 'sigmoid', 'probability': True},\n",
       "  {'C': 0.001, 'gamma': 'auto', 'kernel': 'sigmoid', 'probability': False}],\n",
       " 'split0_test_score': array([0.75806452, 0.75806452, 0.59677419, 0.59677419, 0.64516129,\n",
       "        0.64516129, 0.69354839, 0.69354839, 0.75806452, 0.75806452,\n",
       "        0.58064516, 0.58064516, 0.66129032, 0.66129032, 0.70967742,\n",
       "        0.70967742, 0.75806452, 0.75806452, 0.64516129, 0.64516129,\n",
       "        0.67741935, 0.67741935, 0.70967742, 0.70967742, 0.75806452,\n",
       "        0.75806452, 0.64516129, 0.64516129, 0.67741935, 0.67741935,\n",
       "        0.69354839, 0.69354839, 0.75806452, 0.75806452, 0.69354839,\n",
       "        0.69354839, 0.69354839, 0.69354839, 0.75806452, 0.75806452,\n",
       "        0.75806452, 0.75806452, 0.69354839, 0.69354839, 0.69354839,\n",
       "        0.69354839, 0.74193548, 0.74193548, 0.75806452, 0.75806452,\n",
       "        0.67741935, 0.67741935, 0.69354839, 0.69354839, 0.72580645,\n",
       "        0.72580645, 0.75806452, 0.75806452, 0.67741935, 0.67741935,\n",
       "        0.69354839, 0.69354839, 0.72580645, 0.72580645, 0.66129032,\n",
       "        0.66129032, 0.66129032, 0.66129032, 0.66129032, 0.66129032,\n",
       "        0.66129032, 0.66129032, 0.66129032, 0.66129032, 0.66129032,\n",
       "        0.66129032, 0.66129032, 0.66129032, 0.66129032, 0.66129032]),\n",
       " 'split1_test_score': array([0.80645161, 0.80645161, 0.75806452, 0.75806452, 0.75806452,\n",
       "        0.75806452, 0.72580645, 0.72580645, 0.80645161, 0.80645161,\n",
       "        0.75806452, 0.75806452, 0.74193548, 0.74193548, 0.70967742,\n",
       "        0.70967742, 0.80645161, 0.80645161, 0.79032258, 0.79032258,\n",
       "        0.79032258, 0.79032258, 0.72580645, 0.72580645, 0.80645161,\n",
       "        0.80645161, 0.79032258, 0.79032258, 0.80645161, 0.80645161,\n",
       "        0.72580645, 0.72580645, 0.80645161, 0.80645161, 0.82258065,\n",
       "        0.82258065, 0.85483871, 0.85483871, 0.79032258, 0.79032258,\n",
       "        0.80645161, 0.80645161, 0.82258065, 0.82258065, 0.85483871,\n",
       "        0.85483871, 0.79032258, 0.79032258, 0.80645161, 0.80645161,\n",
       "        0.79032258, 0.79032258, 0.79032258, 0.79032258, 0.80645161,\n",
       "        0.80645161, 0.80645161, 0.80645161, 0.79032258, 0.79032258,\n",
       "        0.77419355, 0.77419355, 0.80645161, 0.80645161, 0.66129032,\n",
       "        0.66129032, 0.66129032, 0.66129032, 0.66129032, 0.66129032,\n",
       "        0.66129032, 0.66129032, 0.66129032, 0.66129032, 0.66129032,\n",
       "        0.66129032, 0.66129032, 0.66129032, 0.66129032, 0.66129032]),\n",
       " 'split2_test_score': array([0.70967742, 0.70967742, 0.75806452, 0.75806452, 0.66129032,\n",
       "        0.66129032, 0.66129032, 0.66129032, 0.70967742, 0.70967742,\n",
       "        0.75806452, 0.75806452, 0.66129032, 0.66129032, 0.70967742,\n",
       "        0.70967742, 0.70967742, 0.70967742, 0.72580645, 0.72580645,\n",
       "        0.70967742, 0.70967742, 0.70967742, 0.70967742, 0.70967742,\n",
       "        0.70967742, 0.72580645, 0.72580645, 0.70967742, 0.70967742,\n",
       "        0.66129032, 0.66129032, 0.67741935, 0.67741935, 0.72580645,\n",
       "        0.72580645, 0.67741935, 0.67741935, 0.74193548, 0.74193548,\n",
       "        0.67741935, 0.67741935, 0.72580645, 0.72580645, 0.67741935,\n",
       "        0.67741935, 0.74193548, 0.74193548, 0.69354839, 0.69354839,\n",
       "        0.70967742, 0.70967742, 0.72580645, 0.72580645, 0.72580645,\n",
       "        0.72580645, 0.69354839, 0.69354839, 0.70967742, 0.70967742,\n",
       "        0.72580645, 0.72580645, 0.72580645, 0.72580645, 0.66129032,\n",
       "        0.66129032, 0.66129032, 0.66129032, 0.66129032, 0.66129032,\n",
       "        0.66129032, 0.66129032, 0.66129032, 0.66129032, 0.66129032,\n",
       "        0.66129032, 0.66129032, 0.66129032, 0.66129032, 0.66129032]),\n",
       " 'split3_test_score': array([0.82258065, 0.82258065, 0.72580645, 0.72580645, 0.70967742,\n",
       "        0.70967742, 0.61290323, 0.61290323, 0.82258065, 0.82258065,\n",
       "        0.72580645, 0.72580645, 0.70967742, 0.70967742, 0.67741935,\n",
       "        0.67741935, 0.82258065, 0.82258065, 0.72580645, 0.72580645,\n",
       "        0.67741935, 0.67741935, 0.67741935, 0.67741935, 0.82258065,\n",
       "        0.82258065, 0.72580645, 0.72580645, 0.69354839, 0.69354839,\n",
       "        0.67741935, 0.67741935, 0.82258065, 0.82258065, 0.79032258,\n",
       "        0.79032258, 0.70967742, 0.70967742, 0.74193548, 0.74193548,\n",
       "        0.82258065, 0.82258065, 0.79032258, 0.79032258, 0.70967742,\n",
       "        0.70967742, 0.75806452, 0.75806452, 0.82258065, 0.82258065,\n",
       "        0.75806452, 0.75806452, 0.70967742, 0.70967742, 0.79032258,\n",
       "        0.79032258, 0.82258065, 0.82258065, 0.75806452, 0.75806452,\n",
       "        0.70967742, 0.70967742, 0.79032258, 0.79032258, 0.64516129,\n",
       "        0.64516129, 0.64516129, 0.64516129, 0.64516129, 0.64516129,\n",
       "        0.64516129, 0.64516129, 0.64516129, 0.64516129, 0.64516129,\n",
       "        0.64516129, 0.64516129, 0.64516129, 0.64516129, 0.64516129]),\n",
       " 'split4_test_score': array([0.7704918 , 0.7704918 , 0.70491803, 0.70491803, 0.73770492,\n",
       "        0.73770492, 0.70491803, 0.70491803, 0.7704918 , 0.7704918 ,\n",
       "        0.70491803, 0.70491803, 0.72131148, 0.72131148, 0.72131148,\n",
       "        0.72131148, 0.7704918 , 0.7704918 , 0.73770492, 0.73770492,\n",
       "        0.80327869, 0.80327869, 0.68852459, 0.68852459, 0.7704918 ,\n",
       "        0.7704918 , 0.73770492, 0.73770492, 0.80327869, 0.80327869,\n",
       "        0.70491803, 0.70491803, 0.7704918 , 0.7704918 , 0.73770492,\n",
       "        0.73770492, 0.7704918 , 0.7704918 , 0.73770492, 0.73770492,\n",
       "        0.7704918 , 0.7704918 , 0.73770492, 0.73770492, 0.7704918 ,\n",
       "        0.7704918 , 0.73770492, 0.73770492, 0.78688525, 0.78688525,\n",
       "        0.6557377 , 0.6557377 , 0.73770492, 0.73770492, 0.75409836,\n",
       "        0.75409836, 0.78688525, 0.78688525, 0.67213115, 0.67213115,\n",
       "        0.72131148, 0.72131148, 0.75409836, 0.75409836, 0.6557377 ,\n",
       "        0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 ,\n",
       "        0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 ,\n",
       "        0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 ]),\n",
       " 'split5_test_score': array([0.6557377 , 0.6557377 , 0.59016393, 0.59016393, 0.62295082,\n",
       "        0.62295082, 0.59016393, 0.59016393, 0.6557377 , 0.6557377 ,\n",
       "        0.59016393, 0.59016393, 0.62295082, 0.62295082, 0.55737705,\n",
       "        0.55737705, 0.6557377 , 0.6557377 , 0.60655738, 0.60655738,\n",
       "        0.60655738, 0.60655738, 0.59016393, 0.59016393, 0.6557377 ,\n",
       "        0.6557377 , 0.60655738, 0.60655738, 0.60655738, 0.60655738,\n",
       "        0.59016393, 0.59016393, 0.6557377 , 0.6557377 , 0.63934426,\n",
       "        0.63934426, 0.63934426, 0.63934426, 0.67213115, 0.67213115,\n",
       "        0.6557377 , 0.6557377 , 0.63934426, 0.63934426, 0.63934426,\n",
       "        0.63934426, 0.67213115, 0.67213115, 0.6557377 , 0.6557377 ,\n",
       "        0.67213115, 0.67213115, 0.67213115, 0.67213115, 0.67213115,\n",
       "        0.67213115, 0.6557377 , 0.6557377 , 0.67213115, 0.67213115,\n",
       "        0.67213115, 0.67213115, 0.67213115, 0.67213115, 0.6557377 ,\n",
       "        0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 ,\n",
       "        0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 ,\n",
       "        0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 ]),\n",
       " 'split6_test_score': array([0.81967213, 0.81967213, 0.68852459, 0.68852459, 0.68852459,\n",
       "        0.68852459, 0.63934426, 0.63934426, 0.81967213, 0.81967213,\n",
       "        0.68852459, 0.68852459, 0.68852459, 0.68852459, 0.6557377 ,\n",
       "        0.6557377 , 0.81967213, 0.81967213, 0.7704918 , 0.7704918 ,\n",
       "        0.73770492, 0.73770492, 0.67213115, 0.67213115, 0.81967213,\n",
       "        0.81967213, 0.7704918 , 0.7704918 , 0.75409836, 0.75409836,\n",
       "        0.68852459, 0.68852459, 0.81967213, 0.81967213, 0.7704918 ,\n",
       "        0.7704918 , 0.73770492, 0.73770492, 0.78688525, 0.78688525,\n",
       "        0.81967213, 0.81967213, 0.7704918 , 0.7704918 , 0.73770492,\n",
       "        0.73770492, 0.72131148, 0.72131148, 0.83606557, 0.83606557,\n",
       "        0.75409836, 0.75409836, 0.72131148, 0.72131148, 0.80327869,\n",
       "        0.80327869, 0.83606557, 0.83606557, 0.7704918 , 0.7704918 ,\n",
       "        0.72131148, 0.72131148, 0.80327869, 0.80327869, 0.6557377 ,\n",
       "        0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 ,\n",
       "        0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 ,\n",
       "        0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 ]),\n",
       " 'split7_test_score': array([0.83606557, 0.83606557, 0.68852459, 0.68852459, 0.83606557,\n",
       "        0.83606557, 0.75409836, 0.75409836, 0.83606557, 0.83606557,\n",
       "        0.68852459, 0.68852459, 0.83606557, 0.83606557, 0.75409836,\n",
       "        0.75409836, 0.83606557, 0.83606557, 0.7704918 , 0.7704918 ,\n",
       "        0.80327869, 0.80327869, 0.7704918 , 0.7704918 , 0.83606557,\n",
       "        0.83606557, 0.7704918 , 0.7704918 , 0.80327869, 0.80327869,\n",
       "        0.70491803, 0.70491803, 0.83606557, 0.83606557, 0.80327869,\n",
       "        0.80327869, 0.7704918 , 0.7704918 , 0.81967213, 0.81967213,\n",
       "        0.83606557, 0.83606557, 0.80327869, 0.80327869, 0.75409836,\n",
       "        0.75409836, 0.80327869, 0.80327869, 0.83606557, 0.83606557,\n",
       "        0.75409836, 0.75409836, 0.68852459, 0.68852459, 0.81967213,\n",
       "        0.81967213, 0.83606557, 0.83606557, 0.75409836, 0.75409836,\n",
       "        0.68852459, 0.68852459, 0.81967213, 0.81967213, 0.6557377 ,\n",
       "        0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 ,\n",
       "        0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 ,\n",
       "        0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 ]),\n",
       " 'split8_test_score': array([0.78688525, 0.78688525, 0.78688525, 0.78688525, 0.6557377 ,\n",
       "        0.6557377 , 0.73770492, 0.73770492, 0.78688525, 0.78688525,\n",
       "        0.78688525, 0.78688525, 0.6557377 , 0.6557377 , 0.75409836,\n",
       "        0.75409836, 0.78688525, 0.78688525, 0.75409836, 0.75409836,\n",
       "        0.73770492, 0.73770492, 0.72131148, 0.72131148, 0.78688525,\n",
       "        0.78688525, 0.73770492, 0.73770492, 0.73770492, 0.73770492,\n",
       "        0.70491803, 0.70491803, 0.78688525, 0.78688525, 0.73770492,\n",
       "        0.73770492, 0.72131148, 0.72131148, 0.75409836, 0.75409836,\n",
       "        0.78688525, 0.78688525, 0.73770492, 0.73770492, 0.72131148,\n",
       "        0.72131148, 0.75409836, 0.75409836, 0.78688525, 0.78688525,\n",
       "        0.72131148, 0.72131148, 0.6557377 , 0.6557377 , 0.78688525,\n",
       "        0.78688525, 0.78688525, 0.78688525, 0.72131148, 0.72131148,\n",
       "        0.6557377 , 0.6557377 , 0.78688525, 0.78688525, 0.6557377 ,\n",
       "        0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 ,\n",
       "        0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 ,\n",
       "        0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 ]),\n",
       " 'split9_test_score': array([0.75409836, 0.75409836, 0.68852459, 0.68852459, 0.68852459,\n",
       "        0.68852459, 0.7704918 , 0.7704918 , 0.75409836, 0.75409836,\n",
       "        0.68852459, 0.68852459, 0.68852459, 0.68852459, 0.7704918 ,\n",
       "        0.7704918 , 0.75409836, 0.75409836, 0.6557377 , 0.6557377 ,\n",
       "        0.72131148, 0.72131148, 0.75409836, 0.75409836, 0.75409836,\n",
       "        0.75409836, 0.6557377 , 0.6557377 , 0.72131148, 0.72131148,\n",
       "        0.78688525, 0.78688525, 0.75409836, 0.75409836, 0.70491803,\n",
       "        0.70491803, 0.72131148, 0.72131148, 0.75409836, 0.75409836,\n",
       "        0.75409836, 0.75409836, 0.72131148, 0.72131148, 0.72131148,\n",
       "        0.72131148, 0.7704918 , 0.7704918 , 0.75409836, 0.75409836,\n",
       "        0.7704918 , 0.7704918 , 0.72131148, 0.72131148, 0.75409836,\n",
       "        0.75409836, 0.75409836, 0.75409836, 0.7704918 , 0.7704918 ,\n",
       "        0.72131148, 0.72131148, 0.75409836, 0.75409836, 0.6557377 ,\n",
       "        0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 ,\n",
       "        0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 ,\n",
       "        0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 ]),\n",
       " 'mean_test_score': array([0.7719725 , 0.7719725 , 0.69862507, 0.69862507, 0.70037017,\n",
       "        0.70037017, 0.68902697, 0.68902697, 0.7719725 , 0.7719725 ,\n",
       "        0.69701216, 0.69701216, 0.69873083, 0.69873083, 0.70195664,\n",
       "        0.70195664, 0.7719725 , 0.7719725 , 0.71821787, 0.71821787,\n",
       "        0.72646748, 0.72646748, 0.7019302 , 0.7019302 , 0.7719725 ,\n",
       "        0.7719725 , 0.71657853, 0.71657853, 0.73133263, 0.73133263,\n",
       "        0.69383924, 0.69383924, 0.76874669, 0.76874669, 0.74257007,\n",
       "        0.74257007, 0.72961396, 0.72961396, 0.75568482, 0.75568482,\n",
       "        0.76874669, 0.76874669, 0.74420941, 0.74420941, 0.72797462,\n",
       "        0.72797462, 0.74912745, 0.74912745, 0.77363829, 0.77363829,\n",
       "        0.72633527, 0.72633527, 0.71160762, 0.71160762, 0.7638551 ,\n",
       "        0.7638551 , 0.77363829, 0.77363829, 0.72961396, 0.72961396,\n",
       "        0.70835537, 0.70835537, 0.7638551 , 0.7638551 , 0.65634585,\n",
       "        0.65634585, 0.65634585, 0.65634585, 0.65634585, 0.65634585,\n",
       "        0.65634585, 0.65634585, 0.65634585, 0.65634585, 0.65634585,\n",
       "        0.65634585, 0.65634585, 0.65634585, 0.65634585, 0.65634585]),\n",
       " 'std_test_score': array([0.0531619 , 0.0531619 , 0.06170726, 0.06170726, 0.06005339,\n",
       "        0.06005339, 0.05802798, 0.05802798, 0.0531619 , 0.0531619 ,\n",
       "        0.06449613, 0.06449613, 0.05653329, 0.05653329, 0.05859143,\n",
       "        0.05859143, 0.0531619 , 0.0531619 , 0.05844283, 0.05844283,\n",
       "        0.05968946, 0.05968946, 0.04759005, 0.04759005, 0.0531619 ,\n",
       "        0.0531619 , 0.05763775, 0.05763775, 0.0608496 , 0.0608496 ,\n",
       "        0.04706764, 0.04706764, 0.05763457, 0.05763457, 0.05286954,\n",
       "        0.05286954, 0.0563894 , 0.0563894 , 0.03736428, 0.03736428,\n",
       "        0.05763457, 0.05763457, 0.05192231, 0.05192231, 0.05540691,\n",
       "        0.05540691, 0.03482312, 0.03482312, 0.05705844, 0.05705844,\n",
       "        0.04382932, 0.04382932, 0.03579047, 0.03579047, 0.04383402,\n",
       "        0.04383402, 0.05705844, 0.05705844, 0.04270325, 0.04270325,\n",
       "        0.03136536, 0.03136536, 0.04383402, 0.04383402, 0.00447947,\n",
       "        0.00447947, 0.00447947, 0.00447947, 0.00447947, 0.00447947,\n",
       "        0.00447947, 0.00447947, 0.00447947, 0.00447947, 0.00447947,\n",
       "        0.00447947, 0.00447947, 0.00447947, 0.00447947, 0.00447947]),\n",
       " 'rank_test_score': array([ 5,  5, 57, 57, 53, 53, 63, 63,  5,  5, 59, 59, 55, 55, 49, 49,  5,\n",
       "         5, 41, 41, 37, 37, 51, 51,  5,  5, 43, 43, 29, 29, 61, 61, 13, 13,\n",
       "        27, 27, 31, 31, 21, 21, 13, 13, 25, 25, 35, 35, 23, 23,  1,  1, 39,\n",
       "        39, 45, 45, 17, 17,  1,  1, 31, 31, 47, 47, 17, 17, 65, 65, 65, 65,\n",
       "        65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65, 65])}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TO DO:\n",
    "from sklearn.svm import SVC\n",
    "param_grid = {'C': [100, 10, 1.0, 0.1, 0.001],\n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "    'gamma': ['scale','auto'],\n",
    "    'probability' : [True, False]\n",
    "             }\n",
    "grid2 = GridSearchCV(SVC(), param_grid, cv=10, scoring='accuracy')\n",
    "# fit the grid with data\n",
    "grid2.fit(X_train, y_train)\n",
    "grid2.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7736382866208356\n",
      "SVC(C=0.1, kernel='linear', probability=True)\n",
      "{'C': 0.1, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'probability': True, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "# examine the best parameter\n",
    "print(grid2.best_score_)\n",
    "print(grid2.best_estimator_)\n",
    "print(grid2.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = SVC(C=0.1, kernel='linear', probability=True).fit(X_train, y_train)\n",
    "yhat_test2 = svc.predict(X_test)\n",
    "yhat_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_train2 = svc.predict(X_train)\n",
    "yhat_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of train set: 0.7752442996742671\n",
      "Accuracy score of test set: 0.7727272727272727\n",
      "Jaccard score of train set: 0.7234468937875751\n",
      "Jaccard score of test set: 0.7131147540983607\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84       403\n",
      "           1       0.73      0.55      0.62       211\n",
      "\n",
      "    accuracy                           0.78       614\n",
      "   macro avg       0.76      0.72      0.73       614\n",
      "weighted avg       0.77      0.78      0.77       614\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.83        97\n",
      "           1       0.76      0.56      0.65        57\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.77      0.73      0.74       154\n",
      "weighted avg       0.77      0.77      0.76       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TO DO:\n",
    "print(\"Accuracy score of train set:\", accuracy_score(y_train, yhat_train2))\n",
    "print(\"Accuracy score of test set:\", accuracy_score(y_test, yhat_test2))\n",
    "\n",
    "print(\"Jaccard score of train set:\", jaccard_score(y_train, yhat_train2, pos_label = 0))\n",
    "print(\"Jaccard score of test set:\", jaccard_score(y_test, yhat_test2, pos_label = 0))\n",
    "\n",
    "print (classification_report(y_train, yhat_train2))\n",
    "print (classification_report(y_test, yhat_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': {'KNN': 0.7899022801302932, 'DT': 0.7785016286644951, 'SVM': 0.7752442996742671, 'LR': 0, 'EN_HARD': 0, 'EN_SOFT': 0}, 'test': {'KNN': 0.7727272727272727, 'DT': 0.7532467532467533, 'SVM': 0.7727272727272727, 'LR': 0, 'EN_HARD': 0, 'EN_SOFT': 0}}\n",
      "{'train': {'KNN': 0.7435387673956262, 'DT': 0.7075268817204301, 'SVM': 0.7234468937875751, 'LR': 0, 'EN_HARD': 0, 'EN_SOFT': 0}, 'test': {'KNN': 0.7244094488188977, 'DT': 0.6666666666666666, 'SVM': 0.7131147540983607, 'LR': 0, 'EN_HARD': 0, 'EN_SOFT': 0}}\n"
     ]
    }
   ],
   "source": [
    "f1_scores['train']['SVM'] = accuracy_score(y_train, yhat_train2)\n",
    "f1_scores['test']['SVM'] = accuracy_score(y_test, yhat_test2)\n",
    "jaccard_scores['train']['SVM'] = jaccard_score(y_train, yhat_train2, pos_label = 0)\n",
    "jaccard_scores['test']['SVM'] = jaccard_score(y_test, yhat_test2, pos_label = 0)\n",
    "                                          \n",
    "print(f1_scores)\n",
    "print(jaccard_scores) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03XgTdoPM1lW"
   },
   "source": [
    "# Additional Question: \n",
    "### Interpret and explain the parameters you have chosen to fine tune in SVM algorithm.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03XgTdoPM1lW"
   },
   "source": [
    "+ C (Regularization parameter) The strength of the regularization is inversely proportional to C\n",
    "\n",
    "+ kernel (the kernel type to be used in the algorithm): {'linear', 'poly', 'rbf', 'sigmoid', 'precomputed'}\n",
    "\n",
    "+ gamma (Kernel coefficient for 'rbf', 'poly' and 'sigmoid'): {'scale', 'auto'}\n",
    "\n",
    "+ probability (Whether to enable probability estimates) : {'True','False'} In default, probability is set as False. However, there are case the probability must be set as True in order to predict the value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xRVAKHEkM1la"
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTQkBQIXM1la"
   },
   "source": [
    "### 17, 18. Perform task 11 and 12 on Logistic Regression model.\n",
    "\n",
    "Hint: Using GridSearchCV in sklearn.model_selection.\n",
    "\n",
    "**Warning**: You should not use the test data for finding the best parameters.\n",
    "\n",
    "**Requirement**: F1 score on test data has to higher than **0.63**, Jaccard similarity score must be higher than **0.75**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "cWFYayQLM1lb"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1483: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "450 fits failed out of a total of 1000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "50 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\ADmin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.7735854         nan 0.7735854  0.7735854\n",
      " 0.7735854  0.7735854  0.7735854  0.7735854         nan        nan\n",
      "        nan        nan        nan 0.7735854  0.7735854         nan\n",
      " 0.7735854  0.7735854         nan        nan 0.7735854         nan\n",
      " 0.7735854  0.7735854  0.7735854  0.7735854  0.7735854  0.7735854\n",
      "        nan        nan        nan        nan        nan 0.7735854\n",
      " 0.7735854         nan 0.7735854  0.7735854         nan        nan\n",
      " 0.77191962        nan 0.77355896 0.77519831 0.77519831 0.77355896\n",
      " 0.77519831 0.77519831        nan        nan        nan        nan\n",
      "        nan 0.7735854  0.7735854         nan 0.7735854  0.7735854\n",
      "        nan        nan 0.76866737        nan 0.76216288 0.77033316\n",
      " 0.77033316 0.7638551  0.77033316 0.77033316        nan        nan\n",
      "        nan        nan        nan 0.7735854  0.7735854         nan\n",
      " 0.7735854  0.7735854         nan        nan 0.70037017        nan\n",
      " 0.65634585 0.75888419 0.75888419 0.75732417 0.75888419 0.75888419\n",
      "        nan        nan        nan        nan        nan 0.7735854\n",
      " 0.7735854         nan 0.7735854  0.7735854 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([3.98778915e-04, 9.97066498e-05, 1.16066933e-03, 2.99286842e-04,\n",
       "        2.16805935e-03, 5.94229698e-03, 3.61886024e-03, 1.34339333e-03,\n",
       "        3.15856934e-03, 2.07605362e-03, 2.52938271e-04, 1.99747086e-04,\n",
       "        2.99239159e-04, 1.03497505e-04, 1.99198723e-04, 5.64246178e-03,\n",
       "        3.29291821e-03, 2.16555595e-04, 2.77900696e-03, 2.41851807e-03,\n",
       "        2.99310684e-04, 9.97066498e-05, 1.33185387e-03, 9.98258591e-05,\n",
       "        3.54707241e-03, 6.47635460e-03, 3.49123478e-03, 1.32374763e-03,\n",
       "        2.57415771e-03, 2.75578499e-03, 1.99627876e-04, 2.96616554e-04,\n",
       "        2.99143791e-04, 2.99358368e-04, 2.99191475e-04, 5.87253571e-03,\n",
       "        3.54893208e-03, 3.23510170e-04, 2.84507275e-03, 2.43496895e-03,\n",
       "        3.58963013e-04, 3.98969650e-04, 1.19519234e-03, 9.97304916e-05,\n",
       "        3.28860283e-03, 6.33594990e-03, 3.59373093e-03, 1.46980286e-03,\n",
       "        3.83415222e-03, 2.40073204e-03, 2.99310684e-04, 1.99842453e-04,\n",
       "        4.98652458e-04, 0.00000000e+00, 4.99343872e-04, 5.63194752e-03,\n",
       "        3.65114212e-03, 1.85990334e-04, 2.39398479e-03, 1.99437141e-03,\n",
       "        4.01568413e-04, 1.96290016e-04, 7.97700882e-04, 1.03187561e-04,\n",
       "        2.87683010e-03, 6.81056976e-03, 3.49714756e-03, 1.00202560e-03,\n",
       "        3.16693783e-03, 2.48727798e-03, 4.95576859e-04, 1.96170807e-04,\n",
       "        7.14015961e-04, 6.78801537e-04, 3.02696228e-04, 6.64832592e-03,\n",
       "        3.19125652e-03, 9.97066498e-05, 3.18346024e-03, 2.85849571e-03,\n",
       "        1.99818611e-04, 2.00295448e-04, 7.87425041e-04, 2.95424461e-04,\n",
       "        3.19862366e-03, 7.03313351e-03, 4.19595242e-03, 1.28433704e-03,\n",
       "        3.14908028e-03, 2.49292850e-03, 3.99065018e-04, 9.97781754e-05,\n",
       "        1.99460983e-04, 4.98676300e-04, 9.97543335e-05, 6.83536530e-03,\n",
       "        3.48460674e-03, 1.99675560e-04, 3.97355556e-03, 3.34763527e-03]),\n",
       " 'std_fit_time': array([4.88402682e-04, 2.99119949e-04, 3.34541552e-04, 4.57169699e-04,\n",
       "        3.13034919e-04, 1.23280415e-03, 1.28303312e-03, 4.55034637e-04,\n",
       "        1.04581542e-03, 7.03835222e-04, 4.04378328e-04, 3.99494399e-04,\n",
       "        4.57095369e-04, 3.10492516e-04, 3.98398248e-04, 8.91435556e-04,\n",
       "        7.74888832e-04, 3.93486012e-04, 5.60369485e-04, 4.48714914e-04,\n",
       "        4.57204689e-04, 2.99119949e-04, 8.17359777e-04, 2.99477577e-04,\n",
       "        1.25498055e-03, 1.28915613e-03, 9.19213468e-04, 4.58350250e-04,\n",
       "        5.63533941e-04, 8.23162725e-04, 3.99255927e-04, 4.53185399e-04,\n",
       "        4.56949743e-04, 4.16786776e-04, 4.57022539e-04, 6.63747465e-04,\n",
       "        4.85802659e-04, 4.97083028e-04, 5.59104637e-04, 5.92964645e-04,\n",
       "        4.53310169e-04, 4.88636574e-04, 3.54330229e-04, 2.99191475e-04,\n",
       "        8.98685716e-04, 1.16500638e-03, 9.15854787e-04, 1.02423131e-03,\n",
       "        7.57494009e-04, 6.73517372e-04, 4.57204626e-04, 3.99686058e-04,\n",
       "        4.98652470e-04, 0.00000000e+00, 4.99559516e-04, 9.34107998e-04,\n",
       "        1.03019975e-03, 3.73232882e-04, 7.98642266e-04, 6.30713574e-04,\n",
       "        4.92077223e-04, 3.92642148e-04, 3.98851093e-04, 3.09562683e-04,\n",
       "        9.92561687e-04, 1.09543040e-03, 9.15088539e-04, 2.33798078e-05,\n",
       "        1.18729465e-03, 8.60435510e-04, 4.95656219e-04, 3.92416714e-04,\n",
       "        4.69897723e-04, 4.56935989e-04, 4.62695444e-04, 1.17307196e-03,\n",
       "        3.91570729e-04, 2.99119949e-04, 5.90504596e-04, 6.95901368e-04,\n",
       "        3.99638022e-04, 4.00594760e-04, 3.95189451e-04, 4.64924561e-04,\n",
       "        7.48686811e-04, 1.50218135e-03, 9.28182198e-04, 4.58314503e-04,\n",
       "        6.26767663e-04, 1.02167802e-03, 4.89341455e-04, 2.99334526e-04,\n",
       "        3.98921967e-04, 4.98790314e-04, 2.99263000e-04, 1.26959012e-03,\n",
       "        4.86263670e-04, 3.99352148e-04, 7.77558939e-04, 9.44075263e-04]),\n",
       " 'mean_score_time': array([0.00000000e+00, 0.00000000e+00, 9.95159149e-05, 0.00000000e+00,\n",
       "        3.84545326e-04, 3.96490097e-04, 5.85603714e-04, 5.05876541e-04,\n",
       "        1.99389458e-04, 3.93509865e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 2.99048424e-04,\n",
       "        2.98976898e-04, 0.00000000e+00, 6.00433350e-04, 3.27658653e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 3.63659859e-04, 0.00000000e+00,\n",
       "        2.99859047e-04, 5.97882271e-04, 2.98666954e-04, 3.78441811e-04,\n",
       "        5.74731827e-04, 4.53996658e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.89099121e-04,\n",
       "        5.08117676e-04, 0.00000000e+00, 3.98850441e-04, 9.97543335e-05,\n",
       "        0.00000000e+00, 0.00000000e+00, 2.99143791e-04, 0.00000000e+00,\n",
       "        4.02212143e-04, 3.54957581e-04, 5.98263741e-04, 6.12568855e-04,\n",
       "        6.67524338e-04, 6.52813911e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 3.22675705e-04,\n",
       "        5.98168373e-04, 0.00000000e+00, 5.15222549e-04, 2.99167633e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 4.28557396e-04, 0.00000000e+00,\n",
       "        3.99303436e-04, 1.55138969e-04, 4.83751297e-04, 9.96589661e-05,\n",
       "        3.88526917e-04, 2.40063667e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.02045250e-04,\n",
       "        5.98478317e-04, 0.00000000e+00, 6.02793694e-04, 3.99541855e-04,\n",
       "        0.00000000e+00, 0.00000000e+00, 8.12339783e-04, 0.00000000e+00,\n",
       "        6.98256493e-04, 2.95877457e-04, 4.73713875e-04, 4.08005714e-04,\n",
       "        5.37705421e-04, 5.98549843e-04, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.99010086e-04,\n",
       "        9.97066498e-05, 0.00000000e+00, 7.42602348e-04, 4.97460365e-04]),\n",
       " 'std_score_time': array([0.        , 0.        , 0.00029855, 0.        , 0.00047263,\n",
       "        0.00048566, 0.00048093, 0.00050619, 0.00039904, 0.00048205,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0004568 , 0.0004567 , 0.        , 0.00049026, 0.00045187,\n",
       "        0.        , 0.        , 0.00045578, 0.        , 0.00045835,\n",
       "        0.00048817, 0.00045622, 0.00046567, 0.00047161, 0.00047088,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00047735, 0.00050877, 0.        , 0.00048849, 0.00029926,\n",
       "        0.        , 0.        , 0.00045695, 0.        , 0.00049269,\n",
       "        0.00045101, 0.00048848, 0.00050196, 0.00044654, 0.00044781,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00044588, 0.00048868, 0.        , 0.00051735, 0.00045699,\n",
       "        0.        , 0.        , 0.00047223, 0.        , 0.00048905,\n",
       "        0.00032566, 0.00050834, 0.00029898, 0.00047691, 0.00039721,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00049248, 0.00048866, 0.        , 0.00049229, 0.00048934,\n",
       "        0.        , 0.        , 0.00040855, 0.        , 0.00045734,\n",
       "        0.00045199, 0.00047872, 0.00050033, 0.00050076, 0.00048871,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00049901, 0.00029912, 0.        , 0.0004511 , 0.00049759]),\n",
       " 'param_C': masked_array(data=[100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
       "                    100, 100, 100, 100, 100, 100, 100, 100, 100, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
       "                    1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
       "                    1.0, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,\n",
       "                    0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "                    0.01],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_penalty': masked_array(data=['l1', 'l1', 'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'elasticnet', 'elasticnet', 'elasticnet',\n",
       "                    'elasticnet', 'elasticnet', 'none', 'none', 'none',\n",
       "                    'none', 'none', 'l1', 'l1', 'l1', 'l1', 'l1', 'l2',\n",
       "                    'l2', 'l2', 'l2', 'l2', 'elasticnet', 'elasticnet',\n",
       "                    'elasticnet', 'elasticnet', 'elasticnet', 'none',\n",
       "                    'none', 'none', 'none', 'none', 'l1', 'l1', 'l1', 'l1',\n",
       "                    'l1', 'l2', 'l2', 'l2', 'l2', 'l2', 'elasticnet',\n",
       "                    'elasticnet', 'elasticnet', 'elasticnet', 'elasticnet',\n",
       "                    'none', 'none', 'none', 'none', 'none', 'l1', 'l1',\n",
       "                    'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'elasticnet', 'elasticnet', 'elasticnet', 'elasticnet',\n",
       "                    'elasticnet', 'none', 'none', 'none', 'none', 'none',\n",
       "                    'l1', 'l1', 'l1', 'l1', 'l1', 'l2', 'l2', 'l2', 'l2',\n",
       "                    'l2', 'elasticnet', 'elasticnet', 'elasticnet',\n",
       "                    'elasticnet', 'elasticnet', 'none', 'none', 'none',\n",
       "                    'none', 'none'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_solver': masked_array(data=['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga',\n",
       "                    'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga',\n",
       "                    'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga',\n",
       "                    'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga',\n",
       "                    'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga',\n",
       "                    'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga',\n",
       "                    'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga',\n",
       "                    'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga',\n",
       "                    'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga',\n",
       "                    'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga',\n",
       "                    'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga',\n",
       "                    'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga',\n",
       "                    'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga',\n",
       "                    'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga',\n",
       "                    'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga',\n",
       "                    'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga',\n",
       "                    'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga',\n",
       "                    'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga',\n",
       "                    'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga',\n",
       "                    'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 100, 'penalty': 'l1', 'solver': 'newton-cg'},\n",
       "  {'C': 100, 'penalty': 'l1', 'solver': 'lbfgs'},\n",
       "  {'C': 100, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 100, 'penalty': 'l1', 'solver': 'sag'},\n",
       "  {'C': 100, 'penalty': 'l1', 'solver': 'saga'},\n",
       "  {'C': 100, 'penalty': 'l2', 'solver': 'newton-cg'},\n",
       "  {'C': 100, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 100, 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 100, 'penalty': 'l2', 'solver': 'sag'},\n",
       "  {'C': 100, 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 100, 'penalty': 'elasticnet', 'solver': 'newton-cg'},\n",
       "  {'C': 100, 'penalty': 'elasticnet', 'solver': 'lbfgs'},\n",
       "  {'C': 100, 'penalty': 'elasticnet', 'solver': 'liblinear'},\n",
       "  {'C': 100, 'penalty': 'elasticnet', 'solver': 'sag'},\n",
       "  {'C': 100, 'penalty': 'elasticnet', 'solver': 'saga'},\n",
       "  {'C': 100, 'penalty': 'none', 'solver': 'newton-cg'},\n",
       "  {'C': 100, 'penalty': 'none', 'solver': 'lbfgs'},\n",
       "  {'C': 100, 'penalty': 'none', 'solver': 'liblinear'},\n",
       "  {'C': 100, 'penalty': 'none', 'solver': 'sag'},\n",
       "  {'C': 100, 'penalty': 'none', 'solver': 'saga'},\n",
       "  {'C': 10, 'penalty': 'l1', 'solver': 'newton-cg'},\n",
       "  {'C': 10, 'penalty': 'l1', 'solver': 'lbfgs'},\n",
       "  {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 10, 'penalty': 'l1', 'solver': 'sag'},\n",
       "  {'C': 10, 'penalty': 'l1', 'solver': 'saga'},\n",
       "  {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'},\n",
       "  {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 10, 'penalty': 'l2', 'solver': 'sag'},\n",
       "  {'C': 10, 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 10, 'penalty': 'elasticnet', 'solver': 'newton-cg'},\n",
       "  {'C': 10, 'penalty': 'elasticnet', 'solver': 'lbfgs'},\n",
       "  {'C': 10, 'penalty': 'elasticnet', 'solver': 'liblinear'},\n",
       "  {'C': 10, 'penalty': 'elasticnet', 'solver': 'sag'},\n",
       "  {'C': 10, 'penalty': 'elasticnet', 'solver': 'saga'},\n",
       "  {'C': 10, 'penalty': 'none', 'solver': 'newton-cg'},\n",
       "  {'C': 10, 'penalty': 'none', 'solver': 'lbfgs'},\n",
       "  {'C': 10, 'penalty': 'none', 'solver': 'liblinear'},\n",
       "  {'C': 10, 'penalty': 'none', 'solver': 'sag'},\n",
       "  {'C': 10, 'penalty': 'none', 'solver': 'saga'},\n",
       "  {'C': 1.0, 'penalty': 'l1', 'solver': 'newton-cg'},\n",
       "  {'C': 1.0, 'penalty': 'l1', 'solver': 'lbfgs'},\n",
       "  {'C': 1.0, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 1.0, 'penalty': 'l1', 'solver': 'sag'},\n",
       "  {'C': 1.0, 'penalty': 'l1', 'solver': 'saga'},\n",
       "  {'C': 1.0, 'penalty': 'l2', 'solver': 'newton-cg'},\n",
       "  {'C': 1.0, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 1.0, 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 1.0, 'penalty': 'l2', 'solver': 'sag'},\n",
       "  {'C': 1.0, 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'newton-cg'},\n",
       "  {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'lbfgs'},\n",
       "  {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'liblinear'},\n",
       "  {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'sag'},\n",
       "  {'C': 1.0, 'penalty': 'elasticnet', 'solver': 'saga'},\n",
       "  {'C': 1.0, 'penalty': 'none', 'solver': 'newton-cg'},\n",
       "  {'C': 1.0, 'penalty': 'none', 'solver': 'lbfgs'},\n",
       "  {'C': 1.0, 'penalty': 'none', 'solver': 'liblinear'},\n",
       "  {'C': 1.0, 'penalty': 'none', 'solver': 'sag'},\n",
       "  {'C': 1.0, 'penalty': 'none', 'solver': 'saga'},\n",
       "  {'C': 0.1, 'penalty': 'l1', 'solver': 'newton-cg'},\n",
       "  {'C': 0.1, 'penalty': 'l1', 'solver': 'lbfgs'},\n",
       "  {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 0.1, 'penalty': 'l1', 'solver': 'sag'},\n",
       "  {'C': 0.1, 'penalty': 'l1', 'solver': 'saga'},\n",
       "  {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'},\n",
       "  {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 0.1, 'penalty': 'l2', 'solver': 'sag'},\n",
       "  {'C': 0.1, 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'newton-cg'},\n",
       "  {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'lbfgs'},\n",
       "  {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'liblinear'},\n",
       "  {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'sag'},\n",
       "  {'C': 0.1, 'penalty': 'elasticnet', 'solver': 'saga'},\n",
       "  {'C': 0.1, 'penalty': 'none', 'solver': 'newton-cg'},\n",
       "  {'C': 0.1, 'penalty': 'none', 'solver': 'lbfgs'},\n",
       "  {'C': 0.1, 'penalty': 'none', 'solver': 'liblinear'},\n",
       "  {'C': 0.1, 'penalty': 'none', 'solver': 'sag'},\n",
       "  {'C': 0.1, 'penalty': 'none', 'solver': 'saga'},\n",
       "  {'C': 0.01, 'penalty': 'l1', 'solver': 'newton-cg'},\n",
       "  {'C': 0.01, 'penalty': 'l1', 'solver': 'lbfgs'},\n",
       "  {'C': 0.01, 'penalty': 'l1', 'solver': 'liblinear'},\n",
       "  {'C': 0.01, 'penalty': 'l1', 'solver': 'sag'},\n",
       "  {'C': 0.01, 'penalty': 'l1', 'solver': 'saga'},\n",
       "  {'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'},\n",
       "  {'C': 0.01, 'penalty': 'l2', 'solver': 'lbfgs'},\n",
       "  {'C': 0.01, 'penalty': 'l2', 'solver': 'liblinear'},\n",
       "  {'C': 0.01, 'penalty': 'l2', 'solver': 'sag'},\n",
       "  {'C': 0.01, 'penalty': 'l2', 'solver': 'saga'},\n",
       "  {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'newton-cg'},\n",
       "  {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'lbfgs'},\n",
       "  {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'liblinear'},\n",
       "  {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'sag'},\n",
       "  {'C': 0.01, 'penalty': 'elasticnet', 'solver': 'saga'},\n",
       "  {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'},\n",
       "  {'C': 0.01, 'penalty': 'none', 'solver': 'lbfgs'},\n",
       "  {'C': 0.01, 'penalty': 'none', 'solver': 'liblinear'},\n",
       "  {'C': 0.01, 'penalty': 'none', 'solver': 'sag'},\n",
       "  {'C': 0.01, 'penalty': 'none', 'solver': 'saga'}],\n",
       " 'split0_test_score': array([       nan,        nan, 0.75806452,        nan, 0.75806452,\n",
       "        0.75806452, 0.75806452, 0.75806452, 0.75806452, 0.75806452,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.75806452, 0.75806452,        nan, 0.75806452, 0.75806452,\n",
       "               nan,        nan, 0.75806452,        nan, 0.75806452,\n",
       "        0.75806452, 0.75806452, 0.75806452, 0.75806452, 0.75806452,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.75806452, 0.75806452,        nan, 0.75806452, 0.75806452,\n",
       "               nan,        nan, 0.75806452,        nan, 0.75806452,\n",
       "        0.75806452, 0.75806452, 0.74193548, 0.75806452, 0.75806452,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.75806452, 0.75806452,        nan, 0.75806452, 0.75806452,\n",
       "               nan,        nan, 0.77419355,        nan, 0.75806452,\n",
       "        0.70967742, 0.70967742, 0.72580645, 0.70967742, 0.70967742,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.75806452, 0.75806452,        nan, 0.75806452, 0.75806452,\n",
       "               nan,        nan, 0.64516129,        nan, 0.66129032,\n",
       "        0.74193548, 0.74193548, 0.70967742, 0.74193548, 0.74193548,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.75806452, 0.75806452,        nan, 0.75806452, 0.75806452]),\n",
       " 'split1_test_score': array([       nan,        nan, 0.80645161,        nan, 0.80645161,\n",
       "        0.80645161, 0.80645161, 0.80645161, 0.80645161, 0.80645161,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.80645161, 0.80645161,        nan, 0.80645161, 0.80645161,\n",
       "               nan,        nan, 0.80645161,        nan, 0.80645161,\n",
       "        0.80645161, 0.80645161, 0.80645161, 0.80645161, 0.80645161,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.80645161, 0.80645161,        nan, 0.80645161, 0.80645161,\n",
       "               nan,        nan, 0.80645161,        nan, 0.80645161,\n",
       "        0.80645161, 0.80645161, 0.80645161, 0.80645161, 0.80645161,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.80645161, 0.80645161,        nan, 0.80645161, 0.80645161,\n",
       "               nan,        nan, 0.80645161,        nan, 0.80645161,\n",
       "        0.80645161, 0.80645161, 0.80645161, 0.80645161, 0.80645161,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.80645161, 0.80645161,        nan, 0.80645161, 0.80645161,\n",
       "               nan,        nan, 0.75806452,        nan, 0.66129032,\n",
       "        0.80645161, 0.80645161, 0.79032258, 0.80645161, 0.80645161,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.80645161, 0.80645161,        nan, 0.80645161, 0.80645161]),\n",
       " 'split2_test_score': array([       nan,        nan, 0.69354839,        nan, 0.69354839,\n",
       "        0.69354839, 0.69354839, 0.69354839, 0.69354839, 0.69354839,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.69354839, 0.69354839,        nan, 0.69354839, 0.69354839,\n",
       "               nan,        nan, 0.69354839,        nan, 0.69354839,\n",
       "        0.69354839, 0.69354839, 0.69354839, 0.69354839, 0.69354839,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.69354839, 0.69354839,        nan, 0.69354839, 0.69354839,\n",
       "               nan,        nan, 0.72580645,        nan, 0.70967742,\n",
       "        0.70967742, 0.70967742, 0.72580645, 0.70967742, 0.70967742,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.69354839, 0.69354839,        nan, 0.69354839, 0.69354839,\n",
       "               nan,        nan, 0.70967742,        nan, 0.69354839,\n",
       "        0.72580645, 0.72580645, 0.69354839, 0.72580645, 0.72580645,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.69354839, 0.69354839,        nan, 0.69354839, 0.69354839,\n",
       "               nan,        nan, 0.64516129,        nan, 0.66129032,\n",
       "        0.70967742, 0.70967742, 0.74193548, 0.70967742, 0.70967742,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.69354839, 0.69354839,        nan, 0.69354839, 0.69354839]),\n",
       " 'split3_test_score': array([       nan,        nan, 0.85483871,        nan, 0.85483871,\n",
       "        0.85483871, 0.85483871, 0.85483871, 0.85483871, 0.85483871,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.85483871, 0.85483871,        nan, 0.85483871, 0.85483871,\n",
       "               nan,        nan, 0.85483871,        nan, 0.85483871,\n",
       "        0.85483871, 0.85483871, 0.85483871, 0.85483871, 0.85483871,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.85483871, 0.85483871,        nan, 0.85483871, 0.85483871,\n",
       "               nan,        nan, 0.83870968,        nan, 0.85483871,\n",
       "        0.85483871, 0.85483871, 0.85483871, 0.85483871, 0.85483871,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.85483871, 0.85483871,        nan, 0.85483871, 0.85483871,\n",
       "               nan,        nan, 0.82258065,        nan, 0.82258065,\n",
       "        0.85483871, 0.85483871, 0.82258065, 0.85483871, 0.85483871,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.85483871, 0.85483871,        nan, 0.85483871, 0.85483871,\n",
       "               nan,        nan, 0.72580645,        nan, 0.64516129,\n",
       "        0.82258065, 0.82258065, 0.79032258, 0.82258065, 0.82258065,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.85483871, 0.85483871,        nan, 0.85483871, 0.85483871]),\n",
       " 'split4_test_score': array([       nan,        nan, 0.73770492,        nan, 0.73770492,\n",
       "        0.73770492, 0.73770492, 0.73770492, 0.73770492, 0.73770492,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.73770492, 0.73770492,        nan, 0.73770492, 0.73770492,\n",
       "               nan,        nan, 0.73770492,        nan, 0.73770492,\n",
       "        0.73770492, 0.73770492, 0.73770492, 0.73770492, 0.73770492,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.73770492, 0.73770492,        nan, 0.73770492, 0.73770492,\n",
       "               nan,        nan, 0.73770492,        nan, 0.73770492,\n",
       "        0.73770492, 0.73770492, 0.73770492, 0.73770492, 0.73770492,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.73770492, 0.73770492,        nan, 0.73770492, 0.73770492,\n",
       "               nan,        nan, 0.75409836,        nan, 0.75409836,\n",
       "        0.73770492, 0.73770492, 0.73770492, 0.73770492, 0.73770492,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.73770492, 0.73770492,        nan, 0.73770492, 0.73770492,\n",
       "               nan,        nan, 0.75409836,        nan, 0.6557377 ,\n",
       "        0.75409836, 0.75409836, 0.73770492, 0.75409836, 0.75409836,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.73770492, 0.73770492,        nan, 0.73770492, 0.73770492]),\n",
       " 'split5_test_score': array([       nan,        nan, 0.6557377 ,        nan, 0.6557377 ,\n",
       "        0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 ,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.6557377 , 0.6557377 ,        nan, 0.6557377 , 0.6557377 ,\n",
       "               nan,        nan, 0.6557377 ,        nan, 0.6557377 ,\n",
       "        0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 ,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.6557377 , 0.6557377 ,        nan, 0.6557377 , 0.6557377 ,\n",
       "               nan,        nan, 0.6557377 ,        nan, 0.6557377 ,\n",
       "        0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 ,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.6557377 , 0.6557377 ,        nan, 0.6557377 , 0.6557377 ,\n",
       "               nan,        nan, 0.67213115,        nan, 0.67213115,\n",
       "        0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 ,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.6557377 , 0.6557377 ,        nan, 0.6557377 , 0.6557377 ,\n",
       "               nan,        nan, 0.57377049,        nan, 0.6557377 ,\n",
       "        0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 , 0.6557377 ,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.6557377 , 0.6557377 ,        nan, 0.6557377 , 0.6557377 ]),\n",
       " 'split6_test_score': array([       nan,        nan, 0.83606557,        nan, 0.83606557,\n",
       "        0.83606557, 0.83606557, 0.83606557, 0.83606557, 0.83606557,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.83606557, 0.83606557,        nan, 0.83606557, 0.83606557,\n",
       "               nan,        nan, 0.83606557,        nan, 0.83606557,\n",
       "        0.83606557, 0.83606557, 0.83606557, 0.83606557, 0.83606557,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.83606557, 0.83606557,        nan, 0.83606557, 0.83606557,\n",
       "               nan,        nan, 0.81967213,        nan, 0.81967213,\n",
       "        0.83606557, 0.83606557, 0.81967213, 0.83606557, 0.83606557,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.83606557, 0.83606557,        nan, 0.83606557, 0.83606557,\n",
       "               nan,        nan, 0.81967213,        nan, 0.81967213,\n",
       "        0.83606557, 0.83606557, 0.81967213, 0.83606557, 0.83606557,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.83606557, 0.83606557,        nan, 0.83606557, 0.83606557,\n",
       "               nan,        nan, 0.68852459,        nan, 0.6557377 ,\n",
       "        0.81967213, 0.81967213, 0.75409836, 0.81967213, 0.81967213,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.83606557, 0.83606557,        nan, 0.83606557, 0.83606557]),\n",
       " 'split7_test_score': array([       nan,        nan, 0.85245902,        nan, 0.85245902,\n",
       "        0.85245902, 0.85245902, 0.85245902, 0.85245902, 0.85245902,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.85245902, 0.85245902,        nan, 0.85245902, 0.85245902,\n",
       "               nan,        nan, 0.85245902,        nan, 0.85245902,\n",
       "        0.85245902, 0.85245902, 0.85245902, 0.85245902, 0.85245902,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.85245902, 0.85245902,        nan, 0.85245902, 0.85245902,\n",
       "               nan,        nan, 0.83606557,        nan, 0.85245902,\n",
       "        0.85245902, 0.85245902, 0.85245902, 0.85245902, 0.85245902,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.85245902, 0.85245902,        nan, 0.85245902, 0.85245902,\n",
       "               nan,        nan, 0.81967213,        nan, 0.78688525,\n",
       "        0.83606557, 0.83606557, 0.81967213, 0.83606557, 0.83606557,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.85245902, 0.85245902,        nan, 0.85245902, 0.85245902,\n",
       "               nan,        nan, 0.80327869,        nan, 0.6557377 ,\n",
       "        0.81967213, 0.81967213, 0.83606557, 0.81967213, 0.81967213,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.85245902, 0.85245902,        nan, 0.85245902, 0.85245902]),\n",
       " 'split8_test_score': array([       nan,        nan, 0.78688525,        nan, 0.78688525,\n",
       "        0.78688525, 0.78688525, 0.78688525, 0.78688525, 0.78688525,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.78688525, 0.78688525,        nan, 0.78688525, 0.78688525,\n",
       "               nan,        nan, 0.78688525,        nan, 0.78688525,\n",
       "        0.78688525, 0.78688525, 0.78688525, 0.78688525, 0.78688525,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.78688525, 0.78688525,        nan, 0.78688525, 0.78688525,\n",
       "               nan,        nan, 0.78688525,        nan, 0.78688525,\n",
       "        0.78688525, 0.78688525, 0.78688525, 0.78688525, 0.78688525,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.78688525, 0.78688525,        nan, 0.78688525, 0.78688525,\n",
       "               nan,        nan, 0.75409836,        nan, 0.7704918 ,\n",
       "        0.78688525, 0.78688525, 0.80327869, 0.78688525, 0.78688525,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.78688525, 0.78688525,        nan, 0.78688525, 0.78688525,\n",
       "               nan,        nan, 0.67213115,        nan, 0.6557377 ,\n",
       "        0.73770492, 0.73770492, 0.80327869, 0.73770492, 0.73770492,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.78688525, 0.78688525,        nan, 0.78688525, 0.78688525]),\n",
       " 'split9_test_score': array([       nan,        nan, 0.75409836,        nan, 0.75409836,\n",
       "        0.75409836, 0.75409836, 0.75409836, 0.75409836, 0.75409836,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.75409836, 0.75409836,        nan, 0.75409836, 0.75409836,\n",
       "               nan,        nan, 0.75409836,        nan, 0.75409836,\n",
       "        0.75409836, 0.75409836, 0.75409836, 0.75409836, 0.75409836,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.75409836, 0.75409836,        nan, 0.75409836, 0.75409836,\n",
       "               nan,        nan, 0.75409836,        nan, 0.75409836,\n",
       "        0.75409836, 0.75409836, 0.75409836, 0.75409836, 0.75409836,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.75409836, 0.75409836,        nan, 0.75409836, 0.75409836,\n",
       "               nan,        nan, 0.75409836,        nan, 0.73770492,\n",
       "        0.75409836, 0.75409836, 0.75409836, 0.75409836, 0.75409836,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.75409836, 0.75409836,        nan, 0.75409836, 0.75409836,\n",
       "               nan,        nan, 0.73770492,        nan, 0.6557377 ,\n",
       "        0.72131148, 0.72131148, 0.75409836, 0.72131148, 0.72131148,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.75409836, 0.75409836,        nan, 0.75409836, 0.75409836]),\n",
       " 'mean_test_score': array([       nan,        nan, 0.7735854 ,        nan, 0.7735854 ,\n",
       "        0.7735854 , 0.7735854 , 0.7735854 , 0.7735854 , 0.7735854 ,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.7735854 , 0.7735854 ,        nan, 0.7735854 , 0.7735854 ,\n",
       "               nan,        nan, 0.7735854 ,        nan, 0.7735854 ,\n",
       "        0.7735854 , 0.7735854 , 0.7735854 , 0.7735854 , 0.7735854 ,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.7735854 , 0.7735854 ,        nan, 0.7735854 , 0.7735854 ,\n",
       "               nan,        nan, 0.77191962,        nan, 0.77355896,\n",
       "        0.77519831, 0.77519831, 0.77355896, 0.77519831, 0.77519831,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.7735854 , 0.7735854 ,        nan, 0.7735854 , 0.7735854 ,\n",
       "               nan,        nan, 0.76866737,        nan, 0.76216288,\n",
       "        0.77033316, 0.77033316, 0.7638551 , 0.77033316, 0.77033316,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.7735854 , 0.7735854 ,        nan, 0.7735854 , 0.7735854 ,\n",
       "               nan,        nan, 0.70037017,        nan, 0.65634585,\n",
       "        0.75888419, 0.75888419, 0.75732417, 0.75888419, 0.75888419,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.7735854 , 0.7735854 ,        nan, 0.7735854 , 0.7735854 ]),\n",
       " 'std_test_score': array([       nan,        nan, 0.06339247,        nan, 0.06339247,\n",
       "        0.06339247, 0.06339247, 0.06339247, 0.06339247, 0.06339247,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.06339247, 0.06339247,        nan, 0.06339247, 0.06339247,\n",
       "               nan,        nan, 0.06339247,        nan, 0.06339247,\n",
       "        0.06339247, 0.06339247, 0.06339247, 0.06339247, 0.06339247,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.06339247, 0.06339247,        nan, 0.06339247, 0.06339247,\n",
       "               nan,        nan, 0.05438494,        nan, 0.06007043,\n",
       "        0.06151288, 0.06151288, 0.05919796, 0.06151288, 0.06151288,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.06339247, 0.06339247,        nan, 0.06339247, 0.06339247,\n",
       "               nan,        nan, 0.04796209,        nan, 0.04805556,\n",
       "        0.06122356, 0.06122356, 0.0564868 , 0.06122356, 0.06122356,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.06339247, 0.06339247,        nan, 0.06339247, 0.06339247,\n",
       "               nan,        nan, 0.06473615,        nan, 0.00447947,\n",
       "        0.05379701, 0.05379701, 0.04870562, 0.05379701, 0.05379701,\n",
       "               nan,        nan,        nan,        nan,        nan,\n",
       "        0.06339247, 0.06339247,        nan, 0.06339247, 0.06339247]),\n",
       " 'rank_test_score': array([100,  57,   5,  66,   5,   5,   5,   5,   5,   5,  95,  89,  88,\n",
       "         87,  86,   5,   5,  81,   5,   5,  75,  74,   5,  72,   5,   5,\n",
       "          5,   5,   5,   5,  76,  77,  78,  79,  80,   5,   5,  82,   5,\n",
       "          5,  83,  84,  41,  85,  39,   1,   1,  39,   1,   1,  90,  91,\n",
       "         92,  93,  94,   5,   5,  96,   5,   5,  97,  98,  46,  73,  48,\n",
       "         42,  42,  47,  42,  42,  99,  71,  59,  61,  70,   5,   5,  65,\n",
       "          5,   5,  67,  68,  54,  69,  55,  49,  49,  53,  49,  49,  64,\n",
       "         62,  63,  60,  58,   5,   5,  56,   5,   5])}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TO DO:\n",
    "from sklearn.svm import SVC\n",
    "param_grid = {'C': [100, 10, 1.0, 0.1, 0.01],\n",
    "              'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "              'penalty' : ['l1', 'l2', 'elasticnet','none'],\n",
    "}\n",
    "grid3 = GridSearchCV(LogisticRegression(),param_grid, cv=10, scoring='accuracy')\n",
    "# fit the grid with data\n",
    "grid3.fit(X_train, y_train)\n",
    "grid3.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7751983077736646\n",
      "LogisticRegression(solver='newton-cg')\n",
      "{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'newton-cg', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# examine the best parameter\n",
    "print(grid3.best_score_)\n",
    "print(grid3.best_estimator_)\n",
    "print(grid3.best_estimator_.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='newton-cg').fit(X_train, y_train)\n",
    "yhat_test3 = lr.predict(X_test)\n",
    "yhat_test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_train3 = lr.predict(X_train)\n",
    "yhat_train3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of train set: 0.7785016286644951\n",
      "Accuracy score of test set: 0.7727272727272727\n",
      "Jaccard score of train set: 0.7252525252525253\n",
      "Jaccard score of test set: 0.7131147540983607\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84       403\n",
      "           1       0.73      0.56      0.64       211\n",
      "\n",
      "    accuracy                           0.78       614\n",
      "   macro avg       0.76      0.73      0.74       614\n",
      "weighted avg       0.77      0.78      0.77       614\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.83        97\n",
      "           1       0.76      0.56      0.65        57\n",
      "\n",
      "    accuracy                           0.77       154\n",
      "   macro avg       0.77      0.73      0.74       154\n",
      "weighted avg       0.77      0.77      0.76       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TO DO:\n",
    "print(\"Accuracy score of train set:\", accuracy_score(y_train, yhat_train3))\n",
    "print(\"Accuracy score of test set:\", accuracy_score(y_test, yhat_test3))\n",
    "\n",
    "print(\"Jaccard score of train set:\", jaccard_score(y_train, yhat_train3, pos_label = 0))\n",
    "print(\"Jaccard score of test set:\", jaccard_score(y_test, yhat_test3, pos_label = 0))\n",
    "\n",
    "print (classification_report(y_train, yhat_train3))\n",
    "print (classification_report(y_test, yhat_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': {'KNN': 0.7899022801302932, 'DT': 0.7785016286644951, 'SVM': 0.7752442996742671, 'LR': 0.7785016286644951, 'EN_HARD': 0, 'EN_SOFT': 0}, 'test': {'KNN': 0.7727272727272727, 'DT': 0.7532467532467533, 'SVM': 0.7727272727272727, 'LR': 0.7727272727272727, 'EN_HARD': 0, 'EN_SOFT': 0}}\n",
      "{'train': {'KNN': 0.7435387673956262, 'DT': 0.7075268817204301, 'SVM': 0.7234468937875751, 'LR': 0.7252525252525253, 'EN_HARD': 0, 'EN_SOFT': 0}, 'test': {'KNN': 0.7244094488188977, 'DT': 0.6666666666666666, 'SVM': 0.7131147540983607, 'LR': 0.7131147540983607, 'EN_HARD': 0, 'EN_SOFT': 0}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "f1_scores['train']['LR'] = accuracy_score(y_train, yhat_train3)\n",
    "f1_scores['test']['LR'] = accuracy_score(y_test, yhat_test3)\n",
    "jaccard_scores['train']['LR'] = jaccard_score(y_train, yhat_train3, pos_label = 0)\n",
    "jaccard_scores['test']['LR'] = jaccard_score(y_test, yhat_test3, pos_label = 0)\n",
    "                                          \n",
    "print(f1_scores)\n",
    "print(jaccard_scores) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfPytCDYM1le"
   },
   "source": [
    "# Additional Question: \n",
    "### Interpret and explain the parameters you have chosen to fine tune in LR algorithm.\n",
    "Type your answer in the cell bellow as the markdown format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfPytCDYM1le"
   },
   "source": [
    "+ penalty (Specify the norm of the penalty): {'l1', 'l2', 'elasticnet', 'none'}\n",
    "        - 'none': no penalty is added;\n",
    "        - 'l2': add a L2 penalty term and it is the default choice;\n",
    "        - 'l1': add a L1 penalty term;\n",
    "        - 'elasticnet': both L1 and L2 penalty terms are added.\n",
    "\n",
    "+ C (Inverse of regularization strength): smaller values specify stronger regularization.\n",
    "\n",
    "+ solver (Algorithm to use in the optimization problem): {'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'}\n",
    "        - For small datasets, 'liblinear' is a good choice, whereas 'sag'\n",
    "          and 'saga' are faster for large ones;\n",
    "        - For multiclass problems, only 'newton-cg', 'sag', 'saga' and\n",
    "          'lbfgs' handle multinomial loss;\n",
    "        - 'liblinear' is limited to one-versus-rest schemes.\n",
    "+ The choice of the algorithm depends on the penalty chosen: \n",
    "    Supported penalties by solver:\n",
    "           - 'newton-cg'   -   ['l2', 'none']\n",
    "           - 'lbfgs'       -   ['l2', 'none']\n",
    "           - 'liblinear'   -   ['l1', 'l2']\n",
    "           - 'sag'         -   ['l2', 'none']\n",
    "           - 'saga'        -   ['elasticnet', 'l1', 'l2', 'none']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RmPs5O5RM1lf"
   },
   "source": [
    "### TO DO:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xhThcwLYM1li"
   },
   "source": [
    "# Advanced part (15%  of the total score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eRc5JoN7M1lo"
   },
   "source": [
    "# Ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8-eteyNxM1lo"
   },
   "source": [
    "### 19. Perform soft voting on the 4 above models (using the same setting for the 4 models as in previous steps.) \n",
    "**Hint**: Using VotingClassifier in sklearn.ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "id": "G7FfposgM1lp"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "J-EjCxe6M1ls"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('knn',\n",
       "                              KNeighborsClassifier(metric='euclidean',\n",
       "                                                   n_neighbors=26)),\n",
       "                             ('dtc',\n",
       "                              DecisionTreeClassifier(criterion='entropy',\n",
       "                                                     max_depth=5,\n",
       "                                                     min_samples_leaf=0.1,\n",
       "                                                     min_samples_split=0.1)),\n",
       "                             ('svc',\n",
       "                              SVC(C=0.1, kernel='linear', probability=True)),\n",
       "                             ('lr', LogisticRegression(solver='newton-cg'))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TO DO:\n",
    "#create a dictionary of our models\n",
    "knn = KNeighborsClassifier(metric='euclidean', n_neighbors=26)\n",
    "dtc = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_leaf=0.1,\n",
    "                       min_samples_split=0.1)\n",
    "svc = SVC(C=0.1, kernel='linear', probability=True)\n",
    "lr =  LogisticRegression(solver='newton-cg')\n",
    "\n",
    "knn._estimator_type = \"classifier\"\n",
    "dtc._estimator_type = \"classifier\"\n",
    "svc._estimator_type = \"classifier\"\n",
    "lr._estimator_type = \"classifier\"\n",
    "\n",
    "ensemble = VotingClassifier(estimators=[('knn', knn),\n",
    "                                        ('dtc', dtc), \n",
    "                                        ('svc', svc),\n",
    "                                        ('lr', lr)], \n",
    "                            voting='soft')\n",
    "#create our voting classifier, inputting our models\n",
    "# ensemble = VotingClassifier(estimators=models, voting='soft')\n",
    "ensemble.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZu5N_i3M1lu"
   },
   "source": [
    "### 20. Run the prediction on the ensembling model using soft voting on training data and test data, then calculate the f1 score and Jaccard similarity score and save it to f1_scores dict and jaccard_scores dict.¶\n",
    "\n",
    "**Requirement**: F1 score on test data must be higher than **0.66**, Jaccard similarity score must be higher than **0.78**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "SeuL7a0rM1lu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TO DO:\n",
    "yhat_train_sv = ensemble.predict(X_train)\n",
    "yhat_train_sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_test_sv = ensemble.predict(X_test)\n",
    "yhat_test_sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of train set: 0.7736156351791531\n",
      "Accuracy score of test set: 0.7857142857142857\n",
      "Jaccard score of train set: 0.7225548902195609\n",
      "Jaccard score of test set: 0.7272727272727273\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.90      0.84       403\n",
      "           1       0.73      0.54      0.62       211\n",
      "\n",
      "    accuracy                           0.77       614\n",
      "   macro avg       0.76      0.72      0.73       614\n",
      "weighted avg       0.77      0.77      0.76       614\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.91      0.84        97\n",
      "           1       0.79      0.58      0.67        57\n",
      "\n",
      "    accuracy                           0.79       154\n",
      "   macro avg       0.79      0.74      0.75       154\n",
      "weighted avg       0.79      0.79      0.78       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TO DO:\n",
    "print(\"Accuracy score of train set:\", accuracy_score(y_train, yhat_train_sv))\n",
    "print(\"Accuracy score of test set:\", accuracy_score(y_test, yhat_test_sv))\n",
    "\n",
    "print(\"Jaccard score of train set:\", jaccard_score(y_train, yhat_train_sv, pos_label = 0))\n",
    "print(\"Jaccard score of test set:\", jaccard_score(y_test, yhat_test_sv, pos_label = 0))\n",
    "\n",
    "print (classification_report(y_train, yhat_train_sv))\n",
    "print (classification_report(y_test, yhat_test_sv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': {'KNN': 0.7899022801302932, 'DT': 0.7785016286644951, 'SVM': 0.7752442996742671, 'LR': 0.7785016286644951, 'EN_HARD': 0.8371335504885994, 'EN_SOFT': 0.7736156351791531}, 'test': {'KNN': 0.7727272727272727, 'DT': 0.7532467532467533, 'SVM': 0.7727272727272727, 'LR': 0.7727272727272727, 'EN_HARD': 0.7857142857142857, 'EN_SOFT': 0.7857142857142857}}\n",
      "{'train': {'KNN': 0.7435387673956262, 'DT': 0.7075268817204301, 'SVM': 0.7234468937875751, 'LR': 0.7252525252525253, 'EN_HARD': 0.7950819672131147, 'EN_SOFT': 0.7225548902195609}, 'test': {'KNN': 0.7244094488188977, 'DT': 0.6666666666666666, 'SVM': 0.7131147540983607, 'LR': 0.7131147540983607, 'EN_HARD': 0.7317073170731707, 'EN_SOFT': 0.7272727272727273}}\n"
     ]
    }
   ],
   "source": [
    "f1_scores['train']['EN_SOFT'] = accuracy_score(y_train, yhat_train_sv)\n",
    "f1_scores['test']['EN_SOFT'] = accuracy_score(y_test, yhat_test_sv)\n",
    "jaccard_scores['train']['EN_SOFT'] = jaccard_score(y_train, yhat_train_sv, pos_label = 0)\n",
    "jaccard_scores['test']['EN_SOFT'] = jaccard_score(y_test, yhat_test_sv, pos_label = 0)\n",
    "                                          \n",
    "print(f1_scores)\n",
    "print(jaccard_scores) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d9vVirtTM1lw"
   },
   "source": [
    "### 21, 22. Perform task 19 and 20 using hard voting.\n",
    "Hint: Using GridSearchCV in sklearn.model_selection.\n",
    "\n",
    "**Warning**: You should not use the test data for finding the best parameters.\n",
    "\n",
    "**Requirement**: F1 score on test data must be higher than **0.57**, Jaccard similarity score must be higher than **0.73**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "0n-qRxd5M1lx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('knn',\n",
       "                              KNeighborsClassifier(metric='euclidean',\n",
       "                                                   n_neighbors=26)),\n",
       "                             ('dtc',\n",
       "                              DecisionTreeClassifier(criterion='entropy',\n",
       "                                                     max_depth=5,\n",
       "                                                     min_samples_leaf=0.1,\n",
       "                                                     min_samples_split=0.1)),\n",
       "                             ('svc',\n",
       "                              SVC(C=0.1, kernel='linear', probability=True)),\n",
       "                             ('lr', LogisticRegression(solver='newton-cg'))])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TO DO:\n",
    "#create a dictionary of our models\n",
    "knn = KNeighborsClassifier(metric='euclidean', n_neighbors=26)\n",
    "dtc = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_leaf=0.1,\n",
    "                       min_samples_split=0.1)\n",
    "svc = SVC(C=0.1, kernel='linear', probability=True)\n",
    "lr =  LogisticRegression(solver='newton-cg')\n",
    "\n",
    "knn._estimator_type = \"classifier\"\n",
    "dtc._estimator_type = \"classifier\"\n",
    "svc._estimator_type = \"classifier\"\n",
    "lr._estimator_type = \"classifier\"\n",
    "\n",
    "ensemble1 = VotingClassifier(estimators=[('knn', knn),\n",
    "                                        ('dtc', dtc), \n",
    "                                        ('svc', svc),\n",
    "                                        ('lr', lr)], \n",
    "                            voting='hard')\n",
    "#create our voting classifier, inputting our models\n",
    "# ensemble = VotingClassifier(estimators=models, voting='soft')\n",
    "ensemble1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "zxvqWZBcM1lz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TO DO:\n",
    "yhat_train_hv = ensemble1.predict(X_train)\n",
    "yhat_train_hv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat_test_hv = ensemble1.predict(X_test)\n",
    "yhat_test_hv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of train set: 0.7866449511400652\n",
      "Accuracy score of test set: 0.7532467532467533\n",
      "Jaccard score of train set: 0.7385229540918163\n",
      "Jaccard score of test set: 0.6984126984126984\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.92      0.85       403\n",
      "           1       0.77      0.54      0.63       211\n",
      "\n",
      "    accuracy                           0.79       614\n",
      "   macro avg       0.78      0.73      0.74       614\n",
      "weighted avg       0.78      0.79      0.78       614\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.91      0.82        97\n",
      "           1       0.76      0.49      0.60        57\n",
      "\n",
      "    accuracy                           0.75       154\n",
      "   macro avg       0.75      0.70      0.71       154\n",
      "weighted avg       0.75      0.75      0.74       154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#TO DO:\n",
    "print(\"Accuracy score of train set:\", accuracy_score(y_train, yhat_train_hv))\n",
    "print(\"Accuracy score of test set:\", accuracy_score(y_test, yhat_test_hv))\n",
    "\n",
    "print(\"Jaccard score of train set:\", jaccard_score(y_train, yhat_train_hv, pos_label = 0))\n",
    "print(\"Jaccard score of test set:\", jaccard_score(y_test, yhat_test_hv, pos_label = 0))\n",
    "\n",
    "print (classification_report(y_train, yhat_train_hv))\n",
    "print (classification_report(y_test, yhat_test_hv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': {'KNN': 0.7899022801302932, 'DT': 0.7785016286644951, 'SVM': 0.7752442996742671, 'LR': 0.7785016286644951, 'EN_HARD': 0.7866449511400652, 'EN_SOFT': 0.7736156351791531}, 'test': {'KNN': 0.7727272727272727, 'DT': 0.7532467532467533, 'SVM': 0.7727272727272727, 'LR': 0.7727272727272727, 'EN_HARD': 0.7532467532467533, 'EN_SOFT': 0.7857142857142857}}\n",
      "{'train': {'KNN': 0.7435387673956262, 'DT': 0.7075268817204301, 'SVM': 0.7234468937875751, 'LR': 0.7252525252525253, 'EN_HARD': 0.7385229540918163, 'EN_SOFT': 0.7225548902195609}, 'test': {'KNN': 0.7244094488188977, 'DT': 0.6666666666666666, 'SVM': 0.7131147540983607, 'LR': 0.7131147540983607, 'EN_HARD': 0.6984126984126984, 'EN_SOFT': 0.7272727272727273}}\n"
     ]
    }
   ],
   "source": [
    "f1_scores['train']['EN_HARD'] = accuracy_score(y_train, yhat_train_hv)\n",
    "f1_scores['test']['EN_HARD'] = accuracy_score(y_test, yhat_test_hv)\n",
    "jaccard_scores['train']['EN_HARD'] = jaccard_score(y_train, yhat_train_hv, pos_label = 0)\n",
    "jaccard_scores['test']['EN_HARD'] = jaccard_score(y_test, yhat_test_hv, pos_label = 0)\n",
    "                                          \n",
    "print(f1_scores)\n",
    "print(jaccard_scores) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RmteU8YeM1l3"
   },
   "source": [
    "# Report\n",
    "You should be able to report the accuracy of the built model using different evaluation metrics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3q0IThKM1l3"
   },
   "source": [
    "| Algorithm          | Jaccard-training | F1-score-training |Jaccard-testing | F1-score-testing |\n",
    "|--------------------|------------------|-------------------|----------------|------------------|\n",
    "| KNN                | ?                | ?                 |  ?             |  ?               |\n",
    "| Decision Tree      | ?                | ?                 |  ?             |  ?               |\n",
    "| SVM                | ?                | ?                 |  ?             |  ?               |\n",
    "| Logistic Regression| ?                | ?                 |  ?             |  ?               |\n",
    "| Hard Voting        | ?                | ?                 |  ?             |  ?               |\n",
    "| Soft Voting        | ?                | ?                 |  ?             |  ?               |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PpqjW-eOM1l3"
   },
   "source": [
    "### 23. Create a data frame that describes the result as exactly as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "pI3_EsgtM1l4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1-score-training</th>\n",
       "      <th>F1-score-testing</th>\n",
       "      <th>Jaccard-training</th>\n",
       "      <th>Jaccard-testing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN</th>\n",
       "      <td>0.789902</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.743539</td>\n",
       "      <td>0.724409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.778502</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.707527</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.775244</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.723447</td>\n",
       "      <td>0.713115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.778502</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.725253</td>\n",
       "      <td>0.713115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hard Voting</th>\n",
       "      <td>0.786645</td>\n",
       "      <td>0.753247</td>\n",
       "      <td>0.738523</td>\n",
       "      <td>0.698413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soft Voting</th>\n",
       "      <td>0.773616</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.722555</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     F1-score-training  F1-score-testing  Jaccard-training  \\\n",
       "KNN                           0.789902          0.772727          0.743539   \n",
       "Decision Tree                 0.778502          0.753247          0.707527   \n",
       "SVM                           0.775244          0.772727          0.723447   \n",
       "Logistic Regression           0.778502          0.772727          0.725253   \n",
       "Hard Voting                   0.786645          0.753247          0.738523   \n",
       "Soft Voting                   0.773616          0.785714          0.722555   \n",
       "\n",
       "                     Jaccard-testing  \n",
       "KNN                         0.724409  \n",
       "Decision Tree               0.666667  \n",
       "SVM                         0.713115  \n",
       "Logistic Regression         0.713115  \n",
       "Hard Voting                 0.698413  \n",
       "Soft Voting                 0.727273  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TO DO:\n",
    "df1 = pd.DataFrame(f1_scores)\n",
    "df2 = pd.DataFrame(jaccard_scores)\n",
    "\n",
    "result = pd.concat([df1,df2],axis = 1)\n",
    "result.columns = ['F1-score-training', 'F1-score-testing','Jaccard-training','Jaccard-testing']\n",
    "result.index = ['KNN','Decision Tree','SVM','Logistic Regression','Hard Voting','Soft Voting']\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYifTRP7M1l5"
   },
   "source": [
    "# Additional Question: \n",
    "### Are ensemble methods always better than a single model? If not, explain why?\n",
    "\n",
    "Ensemble approaches are not always better than single models since ensemble methods essentially obtain the average accuracy, whereas some models performed better and some did worse on different subsets of the data. As a result, an ensemble model may or may not outperform any single contributing member in terms of modeling performance. \n",
    "\n",
    "As we can observe from the results table above that Hard Voting performs worse than many of the ensemble's contributing memebers. As a result, the other contributing member with the greater performance should be used instead. Soft Voting, on the other hand, outperforms all other models in the ensemble. We can put it to good use in order to improve our performance.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "450BrJ44M1l6"
   },
   "source": [
    "### TO DO:\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "2yXSkeUjM1kr",
    "qaJt1GeEM1lA",
    "450BrJ44M1l6"
   ],
   "name": "DSP303x_01_EN_2_Starter_Code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
